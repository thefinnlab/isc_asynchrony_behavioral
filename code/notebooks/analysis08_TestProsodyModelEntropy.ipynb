{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a528bc23-430b-40e7-b7ad-7171c833ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "import os, sys\n",
    "import argparse\n",
    "import torch\n",
    "import pyrootutils\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../modeling/joint-clm-prosody/')\n",
    "\n",
    "from config import *\n",
    "from src import utils\n",
    "# import dataset_utils as utils\n",
    "# from tommy_utils import nlp #nlp_utils as nlpf\n",
    "import prosody_analysis_utils as analysis\n",
    "from src.data.components.datasets import tokenize_text_with_labels, TokenTaggingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538ef30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from '/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/notebooks/../modeling/joint-clm-prosody/src/utils/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27732982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "from scipy import stats\n",
    "\n",
    "def load_model(config_path, ckpt_path, overrides):\n",
    "\n",
    "    with initialize(version_base=\"1.3\", config_path=config_path):\n",
    "        cfg = compose(config_name=\"train.yaml\", overrides=overrides)\n",
    "\n",
    "    model: LightningModule = hydra.utils.instantiate(cfg.model)\n",
    "\n",
    "    # Load the model from a checkpoint\n",
    "    checkpoint = torch.load(ckpt_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        cfg.data.model_name, add_prefix_space=False\n",
    "    )\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    return cfg, tokenizer, model\n",
    "\n",
    "def get_prosody_model_predictions(batch, model, out_fn=None):\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        _, outputs = model.step(batch=batch)\n",
    "        logits = outputs['logits'][:, -1, :]\n",
    "    \n",
    "    # get the probability of the logits\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # if we provide we save logits out\n",
    "    if out_fn:\n",
    "        torch.save(logits, out_fn)\n",
    "    \n",
    "    return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ab86c",
   "metadata": {},
   "source": [
    "## Loading data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2cd29e",
   "metadata": {},
   "source": [
    "### Set task parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0d975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helsinki-prosody_scratch-gpt2_joint-loss_prosody-embed\n"
     ]
    }
   ],
   "source": [
    "from src.utils.text_processing import python_remove_punctuation\n",
    "\n",
    "\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'code/modeling/joint-clm-prosody/')\n",
    "EXPERIMENT = [\"experiment=helsinki_prosody.yaml\"]\n",
    "\n",
    "task = 'black'\n",
    "window_size = 25\n",
    "top_n = [1]\n",
    "\n",
    "model_name = 'helsinki-prosody_scratch-gpt2_joint-loss_prosody-embed'\n",
    "ckpt_path = os.path.join(MODELS_DIR, 'logs/train/runs/2024-09-12/07-41-15/checkpoints/epoch_014.ckpt')\n",
    "overrides = EXPERIMENT + [f\"model.loss_mode=joint\", f\"model.pretrained=False\", f\"model.use_prosody_embeddings=True\"]\n",
    "\n",
    "modeling_dir = os.path.join(BASE_DIR, 'code/modeling/joint-clm-prosody/')\n",
    "results_dir = os.path.join(BASE_DIR, 'derivatives/joint-prosody-clm/')\n",
    "\n",
    "pyrootutils.setup_root(modeling_dir, indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "print (f'{model_name}', flush=True)\n",
    "    \n",
    "####################################\n",
    "### Initialize hydra config file ###\n",
    "####################################\n",
    "\n",
    "# Get relative path --> path for initialize needs to be relative\n",
    "config_path = os.path.join(os.path.relpath(modeling_dir, os.getcwd()), 'configs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "807a2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # out_dir = os.path.join(BASE_DIR, 'derivatives/model-predictions', p.task, p.model_name, f'window-size-{p.window_size}')\n",
    "    # logits_dir = os.path.join(SCRATCH_DIR, 'derivatives/model-predictions', p.task, p.model_name, f'window-size-{p.window_size}', 'logits')\n",
    "\n",
    "    # utils.attempt_makedirs(out_dir)\n",
    "    # utils.attempt_makedirs(logits_dir)\n",
    "\n",
    "task = 'black'\n",
    "\n",
    "# Define column names for prosody data --> remove non-words\n",
    "prosody_columns = ['stim', 'start', 'end', 'word', 'prominence', 'boundary']\n",
    "\n",
    "df_prosody = pd.read_csv(os.path.join(BASE_DIR, 'stimuli/prosody/', f'{task}.prom'), sep='\\t', names=prosody_columns)\n",
    "df_prosody = df_prosody[~df_prosody['word'].isin(analysis.REMOVE_WORDS)].reset_index(drop=True) # remove non-words\n",
    "\n",
    "df_preproc = pd.read_csv(os.path.join(BASE_DIR, 'stimuli/preprocessed/', task, f'{task}_transcript-preprocessed.csv'))\n",
    "df_preproc = df_preproc.rename(columns={'Word_Written': 'word', 'Punctuation': 'punctuation'})\n",
    "\n",
    "# make sure the words match\n",
    "words_preproc = df_preproc['word'].str.lower().apply(python_remove_punctuation)\n",
    "words_prosody =  df_prosody['word'].str.lower().apply(python_remove_punctuation)\n",
    "\n",
    "assert all(words_preproc == words_prosody)\n",
    "\n",
    "# if it matches we can add in prosody as a column\n",
    "df_preproc['prominence'] = df_prosody['prominence']\n",
    "df_preproc.loc[df_preproc['prominence'] < 0, 'prominence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36da06db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Case</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS_Definition</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>Stop_Word</th>\n",
       "      <th>Word_Vocab</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Named_Entity</th>\n",
       "      <th>NWP_Candidate</th>\n",
       "      <th>prominence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So</td>\n",
       "      <td>success</td>\n",
       "      <td>RB</td>\n",
       "      <td>adverb</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>So</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun, personal</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>success</td>\n",
       "      <td>VBD</td>\n",
       "      <td>verb, past tense</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>was</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>success</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>a</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>junior</td>\n",
       "      <td>success</td>\n",
       "      <td>JJ</td>\n",
       "      <td>adjective or numeral, ordinal</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>junior</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>what</td>\n",
       "      <td>success</td>\n",
       "      <td>WP</td>\n",
       "      <td>WH-pronoun</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>what</td>\n",
       "      <td>790.779999</td>\n",
       "      <td>791.009999</td>\n",
       "      <td>0.23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>I</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun, personal</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>791.010000</td>\n",
       "      <td>791.130000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>do</td>\n",
       "      <td>success</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb, present tense, not 3rd person singular</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>do</td>\n",
       "      <td>791.129999</td>\n",
       "      <td>791.469999</td>\n",
       "      <td>0.34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>Thank</td>\n",
       "      <td>success</td>\n",
       "      <td>VB</td>\n",
       "      <td>verb, base form</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>Thank</td>\n",
       "      <td>792.350000</td>\n",
       "      <td>792.610000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>you</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun, personal</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>you</td>\n",
       "      <td>799.960000</td>\n",
       "      <td>799.980000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     Case  POS                                POS_Definition  \\\n",
       "0         So  success   RB                                        adverb   \n",
       "1          I  success  PRP                             pronoun, personal   \n",
       "2        was  success  VBD                              verb, past tense   \n",
       "3          a  success   DT                                    determiner   \n",
       "4     junior  success   JJ                 adjective or numeral, ordinal   \n",
       "...      ...      ...  ...                                           ...   \n",
       "1536    what  success   WP                                    WH-pronoun   \n",
       "1537       I  success  PRP                             pronoun, personal   \n",
       "1538      do  success  VBP  verb, present tense, not 3rd person singular   \n",
       "1539   Thank  success   VB                               verb, base form   \n",
       "1540     you  success  PRP                             pronoun, personal   \n",
       "\n",
       "     punctuation  Stop_Word Word_Vocab       Onset      Offset  Duration  \\\n",
       "0                      True         So    0.240000    0.630000      0.39   \n",
       "1                      True          I    0.680000    1.260000      0.58   \n",
       "2                      True        was    1.960000    2.300000      0.34   \n",
       "3                      True          a    2.300000    2.450000      0.15   \n",
       "4                     False     junior    2.460000    3.140000      0.68   \n",
       "...          ...        ...        ...         ...         ...       ...   \n",
       "1536                   True       what  790.779999  791.009999      0.23   \n",
       "1537                   True          I  791.010000  791.130000      0.12   \n",
       "1538          .        True         do  791.129999  791.469999      0.34   \n",
       "1539                  False      Thank  792.350000  792.610000      0.26   \n",
       "1540           .       True        you  799.960000  799.980000      0.02   \n",
       "\n",
       "      Named_Entity  NWP_Candidate  prominence  \n",
       "0            False          False       1.016  \n",
       "1            False          False       3.303  \n",
       "2            False          False       1.032  \n",
       "3            False          False       0.452  \n",
       "4            False           True       1.378  \n",
       "...            ...            ...         ...  \n",
       "1536         False          False       0.066  \n",
       "1537         False          False       0.656  \n",
       "1538         False          False       0.000  \n",
       "1539         False           True       0.599  \n",
       "1540         False          False       1.049  \n",
       "\n",
       "[1541 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35adcdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Huggingface model.\n",
      "Initializing new model\n",
      "Using joint loss\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "cfg, tokenizer, model = load_model(config_path, ckpt_path, overrides)\n",
    "\n",
    "print (f'Model loaded', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e4f31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the first word to the dataframe --> we don't run NWP on this as there is no context\n",
    "# to condition, nor do we have humans do it\n",
    "df = analysis.create_results_dataframe()\n",
    "first_word = df_preproc.iloc[0]['word'].lower()\n",
    "df.loc[len(df)] = {'ground_truth_word': first_word}\n",
    "\n",
    "# set up variables to be used in the loop\n",
    "df_stack = {str(n): [df] for n in top_n}\n",
    "prev_probs = None\n",
    "\n",
    "# create a list of indices that we will iterate through to sample the transcript\n",
    "segments = analysis.get_segment_indices(n_words=len(df_preproc), window_size=window_size)[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ce5d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 1540/1540 [00:03<00:00, 481.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 3/1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# also keep track of the current ground truth word\n",
    "inputs, labels = zip(*[analysis.transcript_to_input(df_preproc, segment, add_punctuation=True) for segment in segments])\n",
    "\n",
    "dataset = TokenTaggingDataset(inputs, labels, tokenizer, model_name='gpt2', remove_punctuation=False, buffer_missing_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770fef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosody_analysis_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6731f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.data.components.collators import collate_fn, encode_and_pad_batch\n",
    "\n",
    "def collate(batch):\n",
    "    return collate_fn(batch, tokenizer.pad_token_id)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f6f76bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "\n",
    "    ground_truth_index = segments[i][-1] + 1\n",
    "    ground_truth_word = df_preproc.loc[ground_truth_index, 'word']\n",
    "\n",
    "    # we've buffered the samples and we're gonna wait for the real one\n",
    "    if not any(batch['input_text']):\n",
    "        continue\n",
    "\n",
    "    probs = get_prosody_model_predictions(batch, model)\n",
    "\n",
    "    sys.exit(0)\n",
    "\n",
    "    if i == 6:\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56356c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove.42B.300d from saved .bin file.\n",
      "Loading word2vec from saved .bin file.\n",
      "Loading fasttext from saved .bin file.\n"
     ]
    }
   ],
   "source": [
    "word_models = {model_name: utils.load_word_model(model_name=model_name, cache_dir=CACHE_DIR) for model_name in utils.WORD_MODELS.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ea4972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_stats = analysis.get_model_statistics(ground_truth_word, probs, tokenizer, prev_probs=prev_probs, word_models=word_models, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44d13f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth_word</th>\n",
       "      <th>ground_truth_prob</th>\n",
       "      <th>top_n_predictions</th>\n",
       "      <th>top_prob</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>glove_avg_accuracy</th>\n",
       "      <th>glove_max_accuracy</th>\n",
       "      <th>glove_prediction_density</th>\n",
       "      <th>word2vec_avg_accuracy</th>\n",
       "      <th>word2vec_max_accuracy</th>\n",
       "      <th>word2vec_prediction_density</th>\n",
       "      <th>fasttext_avg_accuracy</th>\n",
       "      <th>fasttext_max_accuracy</th>\n",
       "      <th>fasttext_prediction_density</th>\n",
       "      <th>entropy</th>\n",
       "      <th>relative_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[and]</td>\n",
       "      <td>0.122386</td>\n",
       "      <td>False</td>\n",
       "      <td>0.650876</td>\n",
       "      <td>0.650876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373871</td>\n",
       "      <td>0.373871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.012061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ground_truth_word  ground_truth_prob top_n_predictions  top_prob  \\\n",
       "0                in            0.00001             [and]  0.122386   \n",
       "\n",
       "   binary_accuracy  glove_avg_accuracy  glove_max_accuracy  \\\n",
       "0            False            0.650876            0.650876   \n",
       "\n",
       "   glove_prediction_density  word2vec_avg_accuracy  word2vec_max_accuracy  \\\n",
       "0                       NaN                    NaN                    NaN   \n",
       "\n",
       "   word2vec_prediction_density  fasttext_avg_accuracy  fasttext_max_accuracy  \\\n",
       "0                          NaN               0.373871               0.373871   \n",
       "\n",
       "   fasttext_prediction_density   entropy  relative_entropy  \n",
       "0                          NaN  4.012061               NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5f18706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0969e-08, 5.5014e-08, 6.0451e-08,  ..., 3.9684e-08, 1.0778e-05,\n",
       "         9.3119e-08]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = get_prosody_model_predictions(batch, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "49797230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probability of the logits\n",
    "probs = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "db212f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' great']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([probs.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "666954c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': ['Where I grew up in the South, there was a'],\n",
       " 'tokenized_text': [['Where',\n",
       "   'ĠI',\n",
       "   'Ġgrew',\n",
       "   'Ġup',\n",
       "   'Ġin',\n",
       "   'Ġthe',\n",
       "   'ĠSouth',\n",
       "   ',',\n",
       "   'Ġthere',\n",
       "   'Ġwas',\n",
       "   'Ġa']],\n",
       " 'original_labels': [[0.232,\n",
       "   1.302,\n",
       "   0.202,\n",
       "   0.849,\n",
       "   0.108,\n",
       "   0.0,\n",
       "   1.245,\n",
       "   None,\n",
       "   1.54,\n",
       "   0.072,\n",
       "   0.0]],\n",
       " 'tokenized_labels': tensor([[ 2.3200e-01,  1.3020e+00,  2.0200e-01,  8.4900e-01,  1.0800e-01,\n",
       "           0.0000e+00,  1.2450e+00, -9.9900e+02,  1.5400e+00,  7.2000e-02,\n",
       "           0.0000e+00]]),\n",
       " 'input_ids': tensor([[8496,  314, 6348,  510,  287,  262, 2520,   11,  612,  373,  257]]),\n",
       " 'loss_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'word_to_tokens': [['Where',\n",
       "   [8496],\n",
       "   ' I',\n",
       "   [314],\n",
       "   ' grew',\n",
       "   [6348],\n",
       "   ' up',\n",
       "   [510],\n",
       "   ' in',\n",
       "   [287],\n",
       "   ' the',\n",
       "   [262],\n",
       "   ' South',\n",
       "   [2520],\n",
       "   ',',\n",
       "   [11],\n",
       "   ' there',\n",
       "   [612],\n",
       "   ' was',\n",
       "   [373],\n",
       "   ' a',\n",
       "   [257]]]}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e08eabc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[[-6.2675, -7.2080, -5.4195,  ..., -6.9068,  0.7339, -5.1757],\n",
       "          [-5.4105, -6.4297, -4.1599,  ..., -6.3006,  3.3910, -4.6908],\n",
       "          [-6.6323, -6.7363, -4.4950,  ..., -6.3908, -1.0139, -6.0770],\n",
       "          [-6.8450, -7.3865, -5.5411,  ..., -6.9936,  0.0876, -5.6336]]]),\n",
       " 'preds': tensor([[0.8823, 0.9829, 1.3903, 0.3805]]),\n",
       " 'mu': tensor([[0.3559, 0.5888, 0.7342, 0.3470]]),\n",
       " 'var': tensor([[0.4033, 0.5991, 0.5281, 0.9121]]),\n",
       " 'loss': tensor(6.6485),\n",
       " 'clm_loss': tensor(5.5781),\n",
       " 'prosody_loss': tensor(1.0704)}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    logits = model(**tokens).logits[:, -1, :]\n",
    "\n",
    "\n",
    "\n",
    "# if we provide we save logits out\n",
    "if out_fn:\n",
    "    torch.save(logits, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85a48520",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# we don't need to get the last word\n",
    "for i, segment in enumerate(segments):\n",
    "\n",
    "    ground_truth_index = segment[-1] + 1\n",
    "    ground_truth_word = df_preproc.loc[ground_truth_index, 'word']\n",
    "    \n",
    "    # also keep track of the current ground truth word\n",
    "    inputs, prosody = transcript_to_input(df_preproc, segment, add_punctuation=True)\n",
    "\n",
    "    sys.exit(0)\t\t\n",
    "\n",
    "    # run the inputs through the model, get predictive distribution, and save out the logits\n",
    "    # if the next word is a prediction word save logits\n",
    "    if df_preproc.loc[ground_truth_index, 'NWP_Candidate']: # and p.model_name == 'gpt2-xl':\n",
    "        logits_fn = os.path.join(logits_dir, f'{p.task}_window-size-{p.window_size}_logits-{str(ground_truth_index).zfill(5)}.pt')\n",
    "    else:\n",
    "        logits_fn = None\n",
    "\n",
    "    probs = get_prosody_model_predictions([inputs], model, tokenizer, out_fn=logits_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6cf6cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
