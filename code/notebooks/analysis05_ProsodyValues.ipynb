{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a528bc23-430b-40e7-b7ad-7171c833ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 09:35:04.879289: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-08 09:35:04.879361: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-08 09:35:04.885404: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-08 09:35:05.483506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-08 09:35:22.275049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "import os, sys, glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "import matplotlib.colors as clr\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/utils/')\n",
    "\n",
    "from config import *\n",
    "\n",
    "import analysis_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196e274a-f622-47ba-85be-28d08d74f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = ['black', 'wheretheressmoke', 'howtodraw']\n",
    "\n",
    "gentle_dir = os.path.join(BASE_DIR, 'stimuli/gentle')\n",
    "results_dir = os.path.join(BASE_DIR, 'derivatives/results/behavioral/')\n",
    "preproc_dir = os.path.join(BASE_DIR, 'stimuli/preprocessed')\n",
    "prosody_dir = os.path.join(BASE_DIR, 'stimuli/prosody')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444fda1-a358-44e1-8883-2eab768a2fcc",
   "metadata": {},
   "source": [
    "## Load all task selected words and prosody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e56f6e-d3a3-47d7-b9ec-3c027e7c7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_WORDS = [\"sp\", \"br\", \"lg\", \"cg\", \"ls\", \"ns\", \"sl\", \"ig\", \"{sp}\", \"{br}\", \"{lg}\", \n",
    " \"{cg}\", \"{ls}\", \"{ns}\", \"{sl}\", \"{ig}\", \"SP\", \"BR\", \"LG\", \"CG\", \"LS\",\n",
    " \"NS\", \"SL\", \"IG\", \"{SP}\", \"{BR}\", \"{LG}\", \"{CG}\", \"{LS}\", \"{NS}\", \"{SL}\", \"{IG}\", \"pause\"]\n",
    "\n",
    "def get_prosody_metrics(index, prosody_raw, boundary_raw, n_prev):\n",
    "\n",
    "    columns = ['prominence_mean', 'prominence_std', 'boundary_mean', 'boundary_std']\n",
    "    columns = [f'{col}_nprev-{n_prev}' for col in columns]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    if (index - n_prev >= 0):\n",
    "        n_prev_prosody = prosody_raw[index:index+n_prev]\n",
    "        n_prev_boundary = boundary_raw[index:index+n_prev]\n",
    "\n",
    "        # get mean and std of n_prev words prosody\n",
    "        prosody_mean = n_prev_prosody.mean()\n",
    "        prosody_std = n_prev_prosody.std()\n",
    "\n",
    "        # relative_prosody = prosody_raw[idx+n_prev] - prosody_mean\n",
    "        # relative_prosody_norm = relative_prosody / prosody_std\n",
    "\n",
    "        # # get mean and std of n_prev prosodic boundaries\n",
    "        # boundary_mean = n_prev_boundary.mean()\n",
    "        # boundary_std = n_prev_boundary.std()\n",
    "\n",
    "def calculate_prosody_metrics(df_prosody, n_prev=3, remove_characters=[], zscore=False):\n",
    "    # Extract raw values\n",
    "    prosody_raw = df_prosody['prominence'].to_numpy()\n",
    "    boundary_raw = df_prosody['boundary'].to_numpy()\n",
    "\n",
    "    if zscore:\n",
    "        prosody_raw = stats.zscore(prosody_raw)\n",
    "    \n",
    "    # get mean of past n_words\n",
    "    indices = np.arange(len(prosody_raw))\n",
    "    # start_idxs = indices - n_prev\n",
    "\n",
    "    # go through the past x words \n",
    "    all_items = []\n",
    "    \n",
    "    for idx in tqdm(indices):\n",
    "\n",
    "\n",
    "        # get the prosody of the n_prev words\n",
    "        if idx >= 0:\n",
    "            n_prev_prosody = prosody_raw[idx:idx+n_prev]\n",
    "            n_prev_boundary = boundary_raw[idx:idx+n_prev]\n",
    "            \n",
    "            # get mean and std of n_prev words prosody\n",
    "            prosody_mean = n_prev_prosody.mean()\n",
    "            prosody_std = n_prev_prosody.std()\n",
    "\n",
    "            relative_prosody = prosody_raw[idx+n_prev] - prosody_mean\n",
    "            relative_prosody_norm = relative_prosody / prosody_std\n",
    "\n",
    "            # get mean and std of n_prev prosodic boundaries\n",
    "            boundary_mean = n_prev_boundary.mean()\n",
    "            boundary_std = n_prev_boundary.std()\n",
    "            \n",
    "        else:\n",
    "            prosody_mean = prosody_std = relative_prosody = relative_prosody_norm = np.nan\n",
    "            boundary_mean = boundary_std = np.nan\n",
    "        \n",
    "        all_items.append(\n",
    "            (prosody_mean, prosody_std, relative_prosody, relative_prosody_norm, boundary_mean, boundary_std)\n",
    "        )\n",
    "\n",
    "    prosody_mean, prosody_std, relative_prosody, relative_prosody_norm, boundary_mean, boundary_std = zip(*all_items)\n",
    "\n",
    "    df_prosody['prominence_mean'] = prosody_mean\n",
    "    df_prosody['prominence_std'] = prosody_std\n",
    "    df_prosody['relative_prominence'] = relative_prosody\n",
    "    df_prosody['relative_prominence_norm'] = relative_prosody_norm\n",
    "    df_prosody['boundary_mean'] = boundary_mean\n",
    "    df_prosody['boundary_std'] = boundary_std\n",
    "\n",
    "    # remove non-words\n",
    "    df_prosody = df_prosody[~df_prosody['word'].isin(remove_characters)].reset_index(drop=True)\n",
    "    \n",
    "    return df_prosody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c1fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'black'\n",
    "stim_dir = os.path.join(BASE_DIR, 'stimuli/')\n",
    "\n",
    "###############################################\n",
    "######## Load prosody data and process ########\n",
    "###############################################\n",
    "\n",
    "# Define column names for prosody data\n",
    "prosody_columns = ['stim', 'start', 'end', 'word', 'prominence', 'boundary']\n",
    "\n",
    "# Process prosody -- calculate the average prosody over the past n words\n",
    "df_prosody = pd.read_csv(os.path.join(stim_dir, 'prosody', f'{task}.prom'), sep='\\t', names=prosody_columns)\n",
    "# df_prosody = calculate_prosody_metrics(df_prosody, n_prev=p.n_words, remove_characters=REMOVE_WORDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
