{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0196f0-7320-4327-83ca-f2ccdc3d0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /dartfs/rc/lab/F/FinnLab/tommy/models/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/utils/')\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/')\n",
    "\n",
    "from config import *\n",
    "# from src.data.prominence_regression_datamodule import ProminenceRegressionDataModule\n",
    "# from src.models.joint_clm_prosody import ProsodyCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f7c51",
   "metadata": {},
   "source": [
    "## Try transformers WhisperDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17019d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m assistant_model \u001b[38;5;241m=\u001b[39m WhisperForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistil-whisper/distil-large-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf-internal-testing/librispeech_asr_dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[1;32m     14\u001b[0m     sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39msample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,  return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m ) \u001b[38;5;66;03m#.input_features\u001b[39;00m\n\u001b[1;32m     17\u001b[0m predicted_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_features, assistant_model\u001b[38;5;241m=\u001b[39massistant_model)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/arrow_dataset.py:2872\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/arrow_dataset.py:2857\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2855\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2856\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2857\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/formatting/formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/formatting/formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/formatting/formatting.py:444\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/formatting/formatting.py:222\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/features/features.py:2039\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m \n\u001b[1;32m   2027\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m-> 2039\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2042\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2043\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2044\u001b[0m         )\n\u001b[1;32m   2045\u001b[0m     }\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/features/features.py:1400\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1400\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/datasets/features/audio.py:191\u001b[0m, in \u001b[0;36mAudio.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    189\u001b[0m array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmono:\n\u001b[0;32m--> 191\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_mono\u001b[49m(array)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate \u001b[38;5;241m!=\u001b[39m sampling_rate:\n\u001b[1;32m    193\u001b[0m     array \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mresample(array, orig_sr\u001b[38;5;241m=\u001b[39msampling_rate, target_sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/lazy_loader/__init__.py:83\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     81\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[0;32m---> 83\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/lazy_loader/__init__.py:82\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m     81\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 82\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/librosa/core/audio.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoxr\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlazy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit, stencil, guvectorize\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_fftlib\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frames_to_samples, time_to_samples\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/__init__.py:92\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Re-export decorators\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (cfunc, jit, njit, stencil,\n\u001b[1;32m     93\u001b[0m                                    jit_module)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Re-export vectorize decorators and the thread layer querying function\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (vectorize, guvectorize, threading_layer,\n\u001b[1;32m     97\u001b[0m                             get_num_threads, set_num_threads,\n\u001b[1;32m     98\u001b[0m                             set_parallel_chunksize, get_parallel_chunksize,\n\u001b[1;32m     99\u001b[0m                             get_thread_id)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/core/decorators.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeprecationError, NumbaDeprecationWarning\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstencils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstencil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stencil\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, extending, sigutils, registry\n\u001b[1;32m     15\u001b[0m _logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/stencils/stencil.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllvmlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ir \u001b[38;5;28;01mas\u001b[39;00m lir\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types, typing, utils, ir, config, ir_utils, registry\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemplates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (CallableTemplate, signature,\n\u001b[1;32m     13\u001b[0m                                          infer_global, AbstractTemplate)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lower_builtin\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/core/registry.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m threadsafe_cached_property \u001b[38;5;28;01mas\u001b[39;00m cached_property\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdescriptors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetDescriptor\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, typing, dispatcher, cpu\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Default CPU target descriptors\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCPUTarget\u001b[39;00m(TargetDescriptor):\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/core/dispatcher.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstractmethod\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _dispatcher\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     utils, types, errors, typing, serialize, config, compiler, sigutils\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler_lock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m global_compiler_lock\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypeconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_type_manager\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/numba/core/compiler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m event\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (utils, errors, interpreter, bytecode, postproc, config,\n\u001b[1;32m      7\u001b[0m                         callconv, cpu)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparfors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparfor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParforDiagnostics\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompilerError\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForCausalLM, WhisperForConditionalGeneration, WhisperProcessor\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
    "\n",
    "assistant_model = WhisperForCausalLM.from_pretrained(\"distil-whisper/distil-large-v2\")\n",
    "\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "sample = ds[0][\"audio\"]\n",
    "inputs = processor(\n",
    "    sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\",  return_attention_mask=True\n",
    ") #.input_features\n",
    "\n",
    "predicted_ids = model.generate(input_features, assistant_model=assistant_model)\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8437a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\n",
    "    \"openai/whisper-small\", \n",
    "    language=\"english\", \n",
    "    bos_token=None,\n",
    "    unk_token=None,\n",
    ")\n",
    "\n",
    "tokens = tokenizer(ds[0]['text'])\n",
    "tokenizer.decode(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45c5ca",
   "metadata": {},
   "source": [
    "### Test EnCodec for audio tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "817e3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentError\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import os, sys\n",
    "import json\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "from lightning import LightningDataModule\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCTC\n",
    "\n",
    "\n",
    "class AudioTextDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        audio_dir: str,\n",
    "        textgrid_dir: str,\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "        # model_name: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.audio_dir = audio_dir\n",
    "        self.textgrid_dir = textgrid_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\":\n",
    "            self.train_texts, self.val_texts, self.train_audio_tokens, self.val_audio_tokens = self._load_data(\"train\")\n",
    "        if stage == \"test\":\n",
    "            self.test_texts, self.test_audio_tokens = self._load_data(\"test\")\n",
    "\n",
    "    def _load_data(self, split: str):\n",
    "        texts = []\n",
    "        audio_tokens = []\n",
    "        split_dir = os.path.join(self.data_dir, split)\n",
    "        for file_name in os.listdir(split_dir):\n",
    "            textgrid_path = os.path.join(self.textgrid_dir, file_name.replace(\".wav\", \".TextGrid\"))\n",
    "            audio_path = os.path.join(self.audio_dir, file_name)\n",
    "            words = parse_textgrid(textgrid_path)\n",
    "            waveform, sample_rate = load_audio(audio_path)\n",
    "\n",
    "            return words, waveform, sample_rate\n",
    "            for word in words:\n",
    "                segment = extract_word_segment(waveform, sample_rate, word[\"start_time\"], word[\"end_time\"])\n",
    "                token = encode_segment(segment, self.model, self.feature_extractor)\n",
    "                texts.append(word[\"text\"])\n",
    "                audio_tokens.append(token)\n",
    "        return texts, audio_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959a86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'gigaspeech'\n",
    "split = 'test'\n",
    "text_model_name = 'gpt2'\n",
    "audio_model_name = 'wav2vec2'\n",
    "\n",
    "file_paths = glob.glob(os.path.join(DATASETS_DIR, DATASET, 's/textgrids/test/', '*'))\n",
    "file_name = os.path.basename(file_paths[0])\n",
    "\n",
    "audio_dir = os.path.join(DATASETS_DIR, DATASET,  's/audio')\n",
    "textgrid_dir = os.path.join(DATASETS_DIR, DATASET, 's/textgrids')\n",
    "cache_dir = audio_dir.replace(DATASETS_DIR, SCRATCH_DIR)\n",
    "\n",
    "textgrid_path = os.path.join(textgrid_dir, split, file_name.replace(\".wav\", \".TextGrid\"))\n",
    "audio_path = os.path.join(audio_dir, split, file_name.replace('.TextGrid', '.wav'))\n",
    "# words = parse_textgrid(textgrid_path)\n",
    "# waveform, sample_rate = load_audio(audio_path)\n",
    "\n",
    "# # Audio tokenization process\n",
    "# processor = AutoProcessor.from_pretrained(audio_models[audio_model_name])\n",
    "# audio_model = AutoModel.from_pretrained(audio_models[audio_model_name])\n",
    "\n",
    "# # Text tokenization process\n",
    "# text_tokenizer = AutoTokenizer.from_pretrained(text_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35aee2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data.components.audio_text_dataset import AudioTextDataset\n",
    "\n",
    "dataset = AudioTextDataset(audio_dir, textgrid_dir, cache_dir=cache_dir, split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1eb271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file /dartfs/rc/lab/F/FinnLab/datasets/gigaspeech/s/audio/test/YOU1000000102_S0000229.wav: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n"
     ]
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64733d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46998044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/src/data/audio_text_dataset.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  else:\n",
      " 14%|█▍        | 14/100 [00:00<00:01, 66.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:00<00:01, 65.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:00<00:01, 63.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n",
      "Loading from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:03<00:05, 11.83it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[0;32m----> 4\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/src/data/audio_text_dataset.py:59\u001b[0m, in \u001b[0;36mAudioTextDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m words:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/src/data/audio_text_dataset.py:106\u001b[0m, in \u001b[0;36mAudioTextDataset._process_inputs\u001b[0;34m(self, words, waveform, sample_rate, cache_path)\u001b[0m\n\u001b[1;32m    100\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_model\u001b[38;5;241m.\u001b[39m_get_feature_vector_attention_mask(\n\u001b[1;32m    101\u001b[0m     audio_inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m    102\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Perform pooling over the embeddings while accounting for attention mask\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m audio_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpool_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Save the audio inputs to cache if a cache path is provided\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_path:\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/src/data/audio_text_dataset.py:247\u001b[0m, in \u001b[0;36mpool_embeddings\u001b[0;34m(embeddings, attention_mask, pool_type, normalize)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool_type must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m--> 247\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mnormalize(pooled, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pooled\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    x = dataset.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "9ed47a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3ff7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b3390429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107597"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "90faeb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bda94df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:95\u001b[0m, in \u001b[0;36mWav2Vec2Processor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:199\u001b[0m, in \u001b[0;36mWav2Vec2FeatureExtractor.__call__\u001b[0;34m(self, raw_speech, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors, sampling_rate, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# convert into correct format for padding\u001b[39;00m\n\u001b[1;32m    197\u001b[0m encoded_inputs \u001b[38;5;241m=\u001b[39m BatchFeature({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: raw_speech})\n\u001b[0;32m--> 199\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# convert input values to correct format\u001b[39;00m\n\u001b[1;32m    209\u001b[0m input_values \u001b[38;5;241m=\u001b[39m padded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/feature_extraction_sequence_utils.py:179\u001b[0m, in \u001b[0;36mSequenceFeatureExtractor.pad\u001b[0;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[0m\n\u001b[1;32m    177\u001b[0m         processed_features[key] \u001b[38;5;241m=\u001b[39m to_numpy(value)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         processed_features[key] \u001b[38;5;241m=\u001b[39m [\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Convert padding_strategy in PaddingStrategy\u001b[39;00m\n\u001b[1;32m    182\u001b[0m padding_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_strategies(padding\u001b[38;5;241m=\u001b[39mpadding, max_length\u001b[38;5;241m=\u001b[39mmax_length)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/utils/generic.py:299\u001b[0m, in \u001b[0;36mto_numpy\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: to_numpy(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "processor(segments, sampling_rate=sample_rate, padding=True, return_attention_mask=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d6ba000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments = []\n",
    "\n",
    "text_tokens = text_tokenizer(word['text'], return_tensors='pt')\n",
    "\n",
    "for word in words:\n",
    "\n",
    "    ratios = torch.tensor([len(text_tokenizer.decode(x)) for x in text_tokens['input_ids'].T])\n",
    "    ratios = ratios / ratios.sum()\n",
    "\n",
    "    word_segments = extract_word_segment(waveform, sample_rate, word[\"start\"], word[\"end\"], ratios=ratios)\n",
    "    all_segments.extend(word_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7e62c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join([word['text'] for word in words])\n",
    "text_tokenizer = AutoTokenizer.from_pretrained(text_model_name,  use_fast=True) #add_prefix_space=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fdd933d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words\n",
    "tokens = text_tokenizer(text)\n",
    "\n",
    "# Find number of counts for each word (e.g., number of tokens each word is broken into)\n",
    "word_ids, token_counts = np.unique(tokens.word_ids(), return_counts=True)\n",
    "\n",
    "assert (len(word_ids) == len(words))\n",
    "\n",
    "for word, idx, n_tokens in zip(words, word_ids, token_counts):\n",
    "\n",
    "    # If there is more than one token, we need to divide the audio into segments\n",
    "    if n_tokens > 1:\n",
    "        ratios = torch.tensor([len(x) for x in text_tokenizer.batch_decode(tokens['input_ids'][idx:idx+n_tokens])])\n",
    "        ratios = ratios / ratios.sum()\n",
    "        word_segments = extract_word_segment(waveform, sample_rate, word[\"start\"], word[\"end\"], ratios=ratios)\n",
    "    else:\n",
    "        word_segments = extract_word_segment(waveform, sample_rate, word[\"start\"], word[\"end\"])\n",
    "\n",
    "    all_segments.extend(word_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8a5291c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_inputs(words, waveform, sample_rate):\n",
    "\n",
    "    # Join the words together into a sentence\n",
    "    text = \" \".join([word['text'] for word in words])\n",
    "\n",
    "    # Tokenize the words\n",
    "    text_tokens = text_tokenizer(text)\n",
    "\n",
    "    # Find number of counts for each word (e.g., number of tokens each word is broken into)\n",
    "    word_ids, token_counts = np.unique(text_tokens.word_ids(), return_counts=True)\n",
    "\n",
    "    assert (len(word_ids) == len(words))\n",
    "\n",
    "    segments = []\n",
    "    \n",
    "    # Ensure we get the right number of audio segments for each word (e.g., for each token)\n",
    "    for word, idx, n_tokens in zip(words, word_ids, token_counts):\n",
    "\n",
    "        # If there is more than one token, we need to divide the audio into segments\n",
    "        if n_tokens > 1:\n",
    "            ratios = torch.tensor([len(x) for x in text_tokenizer.batch_decode(text_tokens['input_ids'][idx:idx+n_tokens])])\n",
    "            ratios = ratios / ratios.sum()\n",
    "            word_segments = extract_word_segment(waveform, sample_rate, word[\"start\"], word[\"end\"], ratios=ratios)\n",
    "        else:\n",
    "            word_segments = extract_word_segment(waveform, sample_rate, word[\"start\"], word[\"end\"])\n",
    "\n",
    "        segments.extend(word_segments)\n",
    "    \n",
    "    # Process all segments simultaneously\n",
    "    features =  processor(segments, sampling_rate=sample_rate, padding=True, return_attention_mask=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_inputs = audio_model(**features).last_hidden_state\n",
    "\n",
    "    # Get the attention mask for the hidden states\n",
    "    attention_mask = audio_model._get_feature_vector_attention_mask(\n",
    "        audio_inputs.shape[1], \n",
    "        features['attention_mask']\n",
    "    )\n",
    "\n",
    "    # Perform pooling over the embeddings while accounting for attention mask\n",
    "    audio_inputs = pool_embeddings(audio_inputs, attention_mask)\n",
    "\n",
    "    data = {\n",
    "        'text': text,\n",
    "        'text_tokens': text_tokens['input_ids'],\n",
    "        'text_attention_mask': text_tokens['attention_mask'],\n",
    "        'audio_inputs': audio_inputs\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7ddebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _process_inputs(words, waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "41f1a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['text_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f601e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fd462e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont\n",
      " let\n",
      " the\n",
      " noise\n",
      " of\n",
      " others\n",
      " opinions\n",
      " drown\n",
      " out\n",
      " your\n",
      " own\n",
      " inner\n",
      " voice\n",
      " and\n",
      " most\n",
      " important\n",
      " have\n",
      " the\n",
      " courage\n",
      " to\n",
      " follow\n",
      " your\n",
      " heart\n",
      " and\n",
      " intuition\n"
     ]
    }
   ],
   "source": [
    "for x in tokens['offset_mapping']:\n",
    "    print (text[slice(*x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedf712",
   "metadata": {},
   "source": [
    "### Run for padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c3352209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# segs = {'input_values': seg.squeeze() for seg in segments}\n",
    "audio_model_name = \"facebook/wav2vec2-large-960h-lv60\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(audio_model_name)\n",
    "audio_model = AutoModel.from_pretrained(audio_model_name)\n",
    "\n",
    "# Pad the batch\n",
    "padded_features = processor(all_segments, sampling_rate=sample_rate, padding=True, return_attention_mask=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outs = audio_model(**padded_features).last_hidden_state\n",
    "\n",
    "attention_mask = audio_model._get_feature_vector_attention_mask(\n",
    "    outs.shape[1], \n",
    "    padded_features['attention_mask']\n",
    ")\n",
    "\n",
    "x = pool_embeddings(outs, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "87100d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1024])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7ad478dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.last_hidden_state.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4a92ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = audio_model._get_feature_vector_attention_mask(\n",
    "    outs.last_hidden_state.shape[1], \n",
    "    padded_features['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7f6aa173",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool_embeddings(outs.last_hidden_state, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bcd0abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(corrected_padded_features[0][:10], ctc_no_pad_features.hidden_states[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1edce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_no_pad_features = processor(segments[:1], sampling_rate=sample_rate, padding=True, return_attention_mask=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    ctc_no_pad_features = model(**ctc_no_pad_features, output_hidden_states=True) #.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f10300f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0346, -0.1451,  0.1917,  ...,  0.1091, -0.0441,  0.1799],\n",
       "         [ 0.0887, -0.0933,  0.1064,  ...,  0.1275, -0.0357,  0.2027],\n",
       "         [-0.0149, -0.0881,  0.2005,  ...,  0.1454, -0.0135,  0.2051],\n",
       "         ...,\n",
       "         [-0.0071, -0.1177, -0.0245,  ...,  0.0899, -0.0504,  0.2034],\n",
       "         [ 0.0589, -0.1012, -0.0130,  ...,  0.1264,  0.0095,  0.2047],\n",
       "         [ 0.1115, -0.1436,  0.0245,  ...,  0.0926, -0.0243,  0.2036]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_no_pad_features.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cacea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-960h-lv60-self were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\") #.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2904b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pad_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c882073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0c60092b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc5d156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aouts = audio_model(\n",
    "    input_values=test_features['input_values'],\n",
    "    attention_mask=test_features['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e9573dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d37a5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "\n",
    "a = pool_embeddings(all_inputs[idx])\n",
    "b = pool_embeddings(outs.last_hidden_state[idx].unsqueeze(0), mask[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "418fdd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3895e-02, -1.4980e-03,  3.9707e-03, -7.2643e-03, -3.9057e-02,\n",
       "         -3.0495e-02, -3.4891e-03,  1.0340e-03, -4.5408e-02, -9.0956e-02,\n",
       "          1.9611e-02, -8.6552e-03,  5.8443e-03,  7.4992e-03, -2.1662e-02,\n",
       "          1.4769e-02, -5.9284e-02,  7.3311e-02, -7.4311e-04, -3.3417e-03,\n",
       "         -4.0792e-02,  3.2262e-02, -1.4679e-03,  4.9121e-03,  1.8026e-02,\n",
       "         -9.9176e-04, -7.1645e-02,  1.4925e-02, -2.7289e-03, -2.7383e-02,\n",
       "          1.9971e-02, -1.8957e-03, -2.9088e-03, -1.8364e-02, -5.1769e-02,\n",
       "          1.2695e-02,  5.3653e-02, -7.0116e-02, -2.1629e-02,  1.7895e-02,\n",
       "         -2.2745e-02, -1.2971e-02, -2.0458e-02,  4.1952e-02, -3.3800e-02,\n",
       "          2.4389e-02, -6.2728e-03,  5.2204e-03, -1.4331e-02,  2.2571e-03,\n",
       "         -3.0958e-02, -9.7201e-03,  4.8494e-02, -5.4363e-03,  8.5382e-03,\n",
       "         -9.4443e-03, -1.1127e-02, -1.0406e-01, -3.8229e-02, -2.1425e-02,\n",
       "          2.8207e-02,  4.5051e-03,  5.3172e-03,  4.4611e-02, -3.5099e-03,\n",
       "          1.8348e-02, -7.2146e-04, -4.7577e-03, -1.9606e-02, -6.9718e-03,\n",
       "         -6.6189e-03, -5.9782e-03, -3.8703e-02, -1.9873e-03,  1.3453e-02,\n",
       "          6.4028e-03, -2.3905e-02, -2.6881e-03,  3.1049e-03, -2.9950e-02,\n",
       "         -4.9631e-03,  8.6217e-03,  1.1092e-02,  3.0267e-02, -7.1067e-03,\n",
       "         -6.0642e-03, -2.3134e-03, -5.6860e-02, -5.5282e-03,  1.5807e-02,\n",
       "          3.9904e-02, -2.7961e-02,  1.5225e-02,  9.9493e-03,  1.3931e-02,\n",
       "         -1.8326e-02,  3.9135e-02,  1.0863e-02, -7.1977e-03, -1.2532e-02,\n",
       "         -2.7132e-03, -4.4870e-02, -3.9264e-03, -5.4199e-02,  4.7924e-02,\n",
       "          3.0405e-02,  2.5642e-02,  5.1877e-02,  9.0992e-03,  3.4715e-02,\n",
       "         -1.3222e-03,  2.4992e-03, -1.0998e-02,  2.2702e-03, -1.4456e-02,\n",
       "          6.7231e-03,  1.0620e-02, -4.9399e-02, -1.0199e-02, -1.9589e-02,\n",
       "          1.3939e-02,  1.2346e-02,  2.6249e-02, -4.0686e-03, -2.2431e-02,\n",
       "         -3.9373e-02, -2.0967e-02,  9.1742e-02, -1.7801e-02, -6.0951e-04,\n",
       "          2.8627e-02, -4.2820e-02,  9.4557e-03,  2.9728e-04, -2.9022e-02,\n",
       "         -3.2319e-02, -2.9876e-02, -1.2045e-03, -9.7190e-03, -7.2152e-02,\n",
       "          6.3111e-04, -1.0331e-02, -6.1313e-03,  2.1836e-02,  9.4807e-03,\n",
       "          1.3825e-03, -1.3766e-01,  4.2317e-03, -3.7716e-02,  2.3777e-02,\n",
       "         -2.3431e-02,  1.4258e-02, -2.0687e-02, -5.1064e-02,  1.8864e-02,\n",
       "         -2.0125e-02,  2.5140e-03, -3.9658e-03, -1.9863e-02, -4.1480e-03,\n",
       "         -4.1211e-02,  5.9209e-02,  2.5181e-02, -1.2287e-03,  2.3452e-02,\n",
       "         -2.2152e-03, -2.5984e-02, -8.8905e-03,  5.8900e-02,  3.4314e-02,\n",
       "          7.7773e-03,  9.2936e-04,  1.0210e-02,  3.0482e-02, -1.2174e-03,\n",
       "         -1.2217e-02, -1.1403e-02, -9.1644e-04,  4.0275e-02, -7.5155e-04,\n",
       "         -1.4517e-03,  4.2913e-03, -3.5644e-02, -5.2306e-02, -3.4602e-02,\n",
       "         -8.0409e-03, -1.0453e-02, -6.6624e-02, -2.6956e-02,  2.7038e-02,\n",
       "         -4.1371e-02, -1.7794e-03, -1.7685e-02, -7.1987e-04, -3.2824e-03,\n",
       "          7.8020e-03, -4.2237e-02,  2.4833e-02, -1.8929e-03,  1.0171e-02,\n",
       "          4.2944e-03,  1.6355e-03, -7.9301e-02,  2.5186e-03, -5.7161e-02,\n",
       "          5.5222e-02, -1.8352e-04, -1.9852e-02,  1.1413e-02,  8.5531e-02,\n",
       "         -5.0878e-02,  2.1732e-02, -1.6657e-03, -2.7125e-02,  6.8172e-03,\n",
       "         -2.3810e-02,  2.5537e-03, -4.1324e-03, -8.8204e-04, -8.3266e-03,\n",
       "          9.8538e-03, -8.8559e-03, -7.3422e-02,  3.1391e-02, -2.3001e-02,\n",
       "          9.0528e-03, -1.2593e-03,  6.3595e-02, -2.0948e-02, -1.7285e-02,\n",
       "          1.5956e-02, -1.1271e-02,  7.6592e-03,  2.7162e-03, -3.2111e-03,\n",
       "         -9.8038e-04, -3.2931e-03, -5.5899e-04, -3.8784e-02, -2.2826e-02,\n",
       "         -3.8679e-03, -5.1600e-02,  1.2419e-02, -1.4274e-02, -4.7924e-02,\n",
       "          4.6033e-03, -1.3256e-02,  3.9979e-02,  1.8183e-02, -3.0790e-02,\n",
       "         -4.5238e-03,  7.3310e-02, -1.1554e-02,  2.0693e-02, -2.0577e-02,\n",
       "          9.0095e-03, -8.5794e-02,  1.7168e-02,  1.5657e-02, -2.1228e-02,\n",
       "          9.7004e-04,  2.9903e-02, -7.0703e-03,  3.4282e-03, -3.8548e-02,\n",
       "          1.7162e-02, -5.0291e-05, -1.3763e-02, -1.5800e-02, -8.1456e-02,\n",
       "          1.3199e-02,  6.2518e-02, -9.4640e-03,  3.8084e-03, -4.7187e-02,\n",
       "         -1.1189e-02, -1.0778e-02,  3.9827e-03, -1.4356e-02,  8.5800e-02,\n",
       "          4.5518e-03,  3.4763e-02,  4.3874e-03, -1.3094e-02,  1.7321e-02,\n",
       "          4.4172e-03, -3.9473e-02,  2.6633e-02, -7.8491e-02,  5.9605e-02,\n",
       "          3.1555e-03, -1.2122e-02,  4.5706e-03, -3.3275e-03, -4.1223e-03,\n",
       "          1.3214e-02, -3.0002e-04, -8.4613e-03,  2.7672e-02,  3.4942e-03,\n",
       "         -7.7880e-03, -6.4130e-02, -3.8112e-02,  2.1251e-02,  1.8672e-02,\n",
       "         -2.0266e-02,  2.5848e-02, -1.3924e-03,  1.4181e-02, -4.1815e-02,\n",
       "          2.2923e-02, -1.6481e-02, -1.7742e-02,  9.4539e-02,  2.1196e-02,\n",
       "         -9.7366e-04, -2.8706e-02, -1.1510e-02, -1.2458e-02,  2.3222e-02,\n",
       "          1.8764e-03,  4.0888e-02,  2.7134e-02,  5.6956e-04,  3.3805e-03,\n",
       "         -1.6573e-02, -2.0809e-02, -3.7335e-03,  3.3552e-02, -1.4585e-02,\n",
       "         -7.9607e-03, -2.1730e-02, -5.7500e-03,  2.0681e-02,  3.1769e-02,\n",
       "         -3.2630e-03, -5.5120e-03,  3.5129e-03, -1.5964e-02, -1.6975e-02,\n",
       "         -6.7950e-03,  7.0484e-03, -7.9697e-02,  1.1509e-02,  2.6339e-02,\n",
       "         -3.0100e-02,  3.4017e-02,  2.4179e-02,  1.1175e-01,  6.6611e-04,\n",
       "         -6.1553e-03,  6.2281e-03,  1.1375e-01,  1.0224e-02, -6.5066e-03,\n",
       "         -3.2813e-02,  5.9368e-03, -3.8335e-02, -7.6511e-03, -3.0099e-02,\n",
       "          6.9704e-02,  3.1467e-02, -8.5975e-03,  3.7607e-03,  1.9249e-02,\n",
       "         -3.4869e-01,  1.4449e-02,  8.5061e-03,  1.9493e-02,  4.8003e-03,\n",
       "          8.8109e-03,  2.1080e-02,  1.3422e-04, -7.6105e-03,  7.6636e-02,\n",
       "          1.1005e-01,  1.6152e-02,  2.8925e-03, -8.8993e-03,  4.7518e-03,\n",
       "          1.3122e-02,  1.6531e-02, -4.1655e-02,  4.6343e-02,  6.2350e-03,\n",
       "         -2.8678e-02, -1.1491e-01, -1.9213e-02, -9.0308e-03, -1.2618e-02,\n",
       "          6.4798e-03,  2.7541e-03,  1.1682e-02,  1.4669e-01, -4.0875e-03,\n",
       "          1.0865e-01, -1.0379e-02, -1.3725e-02,  1.0295e-03, -2.0595e-03,\n",
       "          1.5228e-02, -1.0041e-01,  1.1273e-02,  2.0304e-02, -9.6463e-04,\n",
       "          5.1517e-03,  3.4385e-02,  1.4239e-02,  2.3346e-02, -1.1681e-02,\n",
       "          7.0067e-03, -6.4040e-03, -1.7300e-02, -5.1302e-03, -9.4058e-03,\n",
       "         -8.8251e-03,  7.3672e-02,  1.1846e-02, -6.0883e-03,  8.5055e-03,\n",
       "         -1.3298e-02, -4.1712e-02,  2.1631e-02,  1.2856e-02, -1.8549e-04,\n",
       "          2.2526e-02, -4.8023e-03,  2.5036e-02,  8.4406e-03, -2.1830e-03,\n",
       "          1.5607e-03, -4.5297e-03,  4.6781e-02,  2.7714e-02, -7.9491e-02,\n",
       "         -6.1882e-03,  2.2644e-02,  1.9150e-02,  1.2233e-02,  3.5118e-02,\n",
       "         -3.5709e-02, -3.4818e-02, -2.1480e-02,  2.4545e-03,  7.0266e-03,\n",
       "          1.3292e-01, -2.0950e-02, -1.0514e-02, -1.5462e-02, -8.0242e-02,\n",
       "          6.0449e-03, -2.5347e-02, -9.9075e-02, -9.0758e-03,  1.2377e-03,\n",
       "         -8.6617e-03, -1.3380e-02, -8.9374e-03,  1.7106e-02, -2.4566e-02,\n",
       "          7.5243e-03,  5.1924e-03, -3.1064e-03, -6.6133e-03, -2.7447e-02,\n",
       "         -1.1927e-01,  3.8886e-05, -5.9616e-03,  5.2741e-03,  4.8580e-02,\n",
       "         -1.7706e-02, -6.1086e-02, -1.1894e-02, -2.3544e-02,  2.4733e-02,\n",
       "         -2.2017e-02,  1.0077e-01,  2.0893e-03, -1.0251e-02, -1.1390e-02,\n",
       "          2.2136e-02, -1.0612e-01,  2.2241e-02, -1.2136e-02,  7.1501e-02,\n",
       "         -5.2778e-02, -1.5728e-02, -1.4703e-02, -9.9872e-03,  4.5128e-03,\n",
       "          4.0958e-03, -1.1690e-02,  4.4531e-04, -1.1670e-02, -4.7175e-02,\n",
       "          5.6208e-03,  1.9117e-03, -3.8294e-02, -2.3626e-02,  4.5622e-03,\n",
       "         -4.4972e-03,  3.2267e-03,  2.8050e-02,  5.5779e-02, -4.1515e-02,\n",
       "         -1.5670e-02, -1.0736e-02, -5.2909e-02, -6.1604e-03, -1.6799e-02,\n",
       "          1.2214e-02, -4.9025e-02, -2.6932e-02, -1.1099e-03, -2.0035e-02,\n",
       "          4.6191e-02,  2.1063e-02, -4.1342e-02, -2.4537e-02, -7.8018e-03,\n",
       "          1.2762e-02,  4.7241e-03,  7.8213e-02, -5.8470e-03,  1.8783e-02,\n",
       "          4.7124e-03, -7.3247e-02, -1.8201e-02, -4.2959e-03,  1.6523e-02,\n",
       "          2.5376e-02,  1.5923e-02, -5.1076e-03,  7.4274e-03,  1.9476e-02,\n",
       "         -1.4111e-04, -4.7320e-03, -3.4147e-03,  3.2692e-02, -4.3133e-03,\n",
       "         -3.7618e-02,  7.8680e-03,  2.7524e-02, -7.8758e-03,  8.0528e-02,\n",
       "         -2.0269e-02,  4.2279e-03,  6.3679e-02, -2.2957e-03, -1.4723e-02,\n",
       "          4.4729e-03, -1.0859e-02,  3.3283e-02,  3.6578e-03, -7.6057e-04,\n",
       "         -6.3236e-02, -2.5644e-02,  1.6051e-02, -1.1013e-02,  9.8590e-02,\n",
       "         -1.7854e-03, -1.9512e-02,  1.8377e-03, -1.1551e-02, -7.5293e-03,\n",
       "          1.9016e-03,  1.1625e-02,  3.4956e-03, -1.3412e-03,  1.4454e-02,\n",
       "         -9.9855e-03, -5.3167e-03, -1.3701e-03,  7.3835e-03,  6.0676e-02,\n",
       "         -2.7407e-03, -2.9850e-02,  3.9484e-02,  6.6434e-02,  6.9433e-03,\n",
       "         -1.2276e-03,  2.9317e-02, -4.1031e-02, -1.2107e-02,  1.4971e-03,\n",
       "         -6.0576e-02, -1.4923e-02, -7.1300e-03,  2.5202e-02, -1.3954e-02,\n",
       "         -5.9142e-02,  5.4700e-02, -1.5995e-02, -1.5198e-02,  3.5727e-02,\n",
       "          7.2100e-03,  8.0043e-03,  5.3744e-03, -8.1495e-03,  2.2277e-02,\n",
       "          1.3992e-02, -3.5706e-02,  2.8474e-02, -4.1431e-02, -3.5616e-02,\n",
       "          1.2407e-03,  1.8357e-02, -3.0905e-02,  1.0276e-04,  1.4175e-03,\n",
       "          6.4565e-02, -3.2930e-02,  4.0240e-03, -3.0373e-02,  5.9058e-03,\n",
       "          8.6135e-03,  3.3088e-02,  9.9099e-03, -9.5918e-02, -1.5055e-02,\n",
       "         -1.7490e-02,  7.4419e-03,  9.3815e-03,  2.5757e-02, -1.1389e-02,\n",
       "          1.4525e-02,  5.8522e-02,  5.5711e-03, -5.4939e-02, -9.6386e-03,\n",
       "          4.9019e-04,  1.6047e-02,  8.4155e-02,  9.5240e-03,  4.3559e-04,\n",
       "         -5.6442e-03, -7.8502e-03, -3.3362e-02,  1.0548e-02, -5.6312e-03,\n",
       "          3.5171e-02, -1.9637e-02, -6.8073e-02, -1.1043e-03, -2.9183e-02,\n",
       "          7.6412e-02,  6.7331e-03, -1.5604e-02, -1.3154e-02, -8.3441e-03,\n",
       "          2.4898e-02, -9.9523e-03, -2.7636e-02, -1.3179e-02,  1.2595e-03,\n",
       "          1.5283e-02, -7.5587e-02,  1.1162e-02, -3.5497e-02,  1.9775e-03,\n",
       "          4.9608e-03, -7.0555e-03, -1.3460e-02, -2.8648e-03, -9.4644e-03,\n",
       "          4.0990e-03,  2.2273e-02, -2.8450e-02, -1.5873e-03,  5.6863e-02,\n",
       "         -5.0255e-03,  1.9180e-02,  8.3328e-03,  2.3917e-02, -1.5565e-02,\n",
       "         -2.4294e-04,  1.6713e-02,  1.3320e-03,  3.3180e-02, -1.0536e-02,\n",
       "         -2.0752e-02,  9.4379e-03, -7.1304e-03,  2.5820e-03, -1.9563e-02,\n",
       "          1.9688e-01,  6.9695e-02,  7.0032e-02, -5.0224e-02, -9.1736e-04,\n",
       "         -9.4098e-04, -4.9863e-03, -3.1588e-02, -8.4058e-03,  3.8295e-03,\n",
       "          4.6872e-02,  3.2563e-02, -2.1071e-02,  2.8930e-02,  4.9817e-03,\n",
       "          4.4708e-02,  8.5605e-03,  8.6552e-02,  1.7194e-02,  2.4007e-02,\n",
       "          1.4248e-02,  6.8609e-03, -1.0314e-02, -7.8267e-03, -9.5097e-03,\n",
       "          2.1400e-03, -2.5295e-02,  1.3263e-02,  5.5752e-02, -7.7234e-02,\n",
       "          1.1171e-01,  1.9786e-02,  9.3301e-02,  1.5551e-02, -3.7328e-02,\n",
       "          2.6470e-02,  2.3369e-02,  1.5871e-03, -1.6491e-02, -1.0909e-02,\n",
       "         -2.2629e-03,  6.3707e-02,  5.9491e-03, -1.8683e-03,  1.3593e-03,\n",
       "          7.8939e-02, -1.7306e-02, -1.1938e-01, -1.5299e-02,  7.5610e-03,\n",
       "          4.8586e-02,  2.6348e-02, -6.2396e-02, -8.4368e-03, -8.0881e-02,\n",
       "         -7.8829e-03,  2.6392e-02, -1.1054e-02,  1.0907e-02, -1.9323e-02,\n",
       "          4.0519e-04,  3.9539e-03,  9.4784e-03, -2.8058e-02, -5.3006e-03,\n",
       "         -4.0823e-03,  1.7444e-02, -5.7749e-03, -2.5673e-02, -1.7875e-03,\n",
       "          7.4867e-03,  3.9296e-03,  3.7834e-03,  4.7049e-02, -1.1966e-02,\n",
       "          1.2866e-02,  8.5473e-02, -1.2453e-02,  1.2477e-03, -4.5796e-03,\n",
       "         -1.5409e-02,  4.8866e-03,  1.0954e-02]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_embeddings(outs.last_hidden_state[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "80e9d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = audio_model.feature_extractor(test_features['input_values'])\n",
    "extract_features = extract_features.transpose(1, 2)\n",
    "\n",
    "mask = audio_model._get_feature_vector_attention_mask(extract_features.shape[1], attention_mask=test_features['attention_mask'])\n",
    "\n",
    "\n",
    "        # if attention_mask is not None:\n",
    "        #     # compute reduced attention_mask corresponding to feature vectors\n",
    "        #     attention_mask = self._get_feature_vector_attention_mask(\n",
    "        #         extract_features.shape[1], attention_mask, add_adapter=False\n",
    "        #     )\n",
    "\n",
    "hidden_states, extract_features = audio_model.feature_projection(extract_features)\n",
    "# after_hidden_states = audio_model._mask_hidden_states(\n",
    "#     hidden_states, mask_time_indices=None, attention_mask=mask\n",
    "# )\n",
    "\n",
    "# hidden_states[~mask] = 0\n",
    "\n",
    "# encoder_outputs = audio_model.encoder(\n",
    "#     hidden_states,\n",
    "#     attention_mask=mask,\n",
    "#     # output_attentions=output_attentions,\n",
    "#     output_hidden_states=True,\n",
    "#     # return_dict=return_dict,\n",
    "# )\n",
    "\n",
    "# make sure padded tokens output 0\n",
    "expand_attention_mask = mask.unsqueeze(-1).repeat(1, 1, hidden_states.shape[2])\n",
    "hidden_states[~expand_attention_mask] = 0\n",
    "\n",
    "# extend attention_mask\n",
    "attention_mask = 1.0 - mask[:, None, None, :].to(dtype=hidden_states.dtype)\n",
    "attention_mask = attention_mask * torch.finfo(hidden_states.dtype).min\n",
    "attention_mask = attention_mask.expand(\n",
    "    attention_mask.shape[0], 1, attention_mask.shape[-1], attention_mask.shape[-1]\n",
    ")\n",
    "\n",
    "\n",
    "position_embeddings =  audio_model.encoder.pos_conv_embed(hidden_states)\n",
    "_hidden_states =  _hidden_states + position_embeddings\n",
    "_hidden_states =  audio_model.encoder.layer_norm(_hidden_states)\n",
    "_hidden_states =  audio_model.encoder.dropout(_hidden_states)\n",
    "\n",
    "# layer_outputs = audio_model.encoder.layers[0](\n",
    "#     _hidden_states, attention_mask=attention_mask, output_attentions=False\n",
    "# )\n",
    "\n",
    "attn_residual = _hidden_states\n",
    "_hidden_states = audio_model.encoder.layers[0].layer_norm(_hidden_states)\n",
    "_hidden_states, attn_weights, _ = audio_model.encoder.layers[0].attention(\n",
    "    _hidden_states, attention_mask=attention_mask, output_attentions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "53850a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure padded tokens output 0\n",
    "expand_attention_mask = mask.unsqueeze(-1).repeat(1, 1, hidden_states.shape[2])\n",
    "hidden_states[~expand_attention_mask] = 0\n",
    "\n",
    "# extend attention_mask\n",
    "attention_mask = 1.0 - mask[:, None, None, :].to(dtype=hidden_states.dtype)\n",
    "# attention_mask = attention_mask * torch.finfo(hidden_states.dtype).min\n",
    "attention_mask = attention_mask.expand(\n",
    "    attention_mask.shape[0], 1, attention_mask.shape[-1], attention_mask.shape[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "6512c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask = attention_mask * torch.finfo(hidden_states.dtype).min\n",
    "# attention_mask = attention_mask.expand(\n",
    "#     attention_mask.shape[0], 1, attention_mask.shape[-1], attention_mask.shape[-1]\n",
    "# )\n",
    "\n",
    "_attention_mask = (attention_mask[0].squeeze() + attention_mask[0].squeeze().T).to(bool).to(int).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "f7becbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _a = attention_mask.clone()\n",
    "\n",
    "# _a[0, ...] = _attention_mask\n",
    "# attention_mask = _a\n",
    "\n",
    "attn_residual = _hidden_states\n",
    "_hidden_states = audio_model.encoder.layers[0].layer_norm(_hidden_states)\n",
    "_hidden_states, attn_weights, _ = audio_model.encoder.layers[0].attention(\n",
    "    _hidden_states, attention_mask=attention_mask, output_attentions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "3f855697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947],\n",
       "        [ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947],\n",
       "        [ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947],\n",
       "        ...,\n",
       "        [ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947],\n",
       "        [ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947],\n",
       "        [ 0.7889,  0.8587, -0.5937,  ...,  0.0753, -0.0205, -0.2947]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "bd3df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "_attention_mask = (attention_mask[0].squeeze() + attention_mask[0].squeeze().T).to(bool).to(int).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "41330de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38]]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "0b0e7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "58b6c3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 17, 17])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e841e3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14706e5c43e0>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(attention_mask[0].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "312a2df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38],\n",
       "         [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "          -3.4028e+38, -3.4028e+38]]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2131a58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0447, -0.1186,  0.0409,  ...,  0.1667, -0.0485,  0.0605],\n",
       "        [ 0.0456, -0.0441, -0.0076,  ...,  0.0680,  0.1726,  0.0995],\n",
       "        [ 0.0176,  0.1331,  0.0335,  ...,  0.4063,  0.1755,  0.0937],\n",
       "        ...,\n",
       "        [-0.1121,  0.0705, -0.0606,  ...,  0.0290, -0.0559, -0.0230],\n",
       "        [-0.1271,  0.0769, -0.0588,  ..., -0.0027, -0.0642, -0.0341],\n",
       "        [-0.1330,  0.0814, -0.0562,  ...,  0.0008, -0.0752, -0.0340]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "afc98b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0207, -1.3331,  1.2335,  ..., -1.0619,  2.0371, -0.2729],\n",
       "        [-0.0242, -0.0481, -0.3385,  ..., -0.9398,  1.3715,  0.3472],\n",
       "        [ 0.3132,  0.4043, -1.3884,  ..., -0.0910, -0.8634, -1.2256],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "29d63d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2429, -0.6389,  0.2645,  ..., -0.4481,  0.5589, -0.2960],\n",
       "        [ 0.1344, -0.0145, -0.2479,  ..., -0.3855,  0.3618, -0.1929],\n",
       "        [ 0.0114,  0.2874, -0.5432,  ...,  0.1727, -0.2483, -0.6027],\n",
       "        ...,\n",
       "        [-0.1991, -0.3136, -0.1565,  ..., -0.6363,  0.4043,  0.1371],\n",
       "        [-0.2154, -0.3062, -0.1447,  ..., -0.6598,  0.3813,  0.1274],\n",
       "        [-0.2099, -0.3123, -0.1377,  ..., -0.6847,  0.3718,  0.1461]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b6808f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1368,  0.0256,  0.1614,  ..., -0.0743, -0.0048,  0.1566],\n",
       "        [-0.0478, -0.1585, -0.2020,  ..., -0.1940,  0.0892,  0.0094],\n",
       "        [-0.1805, -0.0529, -0.0556,  ...,  0.2473, -0.1219,  0.0157],\n",
       "        ...,\n",
       "        [ 0.0637, -0.0274,  0.1209,  ...,  0.0385, -0.0625,  0.1091],\n",
       "        [ 0.0123,  0.0546,  0.1353,  ..., -0.0351, -0.0912,  0.1180],\n",
       "        [ 0.0013,  0.0770,  0.1722,  ..., -0.0349, -0.1282,  0.1358]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs['hidden_states'][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b25f8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(after_hidden_states[0], hidden_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e27878ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs =[]\n",
    "\n",
    "for segment in segments:\n",
    "\n",
    "    features = processor(segment, sampling_rate=sample_rate, padding=True, return_attention_mask=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        inputs = audio_model(**features).last_hidden_state\n",
    "    all_inputs.append(inputs)\n",
    "    # sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd15bf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0586e-01, -6.6365e-03,  1.7591e-02, -3.2182e-02, -1.7303e-01,\n",
       "        -1.3510e-01, -1.5457e-02,  4.5807e-03, -2.0117e-01, -4.0295e-01,\n",
       "         8.6880e-02, -3.8345e-02,  2.5892e-02,  3.3223e-02, -9.5970e-02,\n",
       "         6.5432e-02, -2.6264e-01,  3.2479e-01, -3.2922e-03, -1.4804e-02,\n",
       "        -1.8072e-01,  1.4293e-01, -6.5033e-03,  2.1762e-02,  7.9860e-02,\n",
       "        -4.3937e-03, -3.1740e-01,  6.6120e-02, -1.2090e-02, -1.2131e-01,\n",
       "         8.8478e-02, -8.3982e-03, -1.2887e-02, -8.1358e-02, -2.2935e-01,\n",
       "         5.6241e-02,  2.3770e-01, -3.1063e-01, -9.5822e-02,  7.9279e-02,\n",
       "        -1.0077e-01, -5.7464e-02, -9.0634e-02,  1.8586e-01, -1.4974e-01,\n",
       "         1.0805e-01, -2.7790e-02,  2.3128e-02, -6.3490e-02,  9.9996e-03,\n",
       "        -1.3715e-01, -4.3062e-02,  2.1484e-01, -2.4084e-02,  3.7826e-02,\n",
       "        -4.1840e-02, -4.9293e-02, -4.6099e-01, -1.6936e-01, -9.4916e-02,\n",
       "         1.2496e-01,  1.9959e-02,  2.3556e-02,  1.9764e-01, -1.5550e-02,\n",
       "         8.1286e-02, -3.1963e-03, -2.1078e-02, -8.6860e-02, -3.0887e-02,\n",
       "        -2.9323e-02, -2.6485e-02, -1.7146e-01, -8.8040e-03,  5.9600e-02,\n",
       "         2.8366e-02, -1.0590e-01, -1.1909e-02,  1.3755e-02, -1.3268e-01,\n",
       "        -2.1988e-02,  3.8196e-02,  4.9138e-02,  1.3409e-01, -3.1484e-02,\n",
       "        -2.6866e-02, -1.0249e-02, -2.5190e-01, -2.4491e-02,  7.0031e-02,\n",
       "         1.7678e-01, -1.2387e-01,  6.7451e-02,  4.4078e-02,  6.1719e-02,\n",
       "        -8.1187e-02,  1.7338e-01,  4.8125e-02, -3.1887e-02, -5.5519e-02,\n",
       "        -1.2020e-02, -1.9878e-01, -1.7395e-02, -2.4011e-01,  2.1232e-01,\n",
       "         1.3470e-01,  1.1360e-01,  2.2983e-01,  4.0312e-02,  1.5380e-01,\n",
       "        -5.8576e-03,  1.1072e-02, -4.8723e-02,  1.0057e-02, -6.4042e-02,\n",
       "         2.9785e-02,  4.7048e-02, -2.1885e-01, -4.5183e-02, -8.6783e-02,\n",
       "         6.1755e-02,  5.4696e-02,  1.1629e-01, -1.8025e-02, -9.9373e-02,\n",
       "        -1.7443e-01, -9.2888e-02,  4.0644e-01, -7.8864e-02, -2.7003e-03,\n",
       "         1.2682e-01, -1.8970e-01,  4.1891e-02,  1.3170e-03, -1.2858e-01,\n",
       "        -1.4318e-01, -1.3236e-01, -5.3364e-03, -4.3058e-02, -3.1965e-01,\n",
       "         2.7960e-03, -4.5770e-02, -2.7163e-02,  9.6739e-02,  4.2002e-02,\n",
       "         6.1249e-03, -6.0987e-01,  1.8747e-02, -1.6709e-01,  1.0534e-01,\n",
       "        -1.0380e-01,  6.3167e-02, -9.1649e-02, -2.2622e-01,  8.3574e-02,\n",
       "        -8.9160e-02,  1.1137e-02, -1.7569e-02, -8.7998e-02, -1.8377e-02,\n",
       "        -1.8258e-01,  2.6231e-01,  1.1156e-01, -5.4432e-03,  1.0390e-01,\n",
       "        -9.8138e-03, -1.1511e-01, -3.9387e-02,  2.6094e-01,  1.5202e-01,\n",
       "         3.4455e-02,  4.1173e-03,  4.5232e-02,  1.3504e-01, -5.3932e-03,\n",
       "        -5.4122e-02, -5.0517e-02, -4.0600e-03,  1.7843e-01, -3.3295e-03,\n",
       "        -6.4311e-03,  1.9011e-02, -1.5791e-01, -2.3173e-01, -1.5329e-01,\n",
       "        -3.5623e-02, -4.6309e-02, -2.9516e-01, -1.1942e-01,  1.1979e-01,\n",
       "        -1.8328e-01, -7.8832e-03, -7.8350e-02, -3.1892e-03, -1.4542e-02,\n",
       "         3.4565e-02, -1.8712e-01,  1.1002e-01, -8.3858e-03,  4.5061e-02,\n",
       "         1.9025e-02,  7.2458e-03, -3.5132e-01,  1.1158e-02, -2.5323e-01,\n",
       "         2.4465e-01, -8.1302e-04, -8.7948e-02,  5.0562e-02,  3.7892e-01,\n",
       "        -2.2540e-01,  9.6277e-02, -7.3795e-03, -1.2017e-01,  3.0202e-02,\n",
       "        -1.0549e-01,  1.1313e-02, -1.8307e-02, -3.9076e-03, -3.6889e-02,\n",
       "         4.3655e-02, -3.9234e-02, -3.2528e-01,  1.3907e-01, -1.0190e-01,\n",
       "         4.0106e-02, -5.5789e-03,  2.8174e-01, -9.2803e-02, -7.6575e-02,\n",
       "         7.0689e-02, -4.9935e-02,  3.3932e-02,  1.2033e-02, -1.4226e-02,\n",
       "        -4.3433e-03, -1.4589e-02, -2.4764e-03, -1.7182e-01, -1.0112e-01,\n",
       "        -1.7136e-02, -2.2860e-01,  5.5019e-02, -6.3239e-02, -2.1231e-01,\n",
       "         2.0394e-02, -5.8729e-02,  1.7712e-01,  8.0553e-02, -1.3641e-01,\n",
       "        -2.0042e-02,  3.2478e-01, -5.1185e-02,  9.1674e-02, -9.1162e-02,\n",
       "         3.9914e-02, -3.8009e-01,  7.6057e-02,  6.9362e-02, -9.4044e-02,\n",
       "         4.2975e-03,  1.3248e-01, -3.1323e-02,  1.5188e-02, -1.7077e-01,\n",
       "         7.6030e-02, -2.2280e-04, -6.0973e-02, -6.9997e-02, -3.6087e-01,\n",
       "         5.8473e-02,  2.7697e-01, -4.1928e-02,  1.6872e-02, -2.0905e-01,\n",
       "        -4.9572e-02, -4.7749e-02,  1.7644e-02, -6.3601e-02,  3.8011e-01,\n",
       "         2.0165e-02,  1.5401e-01,  1.9437e-02, -5.8010e-02,  7.6734e-02,\n",
       "         1.9569e-02, -1.7488e-01,  1.1799e-01, -3.4773e-01,  2.6406e-01,\n",
       "         1.3979e-02, -5.3704e-02,  2.0249e-02, -1.4741e-02, -1.8263e-02,\n",
       "         5.8539e-02, -1.3291e-03, -3.7485e-02,  1.2260e-01,  1.5480e-02,\n",
       "        -3.4503e-02, -2.8411e-01, -1.6885e-01,  9.4146e-02,  8.2719e-02,\n",
       "        -8.9784e-02,  1.1451e-01, -6.1687e-03,  6.2827e-02, -1.8525e-01,\n",
       "         1.0156e-01, -7.3013e-02, -7.8602e-02,  4.1883e-01,  9.3904e-02,\n",
       "        -4.3135e-03, -1.2717e-01, -5.0992e-02, -5.5192e-02,  1.0288e-01,\n",
       "         8.3130e-03,  1.8114e-01,  1.2021e-01,  2.5233e-03,  1.4976e-02,\n",
       "        -7.3421e-02, -9.2190e-02, -1.6540e-02,  1.4865e-01, -6.4616e-02,\n",
       "        -3.5268e-02, -9.6270e-02, -2.5474e-02,  9.1622e-02,  1.4074e-01,\n",
       "        -1.4456e-02, -2.4419e-02,  1.5563e-02, -7.0726e-02, -7.5203e-02,\n",
       "        -3.0103e-02,  3.1226e-02, -3.5307e-01,  5.0990e-02,  1.1669e-01,\n",
       "        -1.3335e-01,  1.5070e-01,  1.0712e-01,  4.9509e-01,  2.9510e-03,\n",
       "        -2.7269e-02,  2.7592e-02,  5.0394e-01,  4.5294e-02, -2.8826e-02,\n",
       "        -1.4537e-01,  2.6301e-02, -1.6983e-01, -3.3896e-02, -1.3334e-01,\n",
       "         3.0880e-01,  1.3941e-01, -3.8089e-02,  1.6661e-02,  8.5278e-02,\n",
       "        -1.5448e+00,  6.4013e-02,  3.7684e-02,  8.6357e-02,  2.1267e-02,\n",
       "         3.9034e-02,  9.3390e-02,  5.9464e-04, -3.3716e-02,  3.3951e-01,\n",
       "         4.8755e-01,  7.1556e-02,  1.2814e-02, -3.9426e-02,  2.1052e-02,\n",
       "         5.8132e-02,  7.3236e-02, -1.8454e-01,  2.0531e-01,  2.7623e-02,\n",
       "        -1.2705e-01, -5.0907e-01, -8.5117e-02, -4.0008e-02, -5.5902e-02,\n",
       "         2.8707e-02,  1.2201e-02,  5.1754e-02,  6.4986e-01, -1.8109e-02,\n",
       "         4.8133e-01, -4.5983e-02, -6.0807e-02,  4.5611e-03, -9.1241e-03,\n",
       "         6.7462e-02, -4.4486e-01,  4.9940e-02,  8.9952e-02, -4.2735e-03,\n",
       "         2.2823e-02,  1.5233e-01,  6.3084e-02,  1.0343e-01, -5.1751e-02,\n",
       "         3.1041e-02, -2.8371e-02, -7.6643e-02, -2.2728e-02, -4.1670e-02,\n",
       "        -3.9097e-02,  3.2638e-01,  5.2480e-02, -2.6973e-02,  3.7681e-02,\n",
       "        -5.8913e-02, -1.8479e-01,  9.5828e-02,  5.6956e-02, -8.2178e-04,\n",
       "         9.9796e-02, -2.1275e-02,  1.1092e-01,  3.7394e-02, -9.6711e-03,\n",
       "         6.9142e-03, -2.0068e-02,  2.0725e-01,  1.2278e-01, -3.5216e-01,\n",
       "        -2.7415e-02,  1.0032e-01,  8.4838e-02,  5.4196e-02,  1.5558e-01,\n",
       "        -1.5820e-01, -1.5425e-01, -9.5163e-02,  1.0874e-02,  3.1129e-02,\n",
       "         5.8885e-01, -9.2813e-02, -4.6579e-02, -6.8499e-02, -3.5549e-01,\n",
       "         2.6780e-02, -1.1229e-01, -4.3893e-01, -4.0208e-02,  5.4835e-03,\n",
       "        -3.8373e-02, -5.9277e-02, -3.9595e-02,  7.5785e-02, -1.0883e-01,\n",
       "         3.3334e-02,  2.3003e-02, -1.3762e-02, -2.9299e-02, -1.2160e-01,\n",
       "        -5.2841e-01,  1.7228e-04, -2.6411e-02,  2.3365e-02,  2.1522e-01,\n",
       "        -7.8442e-02, -2.7062e-01, -5.2692e-02, -1.0430e-01,  1.0957e-01,\n",
       "        -9.7539e-02,  4.4644e-01,  9.2561e-03, -4.5414e-02, -5.0459e-02,\n",
       "         9.8066e-02, -4.7012e-01,  9.8532e-02, -5.3765e-02,  3.1677e-01,\n",
       "        -2.3382e-01, -6.9677e-02, -6.5138e-02, -4.4246e-02,  1.9993e-02,\n",
       "         1.8145e-02, -5.1791e-02,  1.9728e-03, -5.1702e-02, -2.0899e-01,\n",
       "         2.4901e-02,  8.4691e-03, -1.6965e-01, -1.0467e-01,  2.0211e-02,\n",
       "        -1.9924e-02,  1.4295e-02,  1.2427e-01,  2.4711e-01, -1.8392e-01,\n",
       "        -6.9421e-02, -4.7564e-02, -2.3440e-01, -2.7292e-02, -7.4423e-02,\n",
       "         5.4109e-02, -2.1719e-01, -1.1931e-01, -4.9170e-03, -8.8762e-02,\n",
       "         2.0464e-01,  9.3312e-02, -1.8315e-01, -1.0871e-01, -3.4564e-02,\n",
       "         5.6537e-02,  2.0929e-02,  3.4650e-01, -2.5903e-02,  8.3214e-02,\n",
       "         2.0877e-02, -3.2450e-01, -8.0635e-02, -1.9032e-02,  7.3202e-02,\n",
       "         1.1242e-01,  7.0543e-02, -2.2628e-02,  3.2905e-02,  8.6281e-02,\n",
       "        -6.2516e-04, -2.0964e-02, -1.5128e-02,  1.4483e-01, -1.9109e-02,\n",
       "        -1.6666e-01,  3.4857e-02,  1.2194e-01, -3.4892e-02,  3.5676e-01,\n",
       "        -8.9795e-02,  1.8731e-02,  2.8211e-01, -1.0170e-02, -6.5228e-02,\n",
       "         1.9816e-02, -4.8106e-02,  1.4745e-01,  1.6205e-02, -3.3695e-03,\n",
       "        -2.8015e-01, -1.1361e-01,  7.1108e-02, -4.8792e-02,  4.3678e-01,\n",
       "        -7.9096e-03, -8.6442e-02,  8.1416e-03, -5.1173e-02, -3.3356e-02,\n",
       "         8.4246e-03,  5.1501e-02,  1.5486e-02, -5.9418e-03,  6.4034e-02,\n",
       "        -4.4238e-02, -2.3554e-02, -6.0700e-03,  3.2711e-02,  2.6881e-01,\n",
       "        -1.2142e-02, -1.3224e-01,  1.7492e-01,  2.9432e-01,  3.0760e-02,\n",
       "        -5.4383e-03,  1.2988e-01, -1.8178e-01, -5.3637e-02,  6.6325e-03,\n",
       "        -2.6836e-01, -6.6113e-02, -3.1587e-02,  1.1165e-01, -6.1820e-02,\n",
       "        -2.6201e-01,  2.4233e-01, -7.0864e-02, -6.7330e-02,  1.5828e-01,\n",
       "         3.1942e-02,  3.5461e-02,  2.3810e-02, -3.6104e-02,  9.8691e-02,\n",
       "         6.1987e-02, -1.5819e-01,  1.2615e-01, -1.8355e-01, -1.5779e-01,\n",
       "         5.4964e-03,  8.1326e-02, -1.3692e-01,  4.5527e-04,  6.2797e-03,\n",
       "         2.8604e-01, -1.4589e-01,  1.7827e-02, -1.3456e-01,  2.6164e-02,\n",
       "         3.8160e-02,  1.4659e-01,  4.3903e-02, -4.2494e-01, -6.6697e-02,\n",
       "        -7.7485e-02,  3.2969e-02,  4.1562e-02,  1.1411e-01, -5.0456e-02,\n",
       "         6.4351e-02,  2.5926e-01,  2.4681e-02, -2.4339e-01, -4.2701e-02,\n",
       "         2.1717e-03,  7.1094e-02,  3.7283e-01,  4.2194e-02,  1.9297e-03,\n",
       "        -2.5005e-02, -3.4778e-02, -1.4780e-01,  4.6730e-02, -2.4948e-02,\n",
       "         1.5581e-01, -8.6995e-02, -3.0158e-01, -4.8921e-03, -1.2929e-01,\n",
       "         3.3852e-01,  2.9829e-02, -6.9127e-02, -5.8274e-02, -3.6966e-02,\n",
       "         1.1031e-01, -4.4091e-02, -1.2243e-01, -5.8385e-02,  5.5797e-03,\n",
       "         6.7708e-02, -3.3487e-01,  4.9449e-02, -1.5726e-01,  8.7606e-03,\n",
       "         2.1977e-02, -3.1257e-02, -5.9631e-02, -1.2692e-02, -4.1929e-02,\n",
       "         1.8159e-02,  9.8677e-02, -1.2604e-01, -7.0321e-03,  2.5191e-01,\n",
       "        -2.2264e-02,  8.4972e-02,  3.6916e-02,  1.0596e-01, -6.8958e-02,\n",
       "        -1.0763e-03,  7.4042e-02,  5.9010e-03,  1.4699e-01, -4.6679e-02,\n",
       "        -9.1938e-02,  4.1812e-02, -3.1589e-02,  1.1439e-02, -8.6667e-02,\n",
       "         8.7221e-01,  3.0876e-01,  3.1026e-01, -2.2251e-01, -4.0641e-03,\n",
       "        -4.1688e-03, -2.2090e-02, -1.3994e-01, -3.7240e-02,  1.6966e-02,\n",
       "         2.0765e-01,  1.4426e-01, -9.3351e-02,  1.2816e-01,  2.2070e-02,\n",
       "         1.9806e-01,  3.7925e-02,  3.8345e-01,  7.6172e-02,  1.0636e-01,\n",
       "         6.3122e-02,  3.0395e-02, -4.5692e-02, -3.4674e-02, -4.2130e-02,\n",
       "         9.4805e-03, -1.1206e-01,  5.8758e-02,  2.4699e-01, -3.4216e-01,\n",
       "         4.9488e-01,  8.7655e-02,  4.1335e-01,  6.8894e-02, -1.6537e-01,\n",
       "         1.1727e-01,  1.0353e-01,  7.0312e-03, -7.3058e-02, -4.8328e-02,\n",
       "        -1.0025e-02,  2.8224e-01,  2.6356e-02, -8.2768e-03,  6.0219e-03,\n",
       "         3.4972e-01, -7.6669e-02, -5.2889e-01, -6.7777e-02,  3.3497e-02,\n",
       "         2.1525e-01,  1.1673e-01, -2.7643e-01, -3.7377e-02, -3.5832e-01,\n",
       "        -3.4923e-02,  1.1692e-01, -4.8971e-02,  4.8321e-02, -8.5604e-02,\n",
       "         1.7951e-03,  1.7517e-02,  4.1992e-02, -1.2430e-01, -2.3483e-02,\n",
       "        -1.8085e-02,  7.7282e-02, -2.5584e-02, -1.1374e-01, -7.9190e-03,\n",
       "         3.3168e-02,  1.7409e-02,  1.6761e-02,  2.0844e-01, -5.3011e-02,\n",
       "         5.6999e-02,  3.7867e-01, -5.5171e-02,  5.5278e-03, -2.0289e-02,\n",
       "        -6.8265e-02,  2.1649e-02,  4.8528e-02])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "661aa343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.4595e-02, -3.6891e-02, -7.3343e-02, -6.7418e-02, -8.4808e-02,\n",
       "        -1.5854e-01, -5.1389e-02, -1.4615e-02, -1.0109e-01, -3.7211e-01,\n",
       "         1.2793e-01, -1.4080e-01,  7.3992e-02,  4.0280e-02,  9.1792e-02,\n",
       "         7.2573e-02, -3.1303e-01,  3.4526e-01,  6.2650e-03,  5.0196e-02,\n",
       "        -2.4824e-01,  1.1582e-01,  2.2362e-01,  2.6775e-02,  1.0136e-01,\n",
       "         1.6513e-02, -4.9735e-01,  1.1437e-01, -3.0881e-02, -1.1575e-01,\n",
       "         1.2703e-01, -6.0878e-03,  2.2107e-02, -8.6003e-02, -3.1766e-01,\n",
       "         1.6566e-01,  2.0838e-01, -2.5917e-01, -1.4243e-01,  1.2489e-01,\n",
       "        -1.5440e-01, -8.4106e-02, -1.3576e-01,  1.8271e-01, -2.2669e-01,\n",
       "         4.9862e-02, -6.2690e-03,  3.3725e-02, -4.4198e-02,  4.2136e-03,\n",
       "        -1.1800e-01,  3.0094e-04,  3.3288e-01,  7.6247e-03,  4.6592e-02,\n",
       "        -5.3745e-02, -1.5765e-02, -4.4887e-01, -1.6056e-01, -3.9075e-02,\n",
       "         1.1434e-01,  5.8828e-02,  2.2339e-02,  2.6648e-01, -2.0229e-02,\n",
       "         1.1905e-01,  1.5379e-03, -7.4630e-03, -1.2450e-01, -2.4165e-02,\n",
       "        -5.0275e-02, -1.8614e-02, -2.1903e-01, -5.3786e-02,  1.1263e-01,\n",
       "        -7.0635e-02, -1.3927e-01, -2.0688e-03, -2.3768e-02, -1.2765e-01,\n",
       "        -1.1062e-01, -4.2414e-02,  4.2900e-02,  5.5953e-02, -3.2753e-02,\n",
       "        -3.2528e-02, -5.7708e-02, -3.0576e-01, -1.9051e-02,  4.7322e-02,\n",
       "         2.6596e-01, -1.1377e-01,  2.3039e-02,  4.2413e-02,  5.3068e-02,\n",
       "        -8.8083e-02,  8.8114e-02, -4.0944e-03, -4.0243e-02, -6.2647e-02,\n",
       "        -1.3884e-02, -2.1464e-01,  2.5365e-02, -2.8957e-01,  2.0120e-01,\n",
       "         2.8197e-01,  6.6183e-02,  1.8984e-01,  3.4414e-02,  1.3086e-01,\n",
       "        -3.2695e-02,  7.9610e-02, -3.5556e-02,  1.5834e-02, -8.1021e-02,\n",
       "         3.3997e-02,  2.8325e-02, -3.0598e-01, -5.1514e-02, -4.2488e-02,\n",
       "         1.1231e-01,  4.4481e-02,  1.1839e-01, -1.3321e-02, -1.6141e-01,\n",
       "        -2.6377e-01, -1.1891e-01,  3.7089e-01, -1.0009e-01, -5.5216e-02,\n",
       "         1.3882e-01, -2.3116e-01,  1.0120e-01, -3.8533e-02, -1.0541e-01,\n",
       "        -2.1219e-01, -1.1754e-01,  1.5899e-02, -7.4698e-02, -3.6858e-01,\n",
       "        -7.3750e-03, -6.0484e-02, -2.1834e-02,  1.9183e-01,  2.6056e-02,\n",
       "        -5.7647e-02, -6.3234e-01,  1.1834e-02, -2.0067e-01,  5.1543e-02,\n",
       "        -4.5772e-02,  8.4683e-02,  5.2040e-02, -1.9825e-01,  6.1056e-02,\n",
       "        -8.6583e-02,  3.2569e-02,  9.7753e-03,  8.5678e-04,  7.2279e-04,\n",
       "        -2.2291e-01,  2.9004e-01,  1.2509e-01, -1.5560e-02,  1.3452e-01,\n",
       "        -1.5730e-02, -1.2228e-01, -8.1116e-02,  5.7574e-01,  2.2500e-01,\n",
       "         2.4745e-02,  5.4982e-02,  1.3391e-02,  1.4697e-01, -5.5925e-03,\n",
       "        -2.2729e-03, -8.0762e-02,  3.1181e-02,  1.6002e-01, -3.4862e-03,\n",
       "        -7.3898e-03,  2.7927e-02, -1.8042e-01, -2.5629e-01, -9.2801e-02,\n",
       "        -3.5767e-02, -5.1535e-02, -4.0729e-01, -1.8769e-01,  9.8128e-02,\n",
       "        -2.0926e-01, -1.2652e-02, -7.6830e-02, -1.7296e-02, -2.4775e-02,\n",
       "         5.5200e-02, -6.8977e-02,  2.2407e-01, -3.7760e-02,  2.3838e-02,\n",
       "         4.2718e-03,  2.4849e-02, -2.7887e-01,  6.9963e-02, -2.4957e-01,\n",
       "         3.8286e-01, -2.9662e-02, -6.9438e-02,  2.2856e-02,  3.5976e-01,\n",
       "        -3.9980e-01,  1.3612e-01, -7.0756e-03, -1.1408e-01,  3.0354e-02,\n",
       "        -1.1529e-01,  3.9055e-02, -8.0374e-03, -1.1746e-02, -3.8393e-02,\n",
       "        -2.5475e-02, -3.7863e-02, -2.4079e-01,  2.4451e-01, -8.0033e-02,\n",
       "         1.6783e-02, -5.6498e-03,  2.5737e-01, -1.3802e-01, -2.5880e-02,\n",
       "         7.0067e-02, -5.7355e-02,  2.0312e-02,  1.3964e-03, -7.6994e-03,\n",
       "        -2.7718e-03, -1.2068e-02, -2.5210e-03, -9.8110e-02, -1.2435e-01,\n",
       "        -1.5349e-02, -5.0717e-02,  8.8807e-02, -3.1643e-02, -3.6378e-01,\n",
       "         2.0511e-02, -4.5347e-02,  1.7975e-01,  7.8019e-02, -1.6509e-01,\n",
       "        -2.1189e-02,  3.1941e-01,  6.7954e-02,  3.8280e-02, -1.5095e-01,\n",
       "         8.6016e-02, -3.3368e-01,  2.3553e-01,  1.0272e-01, -5.4316e-02,\n",
       "         6.1268e-03,  1.4267e-01, -2.1230e-02,  4.7587e-02, -3.6591e-01,\n",
       "         6.6288e-02, -1.0462e-02, -4.4752e-02, -1.6735e-01, -3.5720e-01,\n",
       "         7.5687e-02,  1.9272e-01, -6.6517e-02,  1.4974e-02, -1.9695e-01,\n",
       "        -4.9198e-02, -5.8518e-02,  4.3359e-02, -3.6952e-02,  3.8310e-01,\n",
       "         1.4350e-03,  1.7757e-01,  4.7416e-02,  1.5485e-01,  6.2993e-02,\n",
       "        -6.0310e-02, -1.8232e-01,  1.0307e-01, -3.2254e-01,  3.7811e-01,\n",
       "         1.1304e-02, -1.3666e-01,  1.0330e-02, -1.5514e-02,  8.9870e-02,\n",
       "         6.1941e-02, -1.0874e-03, -4.2525e-02,  7.0155e-02,  2.1173e-02,\n",
       "        -3.5848e-02, -4.1220e-01, -1.3617e-01,  1.7056e-01,  6.7147e-02,\n",
       "        -9.1098e-02,  2.3493e-01,  3.2967e-02,  3.1329e-02, -3.1144e-01,\n",
       "         1.5969e-01, -1.1203e-01, -9.7760e-02,  5.4176e-01, -4.7829e-02,\n",
       "        -3.7245e-02, -1.2563e-01, -4.3982e-02, -7.4768e-02,  1.2422e-01,\n",
       "         1.5036e-01,  1.5923e-01,  1.7870e-01,  1.9949e-02, -3.5288e-02,\n",
       "        -8.6299e-02, -1.1851e-01,  1.4796e-02,  1.9434e-01, -6.4644e-02,\n",
       "        -4.7061e-03, -1.1397e-02, -5.5851e-02,  1.2924e-01,  2.2065e-01,\n",
       "        -1.1069e-03, -8.4951e-03,  2.0262e-02, -8.9911e-02, -1.1410e-01,\n",
       "        -9.9597e-02, -6.1958e-02, -4.0755e-01,  1.0312e-01,  1.6162e-01,\n",
       "        -1.0614e-01,  1.9623e-01,  1.1512e-01,  6.3740e-01,  2.0737e-03,\n",
       "        -6.5278e-02,  5.9184e-02,  7.6516e-01,  4.6433e-02,  2.8959e-03,\n",
       "        -2.0909e-01,  3.9921e-02, -1.3918e-01, -3.3673e-02, -2.5639e-01,\n",
       "         2.5726e-01,  1.5439e-01,  3.3261e-02,  2.0733e-02,  1.5509e-01,\n",
       "        -1.4527e+00,  6.9575e-02,  6.9546e-02,  1.0083e-01,  3.7549e-03,\n",
       "        -7.1526e-03,  2.7641e-01, -9.1551e-02,  4.5163e-02,  4.4850e-01,\n",
       "         4.5782e-01,  1.6610e-01,  1.2756e-02, -1.0564e-01, -2.3532e-02,\n",
       "         3.5497e-02,  1.3690e-01, -1.7772e-01,  1.9772e-01,  1.3856e-01,\n",
       "        -1.8332e-01, -5.3166e-01, -1.2514e-01, -3.4628e-02,  8.1619e-03,\n",
       "         1.9867e-02, -4.3571e-03,  9.2230e-02,  6.2007e-01, -8.7650e-02,\n",
       "         6.7022e-01, -1.5108e-02,  1.7735e-01,  1.7409e-02, -1.0270e-02,\n",
       "        -6.0996e-02, -7.3925e-01,  6.6645e-02,  1.0275e-01,  4.4230e-03,\n",
       "         6.7042e-02,  1.1670e-01,  4.0808e-02,  8.9786e-02, -1.3089e-02,\n",
       "         3.1817e-02, -8.4254e-02, -8.7624e-02, -2.6704e-02, -2.1709e-01,\n",
       "        -6.5527e-02,  2.7058e-01,  2.4024e-02, -2.7026e-02,  2.9906e-02,\n",
       "        -2.6662e-02, -1.8420e-01,  1.6711e-01,  9.8402e-02,  2.9214e-02,\n",
       "         5.1028e-02, -1.3684e-02,  4.6336e-02,  2.8676e-02,  3.8906e-02,\n",
       "         9.5684e-03,  4.6112e-02,  3.4525e-01,  1.0232e-01, -3.0082e-01,\n",
       "        -4.0102e-02,  1.9082e-01,  8.7469e-02,  1.5655e-01,  2.4758e-01,\n",
       "        -1.3626e-01, -1.9841e-01, -1.4564e-01,  1.2158e-02, -8.6396e-03,\n",
       "         5.3506e-01, -2.2426e-01, -4.6235e-02, -6.5246e-02, -3.1682e-01,\n",
       "         1.3205e-01, -2.1280e-01, -6.7708e-01, -7.9576e-02,  5.4968e-03,\n",
       "        -3.8366e-02, -6.1583e-02, -4.2710e-02,  1.0082e-03, -1.5505e-01,\n",
       "         5.8717e-02,  2.6940e-02, -1.2631e-02, -1.0165e-01, -1.6416e-01,\n",
       "        -6.7654e-01,  8.7604e-02,  1.2981e-02,  1.3858e-02,  2.1717e-01,\n",
       "        -1.0125e-01, -4.7261e-01, -7.6537e-02, -1.1659e-01,  8.9573e-02,\n",
       "        -9.7885e-02,  4.6339e-01,  9.5149e-02, -5.3515e-02, -9.6931e-02,\n",
       "         1.2889e-01, -4.1888e-01,  1.0637e-01, -1.0720e-01,  3.0538e-01,\n",
       "        -2.8604e-01, -1.1757e-02, -6.5750e-02, -9.9510e-02,  2.1373e-02,\n",
       "         2.5276e-02, -1.0516e-01,  1.3926e-03, -1.3116e-01, -1.9192e-01,\n",
       "         9.5903e-02, -8.3516e-03, -2.1624e-01, -1.7645e-01,  1.0473e-02,\n",
       "        -1.3261e-01,  2.5199e-02,  1.1685e-01,  2.1359e-01, -1.9463e-01,\n",
       "        -9.0405e-02, -7.1680e-02, -2.5957e-01, -5.7280e-02, -6.7780e-02,\n",
       "         6.8732e-02, -2.3168e-01, -9.3062e-02,  6.2584e-02, -9.6734e-02,\n",
       "         2.6682e-01,  9.5468e-02, -2.0466e-01, -1.4549e-01, -5.7660e-02,\n",
       "         8.7385e-02,  4.0660e-03,  3.2177e-01, -2.7319e-02,  8.6002e-02,\n",
       "         4.1244e-02, -4.7082e-01, -7.5256e-02,  1.3038e-01,  1.2665e-01,\n",
       "         1.1627e-01,  9.2429e-02, -5.2874e-02,  4.2768e-02,  8.6308e-02,\n",
       "         2.7690e-03, -1.1386e-02, -7.4126e-03,  1.0484e-01,  1.2451e-03,\n",
       "        -3.2768e-01,  4.2856e-02,  1.3275e-01,  9.4112e-03,  5.1985e-01,\n",
       "        -1.4749e-03, -7.2516e-04,  4.4568e-01, -1.6729e-01, -5.5104e-02,\n",
       "         1.0140e-03, -5.0360e-02,  1.7140e-01,  2.6270e-02,  9.9446e-04,\n",
       "        -2.3516e-01, -1.1355e-01,  2.4245e-02, -1.0325e-01,  3.6178e-01,\n",
       "        -7.9268e-03, -6.6086e-02, -3.2020e-03, -5.0925e-02,  2.4422e-02,\n",
       "        -7.6186e-03,  9.5829e-02, -3.1676e-02, -1.2002e-02,  4.4677e-02,\n",
       "        -1.0188e-01,  4.4657e-03,  4.4927e-03, -1.1445e-02,  3.1414e-01,\n",
       "        -2.0610e-02, -2.0414e-01,  1.4491e-01,  3.1920e-01,  5.0089e-02,\n",
       "        -3.7082e-02,  8.9896e-02, -1.6402e-01, -4.9290e-02, -3.6084e-02,\n",
       "        -2.6733e-01, -9.9528e-02, -6.1207e-02,  1.0827e-01, -8.5613e-02,\n",
       "        -3.2129e-02,  1.9496e-01, -2.0223e-02, -6.8044e-02,  2.0946e-01,\n",
       "         6.1901e-02, -1.5673e-02,  4.0932e-02, -7.2210e-03,  2.1532e-01,\n",
       "         6.4251e-02, -1.1486e-01,  1.3438e-01, -2.5261e-01, -2.4743e-01,\n",
       "        -3.1505e-03,  7.6962e-02, -8.2236e-02,  7.0693e-04, -1.3391e-02,\n",
       "         2.6510e-01, -1.5910e-01, -9.1516e-02, -5.0664e-02,  4.3730e-02,\n",
       "         1.6491e-01,  1.2928e-01,  8.0697e-02, -3.9434e-01, -2.4155e-01,\n",
       "        -1.5757e-01,  1.5027e-02,  7.6148e-02,  6.5142e-02, -2.1994e-02,\n",
       "         8.9884e-02,  2.2397e-01,  5.0407e-02, -2.7625e-01, -6.3220e-03,\n",
       "        -4.9481e-03,  8.1097e-02,  3.5859e-01,  3.8132e-02,  1.1112e-02,\n",
       "        -3.1545e-02, -2.0937e-03, -1.4583e-01,  5.9764e-02, -2.4421e-02,\n",
       "         1.9355e-01,  1.7378e-01, -2.9747e-01, -1.4251e-02, -1.0964e-01,\n",
       "         4.0655e-01,  3.1910e-02, -3.5801e-02, -1.8362e-01,  2.0087e-02,\n",
       "         2.4862e-01, -1.3630e-01, -4.2749e-02, -7.8880e-02,  2.1569e-02,\n",
       "         1.2580e-01, -4.6566e-01,  3.6160e-02, -1.5448e-01,  8.6503e-03,\n",
       "         3.1527e-02, -6.6847e-02, -1.0528e-02, -1.7212e-01, -1.7313e-02,\n",
       "        -3.7989e-03,  1.3433e-01, -1.3733e-01,  2.1282e-02,  3.6281e-01,\n",
       "        -4.6579e-02, -3.2940e-02,  1.0018e-01,  1.1876e-01, -6.4150e-02,\n",
       "        -1.2765e-03,  9.6670e-02,  1.4671e-02,  1.7315e-01, -4.6387e-02,\n",
       "        -3.4614e-02,  8.9277e-03, -3.8620e-02,  1.0143e-01, -1.3732e-01,\n",
       "         1.3744e+00,  7.3116e-01,  4.6231e-01, -2.9016e-01, -2.1359e-02,\n",
       "        -5.6675e-02, -7.3788e-02, -1.4491e-01, -6.0675e-02,  1.7730e-02,\n",
       "         2.1004e-01,  1.3779e-01, -8.5561e-02,  1.3649e-01, -4.9045e-02,\n",
       "         3.6362e-01, -6.0305e-03,  4.2970e-01,  7.5370e-02,  1.6106e-01,\n",
       "         3.3807e-02,  4.4024e-02, -4.0682e-02, -4.9416e-02,  1.2162e-02,\n",
       "        -2.3029e-02, -1.1843e-01,  1.6939e-01,  2.4491e-01, -2.8074e-01,\n",
       "         5.4790e-01,  7.9901e-02,  3.5178e-01,  4.4372e-02, -1.5606e-01,\n",
       "         1.1465e-01,  2.0824e-01,  4.8325e-03, -7.3069e-02, -6.1778e-02,\n",
       "        -1.9917e-02,  2.4158e-01,  2.5546e-02,  7.8074e-02,  6.4061e-03,\n",
       "         3.8026e-01, -8.8825e-02, -5.6043e-01, -6.9513e-02,  1.5281e-01,\n",
       "         2.7270e-01,  1.9205e-01, -2.5501e-01, -5.9222e-02, -2.6922e-01,\n",
       "        -7.3883e-02,  7.5832e-02, -7.5733e-02,  4.8297e-02, -9.2465e-02,\n",
       "        -6.8349e-03,  3.3116e-02, -2.9195e-02, -1.3147e-01, -8.9191e-02,\n",
       "        -6.1125e-02,  5.8687e-02, -5.1143e-02, -8.5006e-02, -1.8108e-02,\n",
       "         9.6613e-02,  9.0720e-03, -8.0411e-03,  2.6131e-01, -5.3439e-02,\n",
       "         1.7283e-02,  3.2248e-01, -1.2742e-01,  9.1945e-03, -1.8179e-02,\n",
       "        -7.7283e-02,  5.8554e-02,  8.7603e-02])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.mean(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5f0446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = audio_model(**features, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6473fe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2BaseModelOutput(last_hidden_state=tensor([[[-1.1868e-01,  1.7360e-02, -1.1886e-02,  ..., -1.4341e-01,\n",
       "           2.7844e-02,  1.1457e-01],\n",
       "         [-1.1999e-01, -2.0933e-03,  5.6863e-02,  ..., -8.5153e-02,\n",
       "           2.2196e-02,  8.1948e-02],\n",
       "         [-1.0305e-01, -1.0361e-02,  4.8652e-02,  ..., -6.5978e-02,\n",
       "           1.2478e-02,  4.5145e-02],\n",
       "         ...,\n",
       "         [-1.0591e-01, -8.3574e-03,  4.7337e-02,  ..., -6.9505e-02,\n",
       "           1.2614e-02,  4.8834e-02],\n",
       "         [-1.0595e-01, -8.3057e-03,  4.7186e-02,  ..., -6.9616e-02,\n",
       "           1.2679e-02,  4.9047e-02],\n",
       "         [-1.0612e-01, -8.1272e-03,  4.7287e-02,  ..., -6.9831e-02,\n",
       "           1.2708e-02,  4.9323e-02]],\n",
       "\n",
       "        [[-1.0334e-01, -6.0915e-02,  3.9164e-02,  ..., -1.8516e-01,\n",
       "          -8.8118e-03, -1.2711e-02],\n",
       "         [-9.4939e-02, -6.2241e-02,  4.3321e-02,  ..., -1.8774e-01,\n",
       "          -1.7906e-02, -1.7977e-02],\n",
       "         [-9.1639e-02, -6.0596e-02,  3.9384e-02,  ..., -1.8169e-01,\n",
       "          -1.3518e-02, -1.6702e-02],\n",
       "         ...,\n",
       "         [-8.9087e-02, -6.5134e-02,  4.6772e-02,  ..., -1.8912e-01,\n",
       "          -2.6631e-02, -2.3824e-02],\n",
       "         [-8.9033e-02, -6.5125e-02,  4.6778e-02,  ..., -1.8908e-01,\n",
       "          -2.6659e-02, -2.3830e-02],\n",
       "         [-8.9021e-02, -6.5122e-02,  4.6777e-02,  ..., -1.8907e-01,\n",
       "          -2.6656e-02, -2.3822e-02]],\n",
       "\n",
       "        [[-8.1225e-02, -1.3701e-01, -5.6752e-02,  ...,  1.6301e-02,\n",
       "           9.2452e-02,  6.9312e-02],\n",
       "         [ 4.8874e-02, -1.9415e-01, -6.0955e-02,  ..., -3.3628e-01,\n",
       "          -1.0515e-01,  2.5637e-01],\n",
       "         [ 5.6712e-02,  3.4954e-02, -2.3849e-01,  ..., -2.6882e-01,\n",
       "          -3.4524e-02,  4.8960e-01],\n",
       "         ...,\n",
       "         [ 2.3866e-02, -5.0235e-02, -6.2719e-07,  ...,  2.0345e-01,\n",
       "          -1.7579e-02, -4.4419e-02],\n",
       "         [ 8.1733e-02, -6.3069e-02,  1.0336e-01,  ...,  2.0463e-01,\n",
       "          -5.8522e-02, -1.4336e-01],\n",
       "         [ 9.8062e-02, -6.3590e-02,  1.2527e-01,  ...,  2.2325e-01,\n",
       "          -6.7366e-02, -1.4884e-01]]]), extract_features=tensor([[[-3.0386e-01, -1.2478e-01,  5.9559e-01,  ...,  4.8791e-01,\n",
       "           5.7344e-02,  4.5353e-02],\n",
       "         [ 1.8634e-02,  8.1316e-03,  4.9743e-01,  ...,  3.0745e-01,\n",
       "           1.5596e-01, -9.5270e-02],\n",
       "         [ 7.5324e-02, -2.3905e-02,  2.9931e-04,  ...,  8.3883e-01,\n",
       "           3.4778e-01, -4.5862e-01],\n",
       "         ...,\n",
       "         [ 1.3760e-01, -2.1217e-01,  1.7283e-01,  ..., -3.3781e-01,\n",
       "          -6.0146e-02, -2.0578e-01],\n",
       "         [ 1.3760e-01, -2.1217e-01,  1.7283e-01,  ..., -3.3781e-01,\n",
       "          -6.0146e-02, -2.0578e-01],\n",
       "         [ 1.3760e-01, -2.1217e-01,  1.7283e-01,  ..., -3.3781e-01,\n",
       "          -6.0146e-02, -2.0578e-01]],\n",
       "\n",
       "        [[-2.2733e-01, -6.1450e-02,  3.1909e-01,  ...,  1.4564e-01,\n",
       "          -5.5649e-02,  6.7045e-01],\n",
       "         [-6.5847e-02, -2.0064e-01, -4.9146e-02,  ...,  1.2432e-01,\n",
       "          -2.7306e-01,  1.7681e-01],\n",
       "         [-1.0550e-01,  1.8754e-01,  6.0415e-02,  ...,  5.4799e-01,\n",
       "          -1.0417e+00, -6.6949e-01],\n",
       "         ...,\n",
       "         [ 1.0813e-01,  1.8362e-01, -1.0859e-01,  ..., -5.4696e-01,\n",
       "          -3.3135e-02, -2.7123e-01],\n",
       "         [ 1.0813e-01,  1.8362e-01, -1.0859e-01,  ..., -5.4696e-01,\n",
       "          -3.3135e-02, -2.7123e-01],\n",
       "         [ 1.0813e-01,  1.8362e-01, -1.0859e-01,  ..., -5.4696e-01,\n",
       "          -3.3135e-02, -2.7123e-01]],\n",
       "\n",
       "        [[-8.8167e-01,  1.7680e-02, -4.1151e-02,  ...,  4.4539e-01,\n",
       "          -1.2625e-01, -8.7172e-01],\n",
       "         [-5.4331e-01,  2.7468e-01,  1.8942e-01,  ..., -2.2958e-01,\n",
       "          -8.7942e-02, -7.6212e-01],\n",
       "         [-1.6058e-01,  8.7498e-01,  3.9776e-01,  ..., -8.1784e-01,\n",
       "           2.0163e-01, -1.1131e+00],\n",
       "         ...,\n",
       "         [-4.2800e-01, -3.3961e-01, -1.2908e-02,  ...,  4.3719e-01,\n",
       "          -1.1028e-01, -9.0742e-01],\n",
       "         [-4.7467e-02, -2.1601e-01,  1.5909e-01,  ...,  1.1438e-01,\n",
       "          -2.7357e-01, -4.3783e-01],\n",
       "         [-1.3335e-03,  1.1503e-01,  4.1831e-01,  ...,  4.6308e-01,\n",
       "          -5.2847e-02, -4.7912e-01]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1eaf9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.00631714,  0.00939941,  0.01229858, ..., -0.01464844,\n",
       "        -0.04824829, -0.02145386], dtype=float32),\n",
       " array([-0.00143433,  0.01113892,  0.01596069, ..., -0.16726685,\n",
       "        -0.16769409, -0.16738892], dtype=float32),\n",
       " array([-0.16616821, -0.16699219, -0.16567993, ...,  0.00582886,\n",
       "         0.00445557,  0.00680542], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3360,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "850c1f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 17, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['extract_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "57c6f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioTextDataset(audio_dir, textgrid_dir, split='test')\n",
    "inputs = dataset._process_inputs(words, waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "a3eae639",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.basename(file_paths[0])\n",
    "\n",
    "textgrid_path = os.path.join(textgrid_dir, split, file_name.replace(\".wav\", \".TextGrid\"))\n",
    "audio_path = os.path.join(audio_dir, split, file_name.replace('.TextGrid', '.wav'))\n",
    "words = parse_textgrid(textgrid_path)\n",
    "waveform, sample_rate = load_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bb745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'gigaspeech'\n",
    "\n",
    "file_paths = glob.glob(os.path.join(DATASETS_DIR, DATASET, 's/textgrids/test/', '*'))\n",
    "# os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "620d5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = parse_textgrid(file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a562284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC, AutoModel\n",
    "import torch\n",
    "\n",
    "# import model, feature extractor, tokenizer\n",
    "model = AutoModel.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fb7cc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "input_values = feature_extractor(segment.squeeze(), return_tensors=\"pt\").input_values\n",
    "outputs = model(input_values) #.logits[0]\n",
    "pooled_state = pool_embeddings(outputs.last_hidden_state)\n",
    "\n",
    "inputs = processor(raw_audio=audio_sample, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905b6eb",
   "metadata": {},
   "source": [
    "### Use EnCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26765d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from transformers import EncodecModel, AutoProcessor\n",
    "librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")\n",
    "librispeech_dummy = librispeech_dummy.cast_column(\"audio\", Audio(sampling_rate=processor.sampling_rate))\n",
    "audio_sample = librispeech_dummy[-1][\"audio\"][\"array\"]\n",
    "inputs = processor(raw_audio=audio_sample, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "encoder_outputs = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c469ed-c693-4b39-9232-265f2e7312fd",
   "metadata": {},
   "source": [
    "## Create PyTorch Lightning DataModule --> similar to pt dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161fa68c-d410-454b-8d00-e1341d7ba516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPT2 tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader: padding with token id: 50256\n",
      "Loading data from /dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/data/helsinki-prosody/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 109791/109791 [01:19<00:00, 1374.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 7217/109791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 12199/12199 [00:08<00:00, 1462.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 768/12199\n"
     ]
    }
   ],
   "source": [
    "modeling_dir = os.path.join(BASE_DIR, 'code/modeling/joint-clm-prosody')\n",
    "\n",
    "data_module = ProminenceRegressionDataModule(\n",
    "    dataset_name = 'helsinki_prominence',\n",
    "    data_dir = os.path.join(modeling_dir, 'data/heglsinki-prosody/data'),\n",
    "    train_file = 'train_360.txt',\n",
    "    val_file = 'dev.txt',\n",
    "    test_file = 'test.txt',\n",
    "    model_name = \"gpt2\",\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "data_module.setup(stage=\"fit\")\n",
    "\n",
    "# for batch in data_module.train_dataloader():\n",
    "#     sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276d59b-1943-43d8-87da-bf755bd700d3",
   "metadata": {},
   "source": [
    "### Get all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693e4728-a9e6-47d2-b3f0-b698b91e9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62179396-82d8-4625-95d5-6560b0fdeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "\n",
    "for batch in data_module.train_dataloader():\n",
    "    all_labels.append(batch['tokenized_labels'].flatten())\n",
    "all_labels = torch.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4dd3c-a870-4d4d-a422-57305f109f0a",
   "metadata": {},
   "source": [
    "## Model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23795dca-d747-4816-9b89-5def56e3186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b93658d6-5b74-492b-be40-7dd7ad3bac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Huggingface model.\n",
      "Loading pretrained model\n",
      "Using joint loss\n"
     ]
    }
   ],
   "source": [
    "model = ProsodyCausalLM(model_name=\"gpt2\", pretrained=True)\n",
    "# outputs = test.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca745ad-f26f-4ef9-8656-be7d17e66576",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, outputs = model.step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc0833b-6e7e-451d-84b5-0f2d29a0841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Normal(outputs['mu'], outputs['var'].squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2b5613-cfa7-4595-8c6c-07ebf0604b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels, mask = model.get_shifted_labels(\n",
    "    logits=outputs['logits'],\n",
    "    labels=batch['input_ids'],\n",
    "    mask=batch['attention_mask']\n",
    ")\n",
    "\n",
    "# logits = outputs['logits']\n",
    "# labels=batch['input_ids']\n",
    "# mask=batch['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588c108c-c666-412d-8410-d392ecf2943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(logits, -1)\n",
    "correct = (preds == labels) * mask.bool()\n",
    "\n",
    "correct = torch.sum(correct)\n",
    "total = torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7be494-7f1d-4008-b814-f5919b611f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = outputs['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e8b994-6c80-4a49-b844-0c02940555a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prosody labels\n",
    "labels = batch['tokenized_labels']\n",
    "dist = outputs['dist']\n",
    "\n",
    "loss_mask = batch['loss_mask']\n",
    "\n",
    "mu = outputs['mu']\n",
    "var = outputs['var'].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c59cd1f5-9b4e-442a-825a-088f1e11d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.gamma import Gamma\n",
    "\n",
    "shifted_labels = labels[..., 1:].contiguous().view(-1)\n",
    "shifted_mu = mu[..., :-1].contiguous() #.view(-1)\n",
    "shifted_var = var[..., :-1].contiguous()#. view(-1)\n",
    "shifted_mask = loss_mask[..., 1:].contiguous().view(-1)\n",
    "\n",
    "dist = Gamma(shifted_mu, shifted_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de4640c8-2362-4c9b-992d-d9a689c758db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9840e+00, -9.9900e+02,  1.1410e+00,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00],\n",
       "        [ 1.8000e-02,  2.0110e+00, -9.9900e+02,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00],\n",
       "        [ 2.1030e+00,  2.2330e+00,  7.1000e-01,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00],\n",
       "        ...,\n",
       "        [ 1.4910e+00,  1.4910e+00,  1.9500e-01,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00],\n",
       "        [ 2.4880e+00, -9.9900e+02,  1.0660e+00,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00],\n",
       "        [-9.9900e+02, -9.9900e+02,  9.9400e-01,  ..., -1.0000e+00,\n",
       "         -1.0000e+00, -1.0000e+00]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['tokenized_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aaab940b-2e5b-4ebf-8584-3e2d1b17aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Then , across the pale glimmering of sand , Henriot saw a figure moving .',\n",
       " 'The captain , who had so long been a cause of so much discomfort , was gone where the wicked cease from troubling .',\n",
       " 'This first book of his brought him into notice , and served as an introduction to Tycho and to Galileo .',\n",
       " \"Here's what I found at the very site of that final shipwreck !\",\n",
       " 'They stopped and stared at me .',\n",
       " \"'Oh , indeed ! ' said mrs Rogers graciously ; for she was the lodger , and her servant was in waiting , so she was more gracious than intimate , in right of her position .\",\n",
       " \"Well , what of it ? It's not my fault . And he began thinking about the next day .\",\n",
       " 'Let us seek David on the hillsides , tending his flocks with loving care .',\n",
       " 'But he heard a rustling in the branches , and a golden apple fell into his hand .',\n",
       " 'So , comrades , said Myles at last , what shall we do now ?',\n",
       " 'To acquire languages , departed or living in spite of such obstinacies as he now knew them inherently to possess , was a herculean performance which gradually led him on to a greater interest in it than in the presupposed patent process .',\n",
       " 'What is the matter with you ?',\n",
       " \"'There are no women here , ' I said .\",\n",
       " 'I would certainly come with you , replied the Queen , but I am afraid that I cannot walk backwards .',\n",
       " 'An old fright ought to realise she is a fright !',\n",
       " 'I remember the study was close , and I came to get cool .',\n",
       " 'In the mid afternoon of this same day Kennicott was called into the country .',\n",
       " 'But even among savages the processes are much more complicated .',\n",
       " 'The Search after Happiness , a Tale , august first eighteen twenty nine .',\n",
       " 'There now , here they are .',\n",
       " \"Don't you know me ?\",\n",
       " 'Brigitte had been seen in the market place betimes that morning , and , wonderful to relate , she had bought the one hare to be had .',\n",
       " \"She can see at a glance that Lord Warburton isn't .\",\n",
       " 'IS THIS MADNESS ?',\n",
       " 'And that kind of thing is a little overwhelming at short range .',\n",
       " 'For it is true , that late learners cannot so well take the ply ; except it be in some minds , that have not suffered themselves to fix , but have kept themselves open , and prepared to receive continual amendment , which is exceeding rare .',\n",
       " \"Interest in one's own social figure is to some extent a material interest , for other men's love or aversion is a principle read into their acts ; and a social animal like man is dependent on other men's acts for his happiness .\",\n",
       " 'Find out who did that .',\n",
       " \"'How is old Betty Barnes ? '\",\n",
       " 'Respect for a person is properly only respect for the law of honesty , etc of which he gives us an example .',\n",
       " 'Harry , like all the educated boys of the South , honored and admired its public men .',\n",
       " \"'What am I to do ? ' she asked , when , after clapping her hands , the old woman appeared before her .\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cde30175-9f91-4ac0-be5f-699db24a22a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.984,\n",
       "  None,\n",
       "  1.141,\n",
       "  0.0,\n",
       "  1.745,\n",
       "  0.858,\n",
       "  0.003,\n",
       "  1.229,\n",
       "  None,\n",
       "  1.309,\n",
       "  0.596,\n",
       "  0.07,\n",
       "  0.954,\n",
       "  0.57,\n",
       "  None],\n",
       " [0.018,\n",
       "  2.011,\n",
       "  None,\n",
       "  0.061,\n",
       "  0.587,\n",
       "  1.907,\n",
       "  0.867,\n",
       "  0.47,\n",
       "  0.067,\n",
       "  1.827,\n",
       "  0.037,\n",
       "  1.096,\n",
       "  0.189,\n",
       "  1.041,\n",
       "  None,\n",
       "  0.545,\n",
       "  1.721,\n",
       "  0.12,\n",
       "  0.034,\n",
       "  1.686,\n",
       "  1.96,\n",
       "  0.898,\n",
       "  0.183,\n",
       "  None],\n",
       " [2.103,\n",
       "  2.233,\n",
       "  0.71,\n",
       "  0.112,\n",
       "  0.866,\n",
       "  1.541,\n",
       "  0.603,\n",
       "  0.056,\n",
       "  0.842,\n",
       "  None,\n",
       "  0.195,\n",
       "  2.098,\n",
       "  0.113,\n",
       "  0.029,\n",
       "  1.691,\n",
       "  0.044,\n",
       "  1.588,\n",
       "  0.212,\n",
       "  0.018,\n",
       "  0.718,\n",
       "  None],\n",
       " [0.424,\n",
       "  0.033,\n",
       "  0.29,\n",
       "  2.272,\n",
       "  0.028,\n",
       "  0.0,\n",
       "  1.688,\n",
       "  0.823,\n",
       "  0.086,\n",
       "  0.33,\n",
       "  1.032,\n",
       "  0.605,\n",
       "  None],\n",
       " [0.508, 2.466, 0.003, 1.42, 0.0, 0.301, None],\n",
       " [None,\n",
       "  None,\n",
       "  2.403,\n",
       "  None,\n",
       "  None,\n",
       "  4.155,\n",
       "  0.32,\n",
       "  0.487,\n",
       "  0.404,\n",
       "  None,\n",
       "  0.971,\n",
       "  0.165,\n",
       "  1.14,\n",
       "  0.145,\n",
       "  0.0,\n",
       "  None,\n",
       "  1.249,\n",
       "  0.465,\n",
       "  0.0,\n",
       "  2.27,\n",
       "  0.562,\n",
       "  0.0,\n",
       "  None,\n",
       "  1.075,\n",
       "  0.351,\n",
       "  0.75,\n",
       "  0.026,\n",
       "  0.293,\n",
       "  1.181,\n",
       "  0.008,\n",
       "  None,\n",
       "  0.789,\n",
       "  0.282,\n",
       "  0.725,\n",
       "  0.012,\n",
       "  0.072,\n",
       "  None],\n",
       " [2.181,\n",
       "  None,\n",
       "  0.332,\n",
       "  0.068,\n",
       "  0.021,\n",
       "  None,\n",
       "  0.931,\n",
       "  2.765,\n",
       "  0.006,\n",
       "  0.123,\n",
       "  None,\n",
       "  0.02,\n",
       "  0.062,\n",
       "  1.165,\n",
       "  0.482,\n",
       "  0.835,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.495,\n",
       "  None],\n",
       " [0.01,\n",
       "  0.527,\n",
       "  1.162,\n",
       "  0.487,\n",
       "  0.005,\n",
       "  0.0,\n",
       "  2.705,\n",
       "  None,\n",
       "  0.091,\n",
       "  0.333,\n",
       "  0.215,\n",
       "  0.008,\n",
       "  0.262,\n",
       "  2.826,\n",
       "  None],\n",
       " [0.038,\n",
       "  0.0,\n",
       "  0.697,\n",
       "  0.028,\n",
       "  0.886,\n",
       "  0.081,\n",
       "  0.0,\n",
       "  1.287,\n",
       "  None,\n",
       "  0.07,\n",
       "  0.016,\n",
       "  2.44,\n",
       "  2.013,\n",
       "  0.23,\n",
       "  0.166,\n",
       "  0.166,\n",
       "  1.798,\n",
       "  None],\n",
       " [2.136,\n",
       "  None,\n",
       "  0.924,\n",
       "  None,\n",
       "  0.23,\n",
       "  0.927,\n",
       "  0.0,\n",
       "  1.291,\n",
       "  None,\n",
       "  0.678,\n",
       "  0.262,\n",
       "  0.014,\n",
       "  0.4,\n",
       "  1.398,\n",
       "  None],\n",
       " [0.754,\n",
       "  1.382,\n",
       "  1.317,\n",
       "  None,\n",
       "  1.15,\n",
       "  0.569,\n",
       "  0.687,\n",
       "  0.697,\n",
       "  1.078,\n",
       "  0.0,\n",
       "  0.285,\n",
       "  1.027,\n",
       "  0.689,\n",
       "  0.004,\n",
       "  0.903,\n",
       "  0.075,\n",
       "  0.145,\n",
       "  0.694,\n",
       "  0.0,\n",
       "  1.679,\n",
       "  None,\n",
       "  0.243,\n",
       "  0.059,\n",
       "  1.284,\n",
       "  0.951,\n",
       "  0.226,\n",
       "  1.483,\n",
       "  0.27,\n",
       "  0.021,\n",
       "  2.421,\n",
       "  0.233,\n",
       "  0.0,\n",
       "  1.928,\n",
       "  0.296,\n",
       "  0.181,\n",
       "  0.0,\n",
       "  1.202,\n",
       "  0.092,\n",
       "  0.022,\n",
       "  1.382,\n",
       "  1.234,\n",
       "  0.317,\n",
       "  None],\n",
       " [2.379, 0.087, 0.0, 1.863, 0.0, 0.061, None],\n",
       " [None, 0.856, 0.0, 0.191, 0.083, None, None, 0.242, 0.0, None],\n",
       " [0.526,\n",
       "  0.158,\n",
       "  2.656,\n",
       "  0.024,\n",
       "  1.047,\n",
       "  0.089,\n",
       "  None,\n",
       "  0.533,\n",
       "  0.0,\n",
       "  0.198,\n",
       "  None,\n",
       "  0.685,\n",
       "  0.02,\n",
       "  0.207,\n",
       "  2.806,\n",
       "  0.363,\n",
       "  0.07,\n",
       "  2.348,\n",
       "  1.136,\n",
       "  1.453,\n",
       "  None],\n",
       " [0.235, 3.166, 0.482, 0.737, 0.0, 0.82, 0.841, 0.282, 0.0, 0.492, None],\n",
       " [1.528,\n",
       "  0.45,\n",
       "  0.14,\n",
       "  1.807,\n",
       "  0.039,\n",
       "  1.58,\n",
       "  None,\n",
       "  0.449,\n",
       "  0.063,\n",
       "  1.652,\n",
       "  0.049,\n",
       "  0.296,\n",
       "  2.26,\n",
       "  None],\n",
       " [0.984,\n",
       "  0.0,\n",
       "  1.578,\n",
       "  0.682,\n",
       "  0.0,\n",
       "  0.131,\n",
       "  1.024,\n",
       "  0.394,\n",
       "  2.974,\n",
       "  0.199,\n",
       "  0.893,\n",
       "  0.1,\n",
       "  0.0,\n",
       "  1.245,\n",
       "  None],\n",
       " [0.548, 0.066, 1.552, 1.15, 0.036, 2.835, 0.01, 0.601, 0.122, 0.677, None],\n",
       " [0.049,\n",
       "  0.493,\n",
       "  0.153,\n",
       "  2.789,\n",
       "  None,\n",
       "  0.013,\n",
       "  2.892,\n",
       "  None,\n",
       "  1.899,\n",
       "  0.205,\n",
       "  0.325,\n",
       "  0.006,\n",
       "  1.209,\n",
       "  None],\n",
       " [2.451, 0.052, None, 0.657, 1.17, 0.305, None],\n",
       " [0.349, 0.007, 0.008, 2.785, None],\n",
       " [1.376,\n",
       "  0.124,\n",
       "  0.03,\n",
       "  1.208,\n",
       "  0.0,\n",
       "  0.03,\n",
       "  0.541,\n",
       "  0.359,\n",
       "  1.82,\n",
       "  0.148,\n",
       "  0.255,\n",
       "  None,\n",
       "  2.859,\n",
       "  None,\n",
       "  1.291,\n",
       "  0.062,\n",
       "  1.952,\n",
       "  None,\n",
       "  0.853,\n",
       "  0.0,\n",
       "  1.08,\n",
       "  0.021,\n",
       "  0.495,\n",
       "  2.103,\n",
       "  0.0,\n",
       "  0.053,\n",
       "  0.902,\n",
       "  None],\n",
       " [0.084, 0.522, 0.339, 0.0, 0.171, 1.95, 0.071, 0.46, 0.648, 1.992, None],\n",
       " [2.227, 0.256, 0.311, None],\n",
       " [0.932,\n",
       "  1.817,\n",
       "  1.96,\n",
       "  0.0,\n",
       "  0.436,\n",
       "  0.0,\n",
       "  0.019,\n",
       "  0.317,\n",
       "  1.445,\n",
       "  0.0,\n",
       "  0.356,\n",
       "  0.194,\n",
       "  None],\n",
       " [1.491,\n",
       "  0.0,\n",
       "  0.534,\n",
       "  2.67,\n",
       "  None,\n",
       "  0.405,\n",
       "  2.576,\n",
       "  0.384,\n",
       "  0.674,\n",
       "  1.053,\n",
       "  0.047,\n",
       "  0.397,\n",
       "  0.036,\n",
       "  1.283,\n",
       "  None,\n",
       "  2.09,\n",
       "  0.006,\n",
       "  0.411,\n",
       "  0.001,\n",
       "  1.582,\n",
       "  0.032,\n",
       "  None,\n",
       "  0.084,\n",
       "  0.046,\n",
       "  0.845,\n",
       "  1.032,\n",
       "  0.713,\n",
       "  0.027,\n",
       "  1.486,\n",
       "  None,\n",
       "  0.027,\n",
       "  0.21,\n",
       "  1.972,\n",
       "  1.504,\n",
       "  2.344,\n",
       "  None,\n",
       "  0.064,\n",
       "  2.152,\n",
       "  0.176,\n",
       "  0.558,\n",
       "  1.433,\n",
       "  1.263,\n",
       "  None,\n",
       "  0.636,\n",
       "  0.266,\n",
       "  2.071,\n",
       "  1.042,\n",
       "  None],\n",
       " [1.699,\n",
       "  0.51,\n",
       "  0.382,\n",
       "  0.608,\n",
       "  1.359,\n",
       "  1.23,\n",
       "  0.543,\n",
       "  0.0,\n",
       "  1.124,\n",
       "  0.765,\n",
       "  0.144,\n",
       "  1.958,\n",
       "  0.644,\n",
       "  None,\n",
       "  0.06,\n",
       "  1.853,\n",
       "  0.463,\n",
       "  1.383,\n",
       "  1.315,\n",
       "  1.875,\n",
       "  0.649,\n",
       "  0.019,\n",
       "  2.04,\n",
       "  0.175,\n",
       "  0.255,\n",
       "  0.007,\n",
       "  0.701,\n",
       "  None,\n",
       "  0.31,\n",
       "  0.0,\n",
       "  1.839,\n",
       "  0.816,\n",
       "  0.26,\n",
       "  0.401,\n",
       "  0.137,\n",
       "  2.462,\n",
       "  0.214,\n",
       "  1.962,\n",
       "  0.245,\n",
       "  1.255,\n",
       "  0.249,\n",
       "  0.0,\n",
       "  0.808,\n",
       "  None],\n",
       " [2.754, 0.613, 0.27, 0.589, 0.397, None],\n",
       " [None, 2.439, 0.0, 0.249, 0.711, None, None],\n",
       " [1.491,\n",
       "  0.195,\n",
       "  0.0,\n",
       "  0.962,\n",
       "  0.024,\n",
       "  1.137,\n",
       "  1.715,\n",
       "  0.299,\n",
       "  0.008,\n",
       "  0.277,\n",
       "  2.372,\n",
       "  0.0,\n",
       "  1.28,\n",
       "  None,\n",
       "  0.475,\n",
       "  0.263,\n",
       "  0.671,\n",
       "  0.0,\n",
       "  0.47,\n",
       "  0.296,\n",
       "  0.048,\n",
       "  2.142,\n",
       "  None],\n",
       " [2.488,\n",
       "  None,\n",
       "  1.066,\n",
       "  0.515,\n",
       "  0.0,\n",
       "  0.894,\n",
       "  0.388,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.256,\n",
       "  None,\n",
       "  2.265,\n",
       "  0.181,\n",
       "  2.068,\n",
       "  0.142,\n",
       "  0.467,\n",
       "  1.412,\n",
       "  None],\n",
       " [None,\n",
       "  0.994,\n",
       "  0.0,\n",
       "  0.244,\n",
       "  0.831,\n",
       "  None,\n",
       "  None,\n",
       "  3.746,\n",
       "  0.759,\n",
       "  None,\n",
       "  0.118,\n",
       "  None,\n",
       "  0.519,\n",
       "  0.079,\n",
       "  0.734,\n",
       "  0.075,\n",
       "  None,\n",
       "  0.607,\n",
       "  0.0,\n",
       "  0.714,\n",
       "  0.346,\n",
       "  0.638,\n",
       "  0.532,\n",
       "  None]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['original_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d135e915-8959-490d-b8e8-91bc88de2d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_text', 'tokenized_text', 'original_labels', 'tokenized_labels', 'input_ids', 'loss_mask', 'attention_mask', 'word_to_tokens'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d37ce1ae-6cdc-445a-9e28-4e9d683afdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_labels = shifted_labels * shifted_mask + 1e-4  # add small constant for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d2a880b-d686-436e-8617-aba87a3419c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = -dist.log_prob(shifted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1668cf3-f92d-4d1a-a340-18ae1f3d5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_nll = nll * shifted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a891e568-2c53-4ce5-abb4-352c0ef474f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = masked_nll.sum() / shifted_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b026d8e-be4c-4cd6-9abd-e556661675cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1118, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4d22410-5615-4cc8-8466-58c5525e159e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6996, 0.0008, 0.4233,  ..., 0.4181, 0.4164, 0.4170],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec31a3f5-daa8-45db-8414-ea6f3fa42c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels * loss_mask + 1e-4  # add small constant for numerical stability\n",
    "nll = -dist.log_prob(labels)\n",
    "\n",
    "# mask loss\n",
    "masked_nll = nll * loss_mask\n",
    "masked_nll_mean = masked_nll.sum() / loss_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d2ad38f-0d1d-4d15-bfe7-c6aa53456b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96d583ab-264e-4691-9d6a-c44c31263993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1053, -0.0000,  1.6620,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [-0.8416,  2.1437, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [ 2.2663,  3.1142,  1.2448,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        ...,\n",
       "        [ 1.4299,  1.6123,  1.0655,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [ 2.4956, -0.0000,  3.3014,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000,  1.9905,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfbf195f-ee03-4f04-a05b-7d22506dcbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 43])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['loss_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11246245-1a98-44ec-b2f2-388425375330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4254, 5.9616, 3.6534,  ..., 1.2453, 1.2425, 1.2350],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['var'].view(-1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "74c25d02-9fc2-4345-baec-3d61b0c51176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(5e-5 == 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29d3229e-f54e-4134-a8a8-96fee1c6e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1849, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['prosody_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323b7c2-631a-43f9-a024-52a7b13365f0",
   "metadata": {},
   "source": [
    "### Manually perform forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47cb3598-6684-449e-a6d3-effbbb7e64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized labels = prosody values\n",
    "input_embeds = test.get_input_embeddings(\n",
    "    input_ids = batch['input_ids'], \n",
    "    prosody_values = batch['tokenized_labels']\n",
    ")\n",
    "\n",
    "# get outputs from causal LM\n",
    "outputs = test.model.transformer(\n",
    "    inputs_embeds=input_embeds, \n",
    "    attention_mask=batch[\"attention_mask\"], \n",
    ")\n",
    "\n",
    "# get the logits for predicting each item in the sequence\n",
    "logits = test.model.lm_head(outputs.last_hidden_state)\n",
    "\n",
    "# get prosody predictions\n",
    "preds = test.regressor(outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925d14c-2512-4f9e-a208-10fcb7a909fb",
   "metadata": {},
   "source": [
    "### Get distribution over the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0816d01f-9cea-43a7-9856-912a89e396d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split last dimension into mu and var\n",
    "mu, var = torch.chunk(preds, chunks=2, dim=-1)\n",
    "\n",
    "# ensure positivity of var + add a small constant for numerical stability\n",
    "var = F.softplus(var)\n",
    "var = (var + eps).squeeze(-1)\n",
    "\n",
    "# have to squeeze the last dimension due to chunking\n",
    "if test.output_activation is not None:\n",
    "    mu = test.output_activation(mu.squeeze(-1))\n",
    "\n",
    "# Gamma distribution with concentration mu and rate var\n",
    "mu = F.softplus(mu)\n",
    "dist = Gamma(mu, var)\n",
    "preds = dist.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd95a2a-1c74-4e24-8562-bd44c631f455",
   "metadata": {},
   "source": [
    "## Test natural output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb123b62-b3c4-4510-b063-480981fbf862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0272, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.prosody_loss(batch, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb175141-5ed9-45c2-9b3a-c72f2ef8f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prosody labels\n",
    "labels = batch['tokenized_labels']\n",
    "dist = outputs['dist']\n",
    "loss_mask = batch[\"loss_mask\"]  # ignore padded sequence in loss\n",
    "\n",
    "\n",
    "\n",
    "# log likelihood of labels given the distribution\n",
    "labels = labels * loss_mask + 1e-4  # add small constant for numerical stability\n",
    "nll = -dist.log_prob(labels)\n",
    "\n",
    "# mask loss\n",
    "masked_nll = nll * loss_mask\n",
    "masked_nll_mean = masked_nll.sum() / loss_mask.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f5d7c16-5436-4fea-a162-6c2afb7818d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5416, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_nll_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688417bc-2aa3-4495-9c77-efe6c4e17e6d",
   "metadata": {},
   "source": [
    "## Test PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ac8b34c-13f4-48ed-9f4c-b6dfa1138842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "6104bd7b-25e2-45bb-b92c-7943c8d88ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8943fe6-3a46-4648-8334-ba50b6197afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    "    'r': 16,\n",
    "    'lora_alpha': 32,\n",
    "    'lora_dropout': 0.05,\n",
    "    'bias': \"none\",\n",
    "    'task_type': \"CAUSAL_LM\",\n",
    "    'base_model_name_or_path': 'gpt2',\n",
    "    'modules_to_save': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ff2e24-e1ce-4483-8d43-b28dc19a541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 39,187,200 || all params: 163,627,008 || trainable%: 23.9491\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(**lora_config)\n",
    "model = get_peft_model(test.model, config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "1a872a15-ae34-4bff-abfd-7ad6b638c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # peft\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    base_model_name_or_path=model_name,\n",
    "    # modules_to_save=[\"wte\", \"lm_head\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(test.model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "40af7fa8-bc50-4d44-8e88-9bc8dd22b6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"gpt2\"\n",
    "\n",
    "# # loading base model and resizing embedding layers\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # gradient checkpointing enabling\n",
    "# model.enable_input_require_grads()\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "# # peft\n",
    "# config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     base_model_name_or_path=model_name,\n",
    "#     modules_to_save=[\"wte\"] \n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, config)\n",
    "\n",
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "e7a2cdef-db6a-4755-8c53-e35145a2f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable layer: model.transformer.wte.weight\n",
      "Non-trainable layer: model.transformer.wpe.weight\n",
      "Non-trainable layer: model.transformer.h.0.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.0.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.0.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.0.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.0.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.0.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.0.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.0.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.0.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.0.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.0.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.0.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.0.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.0.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.1.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.1.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.1.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.1.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.1.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.1.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.1.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.1.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.1.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.1.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.1.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.1.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.1.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.1.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.2.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.2.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.2.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.2.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.2.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.2.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.2.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.2.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.2.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.2.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.2.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.2.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.2.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.2.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.3.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.3.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.3.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.3.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.3.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.3.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.3.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.3.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.3.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.3.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.3.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.3.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.3.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.3.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.4.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.4.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.4.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.4.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.4.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.4.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.4.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.4.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.4.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.4.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.4.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.4.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.4.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.4.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.5.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.5.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.5.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.5.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.5.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.5.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.5.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.5.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.5.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.5.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.5.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.5.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.5.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.5.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.6.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.6.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.6.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.6.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.6.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.6.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.6.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.6.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.6.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.6.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.6.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.6.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.6.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.6.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.7.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.7.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.7.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.7.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.7.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.7.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.7.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.7.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.7.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.7.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.7.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.7.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.7.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.7.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.8.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.8.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.8.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.8.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.8.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.8.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.8.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.8.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.8.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.8.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.8.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.8.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.8.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.8.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.9.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.9.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.9.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.9.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.9.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.9.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.9.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.9.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.9.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.9.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.9.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.9.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.9.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.9.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.10.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.10.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.10.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.10.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.10.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.10.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.10.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.10.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.10.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.10.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.10.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.10.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.10.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.10.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.11.ln_1.weight\n",
      "Non-trainable layer: model.transformer.h.11.ln_1.bias\n",
      "Non-trainable layer: model.transformer.h.11.attn.c_attn.base_layer.weight\n",
      "Non-trainable layer: model.transformer.h.11.attn.c_attn.base_layer.bias\n",
      "Trainable layer: model.transformer.h.11.attn.c_attn.lora_A.default.weight\n",
      "Trainable layer: model.transformer.h.11.attn.c_attn.lora_B.default.weight\n",
      "Non-trainable layer: model.transformer.h.11.attn.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.11.attn.c_proj.bias\n",
      "Non-trainable layer: model.transformer.h.11.ln_2.weight\n",
      "Non-trainable layer: model.transformer.h.11.ln_2.bias\n",
      "Non-trainable layer: model.transformer.h.11.mlp.c_fc.weight\n",
      "Non-trainable layer: model.transformer.h.11.mlp.c_fc.bias\n",
      "Non-trainable layer: model.transformer.h.11.mlp.c_proj.weight\n",
      "Non-trainable layer: model.transformer.h.11.mlp.c_proj.bias\n",
      "Non-trainable layer: model.transformer.ln_f.weight\n",
      "Non-trainable layer: model.transformer.ln_f.bias\n",
      "Trainable layer: prosody_embed.weight\n",
      "Trainable layer: regressor.weight\n",
      "Trainable layer: regressor.bias\n"
     ]
    }
   ],
   "source": [
    "# Inspect the trainable parameters\n",
    "for name, param in test.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Trainable layer: {name}\")\n",
    "    else:\n",
    "        print(f\"Non-trainable layer: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b9c81b2d-fc00-49a1-86af-a9cc176a4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.base_layer.weight\n",
      "transformer.h.0.attn.c_attn.base_layer.bias\n",
      "transformer.h.0.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.0.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.base_layer.weight\n",
      "transformer.h.1.attn.c_attn.base_layer.bias\n",
      "transformer.h.1.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.1.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.base_layer.weight\n",
      "transformer.h.2.attn.c_attn.base_layer.bias\n",
      "transformer.h.2.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.2.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.base_layer.weight\n",
      "transformer.h.3.attn.c_attn.base_layer.bias\n",
      "transformer.h.3.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.3.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.base_layer.weight\n",
      "transformer.h.4.attn.c_attn.base_layer.bias\n",
      "transformer.h.4.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.4.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.base_layer.weight\n",
      "transformer.h.5.attn.c_attn.base_layer.bias\n",
      "transformer.h.5.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.5.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.base_layer.weight\n",
      "transformer.h.6.attn.c_attn.base_layer.bias\n",
      "transformer.h.6.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.6.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.base_layer.weight\n",
      "transformer.h.7.attn.c_attn.base_layer.bias\n",
      "transformer.h.7.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.7.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.base_layer.weight\n",
      "transformer.h.8.attn.c_attn.base_layer.bias\n",
      "transformer.h.8.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.8.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.base_layer.weight\n",
      "transformer.h.9.attn.c_attn.base_layer.bias\n",
      "transformer.h.9.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.9.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.base_layer.weight\n",
      "transformer.h.10.attn.c_attn.base_layer.bias\n",
      "transformer.h.10.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.10.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.base_layer.weight\n",
      "transformer.h.11.attn.c_attn.base_layer.bias\n",
      "transformer.h.11.attn.c_attn.lora_A.default.weight\n",
      "transformer.h.11.attn.c_attn.lora_B.default.weight\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in test.model.named_parameters():\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e3fb5915-424a-48e2-aa08-77017f43b54c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2LMHeadModel' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[408], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mtrainable:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m (layer\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.10/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2LMHeadModel' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "for layer in test.model.layers:\n",
    "    if layer.trainable:\n",
    "        print (layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "09672b9e-2bc9-4184-9420-25eed0daacdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TaskType.FEATURE_EXTRACTION: 'FEATURE_EXTRACTION'>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskType.FEATURE_EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "545b0a9a-8a8d-49de-8fbd-956f05dfde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['This is a']\n",
    "# inputs = [f'{ins} {tokenizer.mask_token}' for ins in inputs]\n",
    "\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs, output_hidden_states=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
