{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb6bacc-61db-4eee-a7b1-7dca6e709290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /dartfs-hpc/rc/home/w/f003rjw/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5717034-8a60-4324-a0a8-2766f6a03dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(DATASETS_DIR, 'deniz-readinglistening/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d9622e86-5deb-4437-9c7a-fb5c2a0ef640",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = ['listening', 'reading']\n",
    "split = ['trn', 'val']\n",
    "\n",
    "test_data = sorted(glob.glob(os.path.join(src_dir, f'responses/subject01*{dtypes[0]}*{split[0]}*')))\n",
    "fname = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f5d7f4a4-a8fe-48ea-a1eb-919b53822850",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'story_01'\n",
    "\n",
    "func_data = dict()\n",
    "with h5py.File(fname) as hf:\n",
    "    if key is None:\n",
    "        for k in hf.keys():\n",
    "            print(\"{} will be loaded\".format(k))\n",
    "            func_data[k] = hf[k][()]\n",
    "    else:\n",
    "        func_data[key] = hf[key][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6652fd-889b-4768-8fdb-bfacb23154c7",
   "metadata": {},
   "source": [
    "## Organize into BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d356c10b-06fe-439d-b6f5-f1b943cc8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def load_sparse_array(fname, varname):\n",
    "    \"\"\"Load a numpy sparse array from an hdf file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname: string\n",
    "        file name containing array to be loaded\n",
    "    varname: string\n",
    "        name of variable to be loaded\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function relies on variables being stored with specific naming\n",
    "    conventions, so cannot be used to load arbitrary sparse arrays.\n",
    "\n",
    "    By Mark Lescroart\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    with h5py.File(fname) as hf:\n",
    "        try:\n",
    "            data = (hf['%s_data'%varname], hf['%s_indices'%varname], hf['%s_indptr'%varname])\n",
    "            sparsemat = scipy.sparse.csr_matrix(data, shape=hf['%s_shape'%varname])\n",
    "        except:\n",
    "            if varname == 'voxel_to_fsaverage':\n",
    "                left = 'vox_to_fsavg_left'\n",
    "                right = 'vox_to_fsavg_right'\n",
    "                \n",
    "                lh_data = (hf['%s_data'%left], hf['%s_indices'%left], hf['%s_indptr'%left])\n",
    "                lh_mat = scipy.sparse.csr_matrix(lh_data, shape=hf['%s_shape'%left])\n",
    "\n",
    "                \n",
    "                rh_data = (hf['%s_data'%right], hf['%s_indices'%right], hf['%s_indptr'%right])\n",
    "                rh_mat = scipy.sparse.csr_matrix(rh_data, shape=hf['%s_shape'%right])\n",
    "\n",
    "                sparsemat = scipy.sparse.hstack([lh_mat.T, rh_mat.T]).T\n",
    "    return sparsemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6a744ffb-19c8-4310-a36c-900cc2e354ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-02\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-03\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-04\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-05\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-06\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-07\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "sub-08\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n",
      "alternateithicatom\n",
      "avatar\n",
      "howtodraw\n",
      "legacy\n",
      "life\n",
      "myfirstdaywiththeyankees\n",
      "naked\n",
      "odetostepfather\n",
      "souls\n",
      "undertheinfluence\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from scipy import stats, sparse\n",
    "\n",
    "src_dir = os.path.join(DATASETS_DIR, 'deniz-readinglistening/src/')\n",
    "derivatives_dir = os.path.join(DATASETS_DIR, 'deniz-readinglistening/derivatives/dark-matter-preproc/')\n",
    "sub_list = [i for i in range(1,9)]\n",
    "splits = ['trn', 'val']\n",
    "dtypes = ['listening', 'reading']\n",
    "\n",
    "TASK_INFO = {\n",
    "\t'tasks': [\n",
    "\t\t'alternateithicatom', 'avatar', 'legacy', 'odetostepfather', 'souls',\n",
    "\t\t'howtodraw', 'myfirstdaywiththeyankees', 'naked', 'undertheinfluence', 'life',\n",
    "\t\t'exorcism', 'fromboyhoodtofatherhood', 'sloth', 'stagefright', 'tildeath',\n",
    "\t\t'adollshouse', 'adventuresinsayingyes', 'buck', 'haveyoumethimyet', 'inamoment', 'theclosetthatateeverything',\n",
    "\t\t'eyespy', 'hangtime', 'itsabox', 'swimmingwithastronauts', 'thatthingonmyarm', 'wheretheressmoke'\n",
    "\t],\n",
    "\t'n_trs': [\n",
    "\t\t354, 378, 410, 414, 360, \n",
    "\t\t365, 368, 433, 314, 440,\n",
    "\t\t478, 357, 448, 304, 334,\n",
    "\t\t252, 402, 343, 507, 215, 325,\n",
    "\t\t389, 334, 365, 395, 444, 300\n",
    "\t]\n",
    "}\n",
    "\n",
    "story_mappings = {\n",
    "    'story_01': 'alternateithicatom',\n",
    "    'story_02': 'avatar',\n",
    "    'story_03': 'howtodraw',\n",
    "    'story_04': 'legacy',\n",
    "    'story_05': 'life',\n",
    "    'story_06': 'myfirstdaywiththeyankees',\n",
    "    'story_07': 'naked',\n",
    "    'story_08': 'odetostepfather',\n",
    "    'story_09': 'souls',\n",
    "    'story_10': 'undertheinfluence',\n",
    "    'story_11': 'wheretheressmoke',\n",
    "}\n",
    "\n",
    "trim_trs = 5\n",
    "\n",
    "for sub_num in sub_list:\n",
    "\n",
    "    sub = f'sub-0{sub_num}'\n",
    "    sub_func_dir = os.path.join(derivatives_dir, sub, 'func')\n",
    "    sub_mapper_dir = os.path.join(derivatives_dir, sub, 'mappers')\n",
    "\n",
    "    if not os.path.exists(sub_func_dir):\n",
    "        os.makedirs(sub_func_dir)\n",
    "\n",
    "    if not os.path.exists(sub_mapper_dir):\n",
    "        os.makedirs(sub_mapper_dir)\n",
    "\n",
    "    # load and save the mapper file to fsaverage\n",
    "    sub_mapper_fn = glob.glob(os.path.join(src_dir, f'mappers/subject0{sub_num}*'))[0]\n",
    "    sub_fsaverage_mapper = load_sparse_array(sub_mapper_fn, 'voxel_to_fsaverage')\n",
    "\n",
    "    mapper_out_fn = os.path.join(sub_mapper_dir, f'{sub}_mapper-fsaverage.npz')\n",
    "    sparse.save_npz(mapper_out_fn, sub_fsaverage_mapper)\n",
    "\n",
    "    print (sub)\n",
    "    \n",
    "    # go through datatype and split \n",
    "    for dtype, split in product(dtypes, splits):\n",
    "        ds_fn = sorted(glob.glob(os.path.join(src_dir, f'responses/subject0{sub_num}*{dtype}*{split}*')))[0]\n",
    "\n",
    "        # get the current file\n",
    "        with h5py.File(ds_fn) as hf:\n",
    "            \n",
    "            # keeps track of the validation runs\n",
    "            if split == 'val':\n",
    "                story_name = 'wheretheressmoke'\n",
    "                ds = hf['story_11'][()].squeeze()\n",
    "                \n",
    "                run_counter = 1\n",
    "\n",
    "                for i, ds_run in enumerate(ds):\n",
    "                    \n",
    "                    sub_fn = f'{sub}_ses-{dtype}_task-{story_name}_run-{i+1}_space-orig_desc-clean_trimmed-zscored.npy'\n",
    "                    sub_fn = os.path.join(sub_func_dir, sub_fn)\n",
    "\n",
    "                    # grab the story from the loaded file --> slice off first 5 trs and then zscore\n",
    "                    ds_run = ds_run[story_slice, :]\n",
    "                    ds_run = stats.zscore(ds_run, axis=0)\n",
    "\n",
    "                    np.save(sub_fn, ds_run)\n",
    "            else:\n",
    "                # go through each story\n",
    "                for key, story_name in story_mappings.items():\n",
    "                    # for all stories except validation story\n",
    "                    if story_name != 'wheretheressmoke':\n",
    "                        \n",
    "                        print (story_name)\n",
    "                        ds = hf[key][()].squeeze()\n",
    "                        \n",
    "                        # prepare the slice for zscoring\n",
    "                        story_index = TASK_INFO['tasks'].index(story_name)\n",
    "                        n_trs = TASK_INFO['n_trs'][story_index]\n",
    "                        story_slice = slice(trim_trs, trim_trs + n_trs)\n",
    "                        \n",
    "                        sub_fn = f'{sub}_ses-{dtype}_task-{story_name}_space-orig_desc-clean_trimmed-zscored.npy'\n",
    "                        sub_fn = os.path.join(sub_func_dir, sub_fn)\n",
    "                        \n",
    "                        # grab the story from the loaded file --> slice off first 5 trs and then zscore\n",
    "                        ds = hf[key][()].squeeze()\n",
    "                        ds = ds[story_slice, :]\n",
    "                        ds = stats.zscore(ds, axis=0)\n",
    "\n",
    "                        np.save(sub_fn, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c29d5658-08ec-42b3-b054-57ad306ddac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = list(story_mappings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2f1a04b8-8e08-468a-9d9e-a9e667addeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avatar', 'legacy', 'naked', 'souls', 'wheretheressmoke']\n",
      "['alternateithicatom', 'howtodraw', 'life', 'myfirstdaywiththeyankees', 'odetostepfather', 'undertheinfluence']\n"
     ]
    }
   ],
   "source": [
    "train_split = sorted(np.random.choice(stories, 5, replace=False))\n",
    "test_split = sorted(set(stories).difference(train_split))\n",
    "\n",
    "print (train_split)\n",
    "print (test_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
