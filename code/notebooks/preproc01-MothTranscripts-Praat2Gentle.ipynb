{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ede745",
   "metadata": {},
   "source": [
    "# Moth Transcripts to Gentle\n",
    "\n",
    "The Huth Moth transcripts are provided within Praat. There are two issues with this format:\n",
    "1. There is no joint transcript including punctuation (allowing us to present the next-word prediction framework)\n",
    "2. Our pipeline uses Gentle as its starting point to process files\n",
    "\n",
    "We load the Praat files and align it with a transcript generated through ChatGPT (adjusting mismatched words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6601b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os, sys, glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from praatio import textgrid as tgio\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from text_utils import strip_punctuation\n",
    "# from text_utils import get_pos_tags, get_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdc80473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_textgrid(praat_fn):\n",
    "    '''\n",
    "    Load a praat textgrid file using PraatIO\n",
    "    '''\n",
    "    \n",
    "    # things to remove from the textgrid (indicates laughing, chewing, pauses etc)\n",
    "    REMOVE_CHARACTERS = ['sp', '{BR}', '{LG}', '{CG}', '{LS}', '{NS}', '{SL}', '{IG}', 'PAUSE']\n",
    "    \n",
    "    # open the textgrid\n",
    "    tg = tgio.openTextgrid(praat_fn, includeEmptyIntervals=False, reportingMode=\"warning\") \n",
    "    \n",
    "    # go through each entry at the word tier, remove the items\n",
    "    textgrid = [x for x in tg.getTier('word').entries if x[-1] not in REMOVE_CHARACTERS]\n",
    "    \n",
    "    return textgrid\n",
    "\n",
    "def load_transcription(transcript_fn):\n",
    "    \n",
    "    with open(transcript_fn, 'r') as f: #open the file\n",
    "        contents = f.readlines() #put the lines to a variable (list).\n",
    "        \n",
    "    # get the transcription stripped of punctuation\n",
    "    words_transcribed = strip_punctuation(contents).split()\n",
    "    \n",
    "    return contents, words_transcribed\n",
    "\n",
    "def textgrid_to_gentle(praat_fn, transcript_fn):\n",
    "    '''\n",
    "    Transform Moth dataset textgrid files into gentle format\n",
    "    '''\n",
    "    \n",
    "    textgrid = load_clean_textgrid(praat_fn)\n",
    "    \n",
    "    contents, words_transcribed = load_transcription(transcript_fn)\n",
    "    \n",
    "    assert (len(textgrid) == len(words_transcribed))\n",
    "    \n",
    "    # create the dictionary to store things in\n",
    "    # put the transcript in the raw form\n",
    "    align = {}\n",
    "    align['transcript'] = contents[0]\n",
    "    align['words'] = []\n",
    "    \n",
    "    # Taken from Kaldi metasentence tokenizer\n",
    "    # splits the transcript based on any punctuation besides for apostrophes and hyphens\n",
    "    regex_split_pattern = r'(\\w|\\â€™\\w|\\'\\w|\\-\\w)+'\n",
    "    \n",
    "    iterator = list(re.finditer(regex_split_pattern, ''.join(contents), re.UNICODE))\n",
    "    n_items = len(list(iterator))\n",
    "    \n",
    "    # make sure the iterator matches the length\n",
    "    assert (len(textgrid) == len(textgrid) == len(words_transcribed))\n",
    "    \n",
    "    # if all matches we're good to go\n",
    "    for tg_info, m in zip(textgrid, iterator):\n",
    "        # span of the word in characters relative to the overall string\n",
    "        start_offset, end_offset = m.span()\n",
    "        word = m.group()\n",
    "        \n",
    "        word_align = {\n",
    "            'alignedWord': word.lower(),\n",
    "            \"case\": \"success\",\n",
    "            'word': word,\n",
    "            'start': tg_info[0],\n",
    "            'end': tg_info[1],\n",
    "            \"startOffset\": start_offset,\n",
    "            \"endOffset\": end_offset,\n",
    "        }\n",
    "        \n",
    "        align['words'].append(word_align)\n",
    "        \n",
    "    return align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0e456",
   "metadata": {},
   "source": [
    "## Set paths \n",
    "\n",
    "These are paths to the main directory and the stimulus directory\n",
    "\n",
    "CHANGE THE PATH BELOW TO MATCH YOUR DIRECTORY --> FinnLabTasks/transcript_alignment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d50ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/'\n",
    "stim_dir = os.path.join(base_dir, 'stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed86e4c",
   "metadata": {},
   "source": [
    "## Load Praat files\n",
    "\n",
    "We first get all the filenames of TextGrid files within the stimulus directory. We also print out the number of files within this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35c06145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in dataset: 28\n"
     ]
    }
   ],
   "source": [
    "praat_fns = sorted(glob.glob(os.path.join(stim_dir, 'praat', '*.TextGrid')))\n",
    "\n",
    "print (f'Total files in dataset: {len(praat_fns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ae474",
   "metadata": {},
   "source": [
    "<b>Note:</b> This is <b>very</b> likely not to work on the first time. Follow the steps below to get the file to load!\n",
    "\n",
    "We are going to load a Praat TextGrid file. This will probably not work on the first time due to overlapping timestamps. To address this, do the following:\n",
    "1. Open the .TextGrid file in a text editor (e.g., TextEdit, SublimeText)\n",
    "2. Look at the Python error -- you will need to manually adjust these overlapping times. Copy the first number in the second parentheses:\n",
    "    - <b>Example error:</b> Two intervals in the same tier overlap in time: (START_1, END_1, sp) and (START_2, END_2, B)\n",
    "    - For this error, copy the number \"START_2\"\n",
    "3. Go to the text editor, and search (cmd + F) for the copied number (e.g., \"START_2\").\n",
    "4. Adjust the word/phoneme before's end time (e.g., END_1) to match the copied number (\"START_2\").\n",
    "5. Save the file and rerun the code\n",
    "6. Repeat for as many times until the file loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "244a517b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus name: wheretheressmoke\n",
      "Successfully loaded Praat file!\n"
     ]
    }
   ],
   "source": [
    "# select a file number to load -- we then select that file from the list of alphabetized file names\n",
    "file_num = -1\n",
    "praat_fn = praat_fns[file_num]\n",
    "\n",
    "# now grab the current filename as a path -- print out only the filename (no extension)\n",
    "filepath = Path(praat_fn)\n",
    "stim_name = filepath.stem\n",
    "print (f'Stimulus name: {filepath.stem}')\n",
    "\n",
    "# attempt to load the praat file -- if this doesn't work, follow the steps above \n",
    "tg = tgio.openTextgrid(praat_fns[file_num], includeEmptyIntervals=False, reportingMode=\"warning\") \n",
    "\n",
    "print (f'Successfully loaded Praat file!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c0f2a",
   "metadata": {},
   "source": [
    "## Adjust the words to have punctuation\n",
    "\n",
    "After loading the transcript using Praat, we concatenate all the transcript words and pass it to ChatGPT to ensure punctuation. Then we need to go through comparing word by word making sure of the following:\n",
    "-  The new transcript matches the original number of words\n",
    "- Words are spelled correctly (as full words)\n",
    "\n",
    "This cell below will print out all the words of the TextGrid as a string. You will need to do the following:\n",
    "1. Open ChatGPT: https://chat.openai.com/chat\n",
    "2. Type the following instructions: \"Add punctuation and capitalization to the following but change nothing else:\"\n",
    "3. Copy and paste the transcript below <i>after</i> the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13c7d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/stimuli/praat/wheretheressmoke.TextGrid'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "praat_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64d02c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I REACHED OVER AND SECRETLY UNDID MY SEATBELT AND WHEN HIS FOOT HIT THE BRAKE AT THE RED LIGHT I FLUNG OPEN THE DOOR AND I RAN I HAD NO SHOES ON I WAS CRYING I HAD NO WALLET BUT I WAS OKAY BECAUSE I HAD MY CIGARETTES AND I DIDN'T WANT ANY PART OF FREEDOM IF I DIDN'T HAVE MY CIGARETTES WHEN YOU LIVE WITH SOMEONE WHO HAS A TEMPER A VERY BAD TEMPER A VERY VERY BAD TEMPER YOU LEARN TO PLAY AROUND THAT YOU LEARN THIS TIME I'LL PLAY POSSUM AND NEXT TIME I'LL JUST BE REAL NICE OR I'LL SAY YES TO EVERYTHING OR YOU MAKE YOURSELF SCARCE OR YOU RUN AND THIS WAS ONE OF THE TIMES WHEN YOU JUST RUN AND AS I WAS RUNNING I THOUGHT THIS WAS A GREAT PLACE TO JUMP OUT BECAUSE THERE WERE BIG LAWNS AND THERE WERE CUL-DE-SACS AND SOMETIMES HE WOULD COME AFTER ME AND DRIVE AND YELL STUFF AT ME TO GET BACK IN GET BACK IN AND I WAS LIKE NO I'M OUT OF HERE THIS IS GREAT AND I WENT AND HID BEHIND A CABANA AND HE LEFT AND I HAD MY CIGARETTES AND UH I STARTED TO WALK IN THIS BEAUTIFUL NEIGHBORHOOD IT WAS TEN-THIRTY AT NIGHT AND IT WAS SILENT AND LOVELY AND THERE WAS NO SOUND EXCEPT FOR SPRINKLERS CH CH CH CH CH CH CH CH AND I WAS ENJOYING MYSELF AND ENJOYING THE ABSENCE OF ANGER AND ENJOYING THESE FEW HOURS I KNEW I'D HAVE OF FREEDOM AND JUST TO PERFECT IT I THOUGHT I'LL HAVE A SMOKE AND THEN IT OCCURRED TO ME WITH HORRIFYING SPEED I DON'T HAVE A LIGHT JUST THEN AS IF IN ANSWER I SEE A FIGURE UP AHEAD WHO IS THAT IT'S NOT HIM OKAY THEY DON'T HAVE A DOG WHO IS THAT WHAT UH WHAT ARE THEY DOING OUT ON THIS SUBURBAN STREET AND THE PERSON COMES CLOSER AND I COULD SEE IT'S A WOMAN AND THEN I CAN SEE SHE HAS HER HANDS IN HER FACE OH SHE'S CRYING AND THEN SHE SEES ME AND SHE COMPOSES HERSELF AND SHE GETS CLOSER AND I SEE SHE HAS NO SHOES ON SHE HAS NO SHOES ON AND SHE'S CRYING AND SHE'S OUT ON THE STREET STREET I RECOGNIZE HER THOUGH I'VE NEVER MET HER AND JUST AS SHE PASSES ME SHE SAYS YOU GOT A CIGARETTE AND I SAY YOU GOT A LIGHT AND SHE SAYS DAMN I HOPE SO AND THEN FIRST SHE DIGS INTO HER CUTOFFS IN THE FRONT NOTHING AND THEN DIGS IN THE BACK AND THEN SHE HAS THIS VEST ON THAT HAS FIFTY MILLION LITTLE POCKETS ON IT AND SHE'S CHECKING AND CHECKING AND IT'S LOOKING BAD IT'S LOOKING VERY BAD SHE DIGS BACK IN THE FRONT AGAIN DEEP DEEP AND SHE PULLS OUT A PACK OF MATCHES THAT HAD BEEN LAUNDERED AT LEAST ONCE UGH WE OPEN IT UP AND THERE IS ONE MATCH INSIDE OKAY OH MY GOD THIS TAKES ON IT'S LIKE NASA NOW WE GOT TO LIKE OH HOW ARE WE GONNA DO IT OKAY AND WE WE HUNKER DOWN WE CROUCH ON THE GROUND AND WHERE'S THE WIND COMING FROM WE'RE STOPPING I TAKE OUT MY CIGARETTES LET'S GET THE CIGARETTES READY OH MY BRAND SHE SAYS NOT SURPRISING AND WE BOTH HAVE OUR CIGARETTES AT THE READY SHE STRIKES ONCE NOTHING SHE STRIKES AGAIN YES FIRE PUFF INHALE MM SWEET KISS OF THAT CIGARETTE AND WE SIT THERE AND WE'RE LOVING THE NICOTINE AND WE BOTH NEED THIS RIGHT NOW I CAN TELL THE NIGHT'S BEEN TOUGH IMMEDIATELY WE START TO REMINISCE ABOUT OUR THIRTY-SECOND RELATIONSHIP I DIDN'T THINK THAT WAS GONNA HAPPEN ME NEITHER OH MAN THAT WAS CLOSE OH I'M SO LUCKY I SAW YOU YEAH THEN SHE SURPRISES ME BY SAYING WHAT WAS THE FIGHT ABOUT AND I SAY WHA WHAT ARE THEY ALL ABOUT AND SHE SAID I KNOW WHAT YOU MEAN SHE SAID WAS IT A BAD ONE AND AND I SAID YOU KNOW LIKE MEDIUM SHE SAID OH AND WE START TO TRADE STORIES ABOUT OUR LIVES WE'RE BOTH FROM UP NORTH WE'RE BOTH KIND OF NEWISH TO THE NEIGHBORHOOD THIS IS IN FLORIDA WE BOTH WENT TO COLLEGE NOT GREAT COLLEGES BUT MAN WE GRADUATED AND I'M ACTUALLY FINDING MYSELF A LITTLE JEALOUS OF HER BECAUSE SHE HAS THIS REALLY COOL JOB WASHING DOGS SHE HAD HORSES BACK HOME AND SHE REALLY LOVES ANIMALS AND SHE WANTS TO BE A VET AND I'M LIKE MAN YOU'RE HALFWAY THERE I'M A WAITRESS AT AN ICE CREAM PARLOR SO UM THAT'S NOT I DON'T KNOW WHERE I WANT TO BE BUT I KNOW IT'S NOT THAT AND THEN IT GETS A LITTLE DEEPER AND WE SHARE SOME OTHER STUFF ABOUT WHAT OUR LIVES ARE LIKE THINGS THAT I CAN'T EVER TELL PEOPLE AT HOME THIS GIRL I CAN TELL HER THE REALLY UGLY STUFF AND SHE STILL UNDERSTANDS HOW IT CAN STILL BE PRETTY SHE UNDERSTANDS LIKE HOW NICE HE'S GONNA BE WHEN I GET HOME AND HOW SWEET THAT'LL BE WE ARE CHAIN-SMOKING OFF EACH OTHER OH THAT'S ALMOST OUT COME ON AND WE WE GO THROUGH THIS ENTIRE PACK UNTIL IT'S GONE AND THEN I SAY YOU KNOW WHAT UH THIS IS A LITTLE FUNNY BUT YOU'RE GONNA HAVE TO SHOW ME THE WAY TO GET HOME BECAUSE ALTHOUGH I'M TWENTY-THREE YEARS OLD I DON'T HAVE MY DRIVER'S LICENSE YET AND I JUST JUMPED OUT RIGHT WHEN I NEEDED TO AND SHE SAYS WELL WHY DON'T YOU COME BACK TO MY HOUSE AND I'LL GIVE YOU A RIDE I SAY OKAY GREAT AND WE START WALKING AND UH WE GET TO THIS UM LOTS OF UH LIGHTS AND UH THE ROADS ARE GETTING WIDER AND WIDER AND THERE'S MORE CARS AND I SEE UM LOTS OF STORES YOU KNOW LAUNDROMATS AND DOLLAR STORES AND EMERGECENTERS AND THEN WE CROSS OVER US ONE AND UH SHE LEADS ME TO SOME PLACE AND I THINK NO BUT YES CARL'S EFFICIENCY APARTMENTS THIS GIRL LIVES THERE AND IT'S HORRIBLE AND IT'S LIT UP SO BRIGHT JUST TO ILLUMINATE THE HORRIBLENESS OF IT IT'S THE KIND OF PLACE WHERE YOU DRIVE YOUR CAR RIGHT UP AND THE DOOR'S RIGHT THERE AND THERE'S FIFTY MILLION CIGARETTE BUTTS OUTSIDE AND THERE'S LIKE DOORS ONE THROUGH SEVEN AND YOU KNOW BEHIND EVERY SINGLE DOOR THERE'S SOME HORRIBLE MISERY GOING ON THERE'S SOMEONE CRYING OR DRUNK OR LONELY OR CRUEL AND I THINK OH GOD SHE LIVES HERE HOW AWFUL WE GO TO THE DOOR DOOR NUMBER FOUR AND SHE VERY VERY QUIETLY KEYS IN AS SOON AS THE DOOR OPENS I HEAR THE BLARE OF TELEVISION COME OUT AND ON THE BLUE LIGHT OF THE TELEVISION THE SMOKE OF A HUNDRED CIGARETTES IN THAT LITTLE CRACK OF LIGHT AND I HEAR THE MAN AND HE SAYS WHERE WERE YOU AND SHE SAYS NEVER MIND I'M BACK AND HE SAYS YOU ALRIGHT AND SHE SAYS YEAH I'M ALRIGHT AND THEN SHE TURNS TO ME AND SAYS YOU WANT A BEER AND HE SAYS WHO THE FUCK IS THAT AND SHE PULLS ME OVER AND HE SEES ME AND HE SAYS OH HEY I'M NOT A THREAT JUST THEN HE TAKES A DRAG OF HIS CIGARETTE A VERY HARD HARD DRAG YOU KNOW THE KIND THAT MAKES THE END OF IT REALLY HEAT UP HOT HOT HOT AND LONG AND IT'S A LITTLE SCARY AND I FOLLOW THE CIGARETTE DOWN BECAUSE I'M AFRAID OF THAT HEAD FALLING OFF AND I'M SURPRISED WHEN I SEE IN THE CROOK OF HIS ARM A LITTLE BOY SLEEPING A TODDLER AND I THINK AND JUST THEN THE GIRL REACHES UNDERNEATH THE BED AND TAKES OUT A CARTON AND SHE TAPS OUT THE LAST S PACK OF CIGARETTES IN THERE AND ON THE WAY UP SHE KISSES THE LITTLE BOY AND THEN SHE KISSES THE MAN AND THE MAN SAYS AGAIN YOU ALRIGHT AND SHE SAYS YEAH I'M JUST GONNA GO OUT AND SMOKE WITH HER AND SO WE GO OUTSIDE AND SIT AMONGST THE CIGARETTE BUTTS AND SMOKE AND I SAY WOW THAT'S YOUR LITTLE BOY AND SHE SAYS YEAH ISN'T HE BEAUTIFUL AND I SAY YEAH HE IS HE IS BEAUTIFUL HE'S MY LIGHT HE KEEPS ME GOING SHE SAYS WE FINISH OUR CIGARETTES SHE FINISHES HER BEER I DON'T HAVE A BEER BECAUSE I CAN'T GO HOME WITH BEER ON MY BREATH AND SHE GOES INSIDE TO GET THE KEYS SHE TAKES TOO LONG IN THERE GETTING THE KEYS AND I THINK SOMETHING MUST BE WRONG AND SHE COMES OUT AND SHE SAYS LOOK I'M REALLY SORRY BUT UM LIKE WE DON'T HAVE ANY GAS IN THE CAR IT'S ALREADY ON E AND HE NEEDS TO GET TO WORK IN THE MORNING AND UM I YOU KNOW I I'M GONNA BE WALK TO WORK AS IT IS SO WHAT I DID WAS THOUGH HERE LOOK I DREW OUT THIS MAP FOR YOU AND YOU'RE REALLY YOU'RE LIKE A MILE AND A HALF FROM HOME AND UM IF YOU WALK THREE STREETS OVER YOU'LL BE BACK ON THAT PRETTY STREET AND YOU JUST TAKE THAT AND YOU'LL BE FINE AND SHE ALSO HAS WRAPPED UP IN TOILET PAPER SEVEN CIGARETTES FOR ME A THIRD OF HER PACK I NOTE AND A NEW PACK OF MATCHES AND SHE TELLS ME GOODBYE AND THAT WAS GREAT TO MEET YOU AND HOW LUCKY AND THAT WAS FUN AND YOU KNOW LET'S BE FRIENDS AND I SAY YEAH OKAY AND I WALK AWAY BUT I KIND OF KNOW WE'RE NOT GONNA BE FRIENDS I MIGHT NOT EVER SEE HER AGAIN AND I KIND OF KNOW I DON'T THINK SHE'S EVER GOING TO BE A VET AND I CROSS AND I WALK AWAY AND MAYBE THIS WOULD'VE SEEMED LIKE A VISIT FROM MY POSSIBLE FUTURE AND SCARY BUT IT KIND OF DOES THE OPPOSITE ON THE WALK HOME I'M LIKE MAN THAT WAS REALLY GRIM OVER THERE AND I'M GOING HOME NOW TO MY NICE BOYFRIEND AND HE IS GONNA BE SO EXTRA HAPPY TO SEE ME AND WE HAVE A ONE-BEDROOM APARTMENT AND WE HAVE TWO TREES AND THERE'S A YARD AND WE HAVE THIS JAR IN THE KITCHEN WHERE THERE'S LIKE LOOSE MONEY THAT WE CAN USE FOR ANYTHING LIKE WE WOULD NEVER EVER RUN OUT OF GAS AND UM I DON'T HAVE A BABY YOU KNOW SO I CAN LEAVE WHENEVER I WANT I SMOKED ALL SEVEN CIGARETTES ON THE WAY HOME AND PEOPLE WHO HAVE NEVER SMOKED CIGARETTES JUST THINK ICK DISGUSTING AND POISON BUT UNLESS YOU'VE HAD THEM AND HELD THEM DEAR YOU DON'T KNOW HOW GREAT THEY CAN BE AND WHAT FRIENDS AND COMFORT AND KINSHIP THEY CAN BRING IT TOOK ME A LONG TIME TO QUIT THAT BOYFRIEND AND THEN TO QUIT SMOKING AND UH SOMETIMES I STILL MISS THE SMOKING\n"
     ]
    }
   ],
   "source": [
    "def get_textgrid_words(textgrid):\n",
    "    '''\n",
    "    Extracts the words in the textgrid to show in a legible format\n",
    "    '''\n",
    "    words = [x[-1] for x in textgrid]\n",
    "    return words\n",
    "\n",
    "# load the textgrid removing all enunciations\n",
    "textgrid = load_clean_textgrid(praat_fn)\n",
    "\n",
    "# gets all the words in the textgrid as an interpretable string\n",
    "tg_words = get_textgrid_words(textgrid)\n",
    "print (' '.join(tg_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b0cf1",
   "metadata": {},
   "source": [
    "## Create a transcript file\n",
    "\n",
    "ChatGPT will then print out a verion of the transcript with punctuation. However, we need to double-check that the words match the original transcript. After getting the transcript from ChatGPT:\n",
    "1. Go to the directory '/stimuli/transcripts/' \n",
    "2. Create a text file names \"STIMULUSNAME.txt\" (where STIMULUSNAME is the name of the stimulus - printed out above)\n",
    "3. Paste the transcript from ChatGPT into the text file\n",
    "\n",
    "You should now be able to load the file in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbb04d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_praat_to_transcript(words_original, words_transcribed):\n",
    "    '''\n",
    "    Compares words from TextGrid and ChatGPT transcript word by word\n",
    "    '''\n",
    "    \n",
    "    for i, (word_orig, word_transc) in enumerate(zip(words_original, words_transcribed)):\n",
    "        if word_orig.lower() != word_transc.lower():\n",
    "            print (f'Word index: {i}')\n",
    "            print (f'TextGrid word: {word_orig}')\n",
    "            print (f'Transcript word: {word_transc}')\n",
    "            print (f'Word context: {words_original[i-5:i+5]}')\n",
    "            break\n",
    "    \n",
    "    if i+1 == len(words_original):\n",
    "        print (f'Finished transcript!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25aa20",
   "metadata": {},
   "source": [
    "## Check the transcript with the original file\n",
    "\n",
    "Run the following cell to compare words from the TextGrid to words from the ChatGPT transcript.\n",
    "\n",
    "Sometimes words will be misaligned:\n",
    "- ChatGPT may have missed some words\n",
    "- The Praat words may be misspelled, or hyphenated words may have been treated separately (e.g., eighty-four --> eighty four)\n",
    "\n",
    "You will need to correct this in either 1) the transcript or 2) the Praat file and make note of the change within the tracking document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6bd1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished transcript!\n"
     ]
    }
   ],
   "source": [
    "transcript_fn = os.path.join(stim_dir, 'transcripts', f'{stim_name}_transcript.txt')\n",
    "\n",
    "# load the textgrid and get all words\n",
    "textgrid = load_clean_textgrid(praat_fn)\n",
    "words_original = get_textgrid_words(textgrid)\n",
    "\n",
    "# load the ChatGPT created transcript\n",
    "_, words_transcribed = load_transcription(transcript_fn)\n",
    "\n",
    "compare_praat_to_transcript(words_original, words_transcribed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a518f12",
   "metadata": {},
   "source": [
    "## Create a gentle align file from Praat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1664de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gentle_stim_dir = os.path.join(stim_dir, 'gentle', stim_name)\n",
    "\n",
    "# if the directory does not exist, make the directory\n",
    "if not os.path.exists(gentle_stim_dir):\n",
    "    os.makedirs(gentle_stim_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91240a9c",
   "metadata": {},
   "source": [
    "Now that the directory is created, we will do the following:\n",
    "- Write the aligned file to the directory\n",
    "- Move a copy of the stimulus audio to the directory\n",
    "- Move a copy of the transcript to the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "819e0684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/stimuli/gentle/wheretheressmoke/a.wav'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given the two files, creates a file in gentle aligned format\n",
    "align_json = textgrid_to_gentle(praat_fn, transcript_fn)\n",
    "\n",
    "# write the file out to the directory\n",
    "with open(os.path.join(gentle_stim_dir, 'align.json'), 'w') as f:\n",
    "    json.dump(align_json, f)\n",
    "    \n",
    "# copy the transcript file renaming it to \"transcript.txt\" matching gentle convention\n",
    "shutil.copyfile(\n",
    "    transcript_fn, \n",
    "    os.path.join(gentle_stim_dir, 'transcript.txt')\n",
    ")\n",
    "\n",
    "# copy the stimulus audio file renaming it to \"a.wav\" matching gentle convention\n",
    "shutil.copyfile(\n",
    "    os.path.join(stim_dir, 'audio', f'{stim_name}.wav'), \n",
    "    os.path.join(gentle_stim_dir, 'a.wav')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
