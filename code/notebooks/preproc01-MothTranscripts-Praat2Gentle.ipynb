{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ede745",
   "metadata": {},
   "source": [
    "# Moth Transcripts to Gentle\n",
    "\n",
    "The Huth Moth transcripts are provided within Praat. There are two issues with this format:\n",
    "1. There is no joint transcript including punctuation (allowing us to present the next-word prediction framework)\n",
    "2. Our pipeline uses Gentle as its starting point to process files\n",
    "\n",
    "We load the Praat files and align it with a transcript generated through ChatGPT (adjusting mismatched words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6601b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os, sys, glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from praatio import textgrid as tgio\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from text_utils import strip_punctuation\n",
    "# from text_utils import get_pos_tags, get_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fdc80473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_textgrid(praat_fn):\n",
    "    '''\n",
    "    Load a praat textgrid file using PraatIO\n",
    "    '''\n",
    "    \n",
    "    # things to remove from the textgrid (indicates laughing, chewing, pauses etc)\n",
    "    REMOVE_CHARACTERS = ['sp', 'br', 'lg', 'cg', 'ls', 'ns', 'sl', 'ig',\n",
    "                         '{sp}', '{br}', '{lg}', '{cg}', '{ls}', '{ns}', '{sl}', '{ig}', 'pause']\n",
    "    \n",
    "    # open the textgrid\n",
    "    tg = tgio.openTextgrid(praat_fn, includeEmptyIntervals=False, reportingMode=\"warning\") \n",
    "    \n",
    "    # remove entries of unwanted characters\n",
    "    for tier_name in tg.tierNames:\n",
    "        # get the current tier\n",
    "        tier = tg.getTier(tier_name)\n",
    "        \n",
    "        for x in tier.entries:\n",
    "            if x[-1].lower() in REMOVE_CHARACTERS:\n",
    "                tier.deleteEntry(x)\n",
    "\n",
    "#         for char in REMOVE_CHARACTERS:\n",
    "#             upper_set = set(tier.find(char.upper()))\n",
    "#             lower_set = set(tier.find(char.lower()))\n",
    "#             remove_idxs = sorted(upper_set.union(lower_set))\n",
    "\n",
    "#             # go through each index and remove\n",
    "#             for idx in remove_idxs:\n",
    "#                 try:\n",
    "#                     tier.deleteEntry(tier.entries[idx])\n",
    "#                 except:\n",
    "#                     print (idx)\n",
    "    \n",
    "#     # go through each entry at the word tier, remove the items\n",
    "#     words = [x for x in tg.getTier('word').entries if x[-1].lower() not in REMOVE_CHARACTERS]\n",
    "#     phones = [x for x in tg.getTier('phone').entries if x[-1].lower() not in REMOVE_CHARACTERS]\n",
    "#     words = tg.getTier('word').entries\n",
    "#     phones = tg.getTier('phone').entries\n",
    "    return tg\n",
    "\n",
    "def load_transcription(transcript_fn):\n",
    "    \n",
    "    with open(transcript_fn, 'r') as f: #open the file\n",
    "        contents = f.readlines() #put the lines to a variable (list).\n",
    "        \n",
    "    # get the transcription stripped of punctuation\n",
    "    words_transcribed = strip_punctuation(contents).split()\n",
    "    \n",
    "    return contents, words_transcribed\n",
    "\n",
    "def textgrid_to_gentle(praat_fn, transcript_fn):\n",
    "    '''\n",
    "    Transform Moth dataset textgrid files into gentle format\n",
    "    '''\n",
    "    \n",
    "    textgrid = load_clean_textgrid(praat_fn)\n",
    "    tg_words = textgrid.getTier('word')\n",
    "    \n",
    "    contents, words_transcribed = load_transcription(transcript_fn)\n",
    "    \n",
    "    assert (len(tg_words) == len(words_transcribed))\n",
    "    \n",
    "    # create the dictionary to store things in\n",
    "    # put the transcript in the raw form\n",
    "    align = {}\n",
    "    align['transcript'] = contents[0]\n",
    "    align['words'] = []\n",
    "    \n",
    "    # Taken from Kaldi metasentence tokenizer\n",
    "    # splits the transcript based on any punctuation besides for apostrophes and hyphens\n",
    "    regex_split_pattern = r'(\\w|\\.\\w|\\:\\w|\\â€™\\w|\\'\\w|\\-\\w)+'\n",
    "    \n",
    "    iterator = list(re.finditer(regex_split_pattern, ''.join(contents), re.UNICODE))\n",
    "    n_items = len(list(iterator))\n",
    "    \n",
    "    # make sure the iterator matches the length\n",
    "    assert (n_items == len(tg_words) == len(words_transcribed))\n",
    "    \n",
    "    # if all matches we're good to go\n",
    "    for word_info, m in zip(tg_words, iterator):\n",
    "        # span of the word in characters relative to the overall string\n",
    "        start_offset, end_offset = m.span()\n",
    "        word = m.group()\n",
    "        \n",
    "        # crop textgrid to the word\n",
    "        cropped_grid = textgrid.crop(cropStart=word_info[0], cropEnd=word_info[1], mode='truncated', rebaseToZero=False)\n",
    "        tg_phones = cropped_grid.getTier('phone').entries\n",
    "        word_phones = []\n",
    "\n",
    "        for phone_info in tg_phones:\n",
    "            phone = re.sub(r'\\d+', '', phone_info[-1])\n",
    "            duration = phone_info[1] - phone_info[0]\n",
    "            word_phones.append({'duration': duration, 'phone': phone})\n",
    "\n",
    "        word_align = {\n",
    "            'alignedWord': word.lower(),\n",
    "            \"case\": \"success\",\n",
    "            'word': word,\n",
    "            'start': word_info[0],\n",
    "            'end': word_info[1],\n",
    "            'phones': word_phones,\n",
    "            \"startOffset\": start_offset,\n",
    "            \"endOffset\": end_offset,\n",
    "        }\n",
    "        \n",
    "        align['words'].append(word_align)\n",
    "        \n",
    "    return align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0e456",
   "metadata": {},
   "source": [
    "## Set paths \n",
    "\n",
    "These are paths to the main directory and the stimulus directory\n",
    "\n",
    "CHANGE THE PATH BELOW TO MATCH YOUR DIRECTORY --> FinnLabTasks/transcript_alignment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5d50ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/'\n",
    "datasets_dir = '/dartfs/rc/lab/F/FinnLab/datasets/'\n",
    "stim_dir = os.path.join(datasets_dir, 'huth-moth', 'stimuli')\n",
    "\n",
    "# for prepping for onlin eexpt\n",
    "# stim_dir = os.path.join(base_dir, 'stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed86e4c",
   "metadata": {},
   "source": [
    "## Load Praat files\n",
    "\n",
    "We first get all the filenames of TextGrid files within the stimulus directory. We also print out the number of files within this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "35c06145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in dataset: 27\n"
     ]
    }
   ],
   "source": [
    "praat_fns = sorted(glob.glob(os.path.join(stim_dir, 'praat', '*.TextGrid')))\n",
    "\n",
    "print (f'Total files in dataset: {len(praat_fns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ae474",
   "metadata": {},
   "source": [
    "<b>Note:</b> This is <b>very</b> likely not to work on the first time. Follow the steps below to get the file to load!\n",
    "\n",
    "We are going to load a Praat TextGrid file. This will probably not work on the first time due to overlapping timestamps. To address this, do the following:\n",
    "1. Open the .TextGrid file in a text editor (e.g., TextEdit, SublimeText)\n",
    "2. Look at the Python error -- you will need to manually adjust these overlapping times. Copy the first number in the second parentheses:\n",
    "    - <b>Example error:</b> Two intervals in the same tier overlap in time: (START_1, END_1, sp) and (START_2, END_2, B)\n",
    "    - For this error, copy the number \"START_2\"\n",
    "3. Go to the text editor, and search (cmd + F) for the copied number (e.g., \"START_2\").\n",
    "4. Adjust the word/phoneme before's end time (e.g., END_1) to match the copied number (\"START_2\").\n",
    "5. Save the file and rerun the code\n",
    "6. Repeat for as many times until the file loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "244a517b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus name: tildeath\n",
      "Successfully loaded Praat file!\n"
     ]
    }
   ],
   "source": [
    "# select a file number to load -- we then select that file from the list of alphabetized file names\n",
    "file_num = 24\n",
    "praat_fn = praat_fns[file_num]\n",
    "\n",
    "# now grab the current filename as a path -- print out only the filename (no extension)\n",
    "filepath = Path(praat_fn)\n",
    "stim_name = filepath.stem\n",
    "print (f'Stimulus name: {filepath.stem}')\n",
    "\n",
    "# attempt to load the praat file -- if this doesn't work, follow the steps above \n",
    "tg = tgio.openTextgrid(praat_fns[file_num], includeEmptyIntervals=False, reportingMode=\"warning\") \n",
    "\n",
    "print (f'Successfully loaded Praat file!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c0f2a",
   "metadata": {},
   "source": [
    "## Adjust the words to have punctuation\n",
    "\n",
    "After loading the transcript using Praat, we concatenate all the transcript words and pass it to ChatGPT to ensure punctuation. Then we need to go through comparing word by word making sure of the following:\n",
    "-  The new transcript matches the original number of words\n",
    "- Words are spelled correctly (as full words)\n",
    "\n",
    "This cell below will print out all the words of the TextGrid as a string. You will need to do the following:\n",
    "1. Open ChatGPT: https://chat.openai.com/chat\n",
    "2. Type the following instructions: \"Add punctuation and capitalization to the following but change nothing else:\"\n",
    "3. Copy and paste the transcript below <i>after</i> the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "64d02c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UM IT WAS FIVE DAYS BEFORE MY TEN YEAR HIGH SCHOOL REUNION WHEN MY HUSBAND TOLD ME HE THOUGHT HE MIGHT BE GAY HE WASNT SURE HE WAS GAY CAUSE HE HAD NEVER BEEN WITH A MAN YET BUT HE THOUGHT IT WAS SOMETHING HE OUGHT TO FIGURE OUT GOOD IDEA UM NOW I I THINK HE TOLD ME THIS AT THAT MOMENT NOT TO GET OUT OF MY HIGH SCHOOL REUNION WHICH WOULD BE UNDERSTANDABLE BUT IN ORDER TO UM BECAUSE WE HAD BEEN LOOKING FOR HOUSES TOGETHER AND WED FINALLY FOUND ONE IN PASADENA THAT WE BOTH LIKED AND I THINK SOMEHOW THE FOREVER OF THE WEDDING VOW SOUNDED KIND OF VAGUE AND IDEALISTIC TO HIM WHERE AS THIRTY YEAR MORTGAGE WAS SURPRISINGLY SPECIFIC IT WAS A COMMITMENT YOU KNOW THE KIND OF COMMITMENT YOU SHOULDNT MAKE WHILE YOUR SEXUALITY IS PENDING SO NOW I AS HE WAS EXPLAINING THIS TO ME I WAS THINKING DOWNSTAIRS OUR NEIGHBORS WE LIVE IN THIS DUPLEX APARTMENT WE WERE RENTING THE KAUFMANS WERE PROBABLY JUST SITTING DOWN FOR DINNER AS THEY HAD DONE FOR FIFTY TWO YEARS AND TALKING ABOUT THEIR BRISKET AND THEY WERE THIS COUPLE THAT USED TO COME UP AND SEE OUR NEW FURNITURE LIKE WHEN WE BOUGHT A NEW ANTIQUE TABLE CAUSE SAM LIKED ANTIQUE SHOPPING PINK FLAG AND UM THEY SO THEY WERE LIKE PARENT FIGURES TO US AND UM AND YOU KNOW THERE WERE SIGNS LIKE WHEN I FIRST MET SAM HE HAD THIS LEATHER JACKET WITH A TIGER PRINT LINING AND I REMEMBER THINKING IT SEEMED KINDA THE LINING I DONT KNOW IT STUCK WITH ME AND THEN UM AND YOU KNOW BUT THEN HE ASKED ME OUT AND WE SLEPT TOGETHER AND HE ASKED ME TO MARRY HIM AND I PUT ON THE BIG WHITE DRESS WHICH HE HELPED ME PICK OUT IN FRONT SERIOUSLY IN IN FRONT OF UM YOU KNOW TWO HUNDRED CLOSE WITNESSES MY CLOSEST FRIENDS AND I FIGURED HES NOT UM AND ALSO I ACTUALLY I GUESS I THERE WAS ONE THING I IGNORED WHICH I PROBABLY SHOULD HAVE PAID ATTENTION TO HE TOLD ME BEFORE WE WERE WHILE WE WERE ENGAGED HE TOLD ME HE SOMETIMES NOTICED MEN BUT HE SAID HE COULDNT IMAGINE SLEEPING WITH A MAN AND YOU KNOW HE JUST NOTICED THEM AND I GUESS I KNEW THIS WAS NOT GOOD BECAUSE I DIDNT TALK TO ANY GIRL FRIENDS ABOUT THIS AND I TALK TO GIRL FRIENDS ABOUT EVERYTHING SO IF I DIDNT IT WAS PROBABLY BAD BUT I DID AT ONE POINT I DID TALK TO ONE GIRL FRIEND WE WERE IN LINE AT DISNEYLAND FOR SPACE MOUNTAIN AND I TOLD HER HOW SAM HAD SAID HE SOMETIMES NOTICE MEN AND DO YOU THINK THATS BAD AND SHE SAID YOU KNOW SHE TOLD ME THIS THEORY OF THE SPECTRUM OF SEXUALITY AND EVERYONE LIES SOMEWHERE ALONG IT AND SOME PEOPLE NOTICE PEOPLE BUT THEY WOULD NEVER ACT ON IT AND UH WELL FOUR YEARS LATER SHE REALIZED SHE WAS A LESBIAN SO S MY ONE PERSON I CONFESSED TO UM SO AS I WAS RECALLING ALL THESE SIGNS I REALIZED SAM WAS STILL TALKING AND UM HE WAS TELLING ME HE FELT SO MUCH BETTER GETTING THIS OFF HIS CHEST AND HED BEEN WANTING TO TELL ME FOR A LONG TIME AND HE FELT SO RELIEVED HE HE KIND OF WANTED TO HAVE SEX AND I SAID WITH WHO AND HE SAID WITH YOU AND I THINK HE MEANT IS AS A COMPLEMENT BUT I WAS LIKE I HAVE TO GO TO BED AND WAKE UP WHEN THE BOOK STORES ARE OPEN SO THE NEXT DAY I WENT DIRECTLY TO THE SELF HELP SECTION UM WHERE ALL PROBLEMS COULD BE SOLVED AND THERE WAS NO BOOK FOR SOMEONE WHOS HUSBAND WHO THOUGHT HE MIGHT BE GAY THERE WAS UM THERE WAS A BOOK CALLED LOVING SOMEONE GAY BUT IT TURNED OUT TO BE FOR TEACHERS AND FAMILY MEMBERS UM BUT NOTHING AND AND UM AND I WAS I WAS NERVOUS BECAUSE THIS IS LA AND I DIDNT WANNA PIONEER A PROBLEM I THIS IS A BA VERY BAD SIGN AND AS IM LOOKING FOR A BOOK ANY BOOK I REMEMBER I SAW ONE CALLED UM HOW TO SURVIVE ALIEN ABDUCTION AND IT WASNT A HUMOR BOOK IT WAS A SERIOUS BOOK WITH LIKE THINGS LIKE BLOCK THEIR MIND CONTROL AND YOU KNOW GET HELP FROM ON HIGH AND SO BASICALLY ACCORDING TO THE LAWS OF SUPPLY AND DEMAND YOURE MORE LIKELY TO BE ABDUCTED BY AN ALIEN THAN TO HAVE YOUR HUSBAND REALIZE HES GAY THATS WHAT THAT SAID TO ME AND SO I UM I LEFT THE SELF HELP SECTION DESPONDENT AND DECIDED THAT IT WAS TIME TO GO TO THERAPY FOUR DAYS NOW FROM MY HIGH SCHOOL REUNION UM SO I WENT FOR THE FIRST TIME I HAD NEVER GONE TO THERAPY I GREW UP IN OKLAHOMA WHICH WAS WHERE MY REUNION WAS GONNA BE AND UM I WENT I THERE WAS THIS THING CALLED THE GOLD GROUP CAUSE I WAS IN A WRITERS GUILD BASICALLY WHEN I BECAME A COMEDY WRITER I DECIDED MY HUSBAND NO LONGER WANTED TO BE A STRAIGHT MAN THAT WAS BASICALLY WHAT HAPPENED THERE SO I WAS IN THE WRITERS GUILD AND UM I WENT THEY PAID FOR THIS GOLD THIS IS TRUE THEY PAY FOR THIS THING CALLED THE GOLD GROUP AND IT WAS A GROUP OF THERAPISTS IN THE VALLEY AND UM IT WAS ONLY A TEN DOLLAR CO PAY AND AND ITS POSSIBLE YOU SHOULDNT SKIMP ON THERAPY BUT I BUT I THOUGHT I WAS GONNA BE IN FOR A WHILE SO I UM I WENT TO THE GOLD GROUP AND I REMEMBER WHEN I GOT IN THERE UM YOU BASICALLY GET WHAT YOU CO PAY FOR BECAUSE THERE I I WAS IN THIS OFFICE WAITING FOR MY THERAPIST AND I COULD HEAR THE SESSION NEXT TO ME IT WAS THIS PAPER THIN WALL AND I COULD HEAR A MAN SOBBING AND I WAS LIKE THEYRE THEYRE GONNA HEAR ME SOBBING AND THEN WHEN MY THERAPIST CAME IN SHE TURNED ON THIS LITTLE F OSCILLATING FAN WHICH I THINK IS A SYSTEM THE GOLD GROUP HAD COME UP WITH TO DEAL WITH THE SOUND PROOFING PROBLEM AND UM SO AND MY THERAPIST AND I DIDNT HAVE ANYTHING TO COMPARE AGAINST BUT I JUST REMEMBER NOTING SHE WAS JUST VERY BADLY DRESSED LIKE PINK AND RED TOGETHER AND STRIPES AND I THOUGHT SHE CANT PUT TOGETHER AN OUTFIT AND SHE HAS TO PUT TOGETHER MY WHOLE LIFE THIS IS NOT GOOD SO UM AND SHE HAD ALL THESE QUESTIONS I HADNT EVEN THOUGHT OF LIKE DO YOU THINK YOU SHOULD YOU BE HIV TESTED MAYBE HES LYING AND HES BEEN CHEATING ON YOU AND SHE HAD A LOT OF ANGER THAT WE WORKED ON SO SHE FELT BETTER UM OKAY SO I PROCEEDED MY DECISION WAS TO GO TO THE REUNION WITH SAM AND PRETEND EVERYTHING WAS FINE BECAUSE IT SEEMED BETTER THAN UM WELL ONE PROBLEM WAS SAM WASNT READY TO COME OUT CAUSE HE HADNT STARTED UH SEE WHEN HE TOLD ME HE THOUGHT HE MIGHT BE GAY HE SAID MAYBE ILL ONLY BE THIRTY PERCENT GAY ILL FIND OUT AND THEN I COULD STILL BE WITH YOU AND I WAS OVERWHELMED AT THE MOMENT BUT I DO REMEMBER THINKING SO HELL SLEEP WITH TEN MEN AND THEN ENJOY THREE OF THEM IM CONFUSED HOW WERE GONNA DO THE MATH OF THIS SO UM SO HE HADNT STARTED THAT EXPERIMENT YET SO HE WASNT READY TO COME OUT CAUSE HE DIDNT KNOW YET SO WE JUST WENT TO MY REUNION LIKE THAT SO WE STAYED WITH MY PARENTS WHICH IS NOT A FUN THING EVEN WHEN YOUR HUSBAND DOESNT THINK HE MIGHT BE GAY AND UM AND MY AND I REMEMBER AT THE REUNION I WON MOST SUCCESSFUL AND I JUST WAS LIKE YEAH AND MY HUSBANDS GAY SO YOU KNOW ITS OKLAHOMA THE THE RUNNER UP WAS LIKE THE MANAGER OF THE FOOTLOCKER SO IT WASNT A HUGE HONOR BUT UM BUT ANYWAY I REMEMBER WHEN I WENT HOME I WAS REALLY NERVOUS ABOUT MY MOM CAUSE MY MOM IT WAS LIKE BEING YOU KNOW THAT SCENE IN MY FAIR LADY WHEN THE LINGUISTIC EXPERTS ASKED HER TO DANCE THATS HOW IT WAS LIKE BEING ALONE WITH MY MOM WITH A SECRET CAUSE MY MOM LIKE RIGHT NOW SHE WOULD SAY YOUR VOICE SOUNDS A LITTLE TIGHT HONEY YOU SHES LIKE VERY EAGLE EYE ABOUT THESE EMOTIONAL THINGS AND I KEPT WORRYING AND TRYING TO AVOID HER AND I COMPLETELY THOUGHT FORGOT ABOUT MY DAD AND UM AT ONE POINT HE WAS SITTING THERE WATCHING ESPN AND HE SAID IS EVERYTHING OKAY AND I SAID NO YOU KNOW IF EVERYTHING WAS OKAY SAM WOULD BE IN HERE WATCHING ESPN WITH YOU INSTEAD OF IN THE KITCHEN FLIPPING THROUGH HOUSE BEAUTIFUL WITH MOM AND HE AND I BASICALLY TOLD MY DAD EVERYTHING WHICH IS NOT THE SYSTEM IN MY HOUSE YOU TELL MY MOM AND MY MOM TELLS MY DAD BUT I TOLD MY DAD AND UM AND THEN I REMEMBERED WHY I DONT EVER TELL MY DAD BECAUSE HE WAS LIKE IT WAS LIKE I WAS ASK HE THOUGHT IT WAS AS IF SAM WAS ASKING PERMISSION TO HAVE AN AFFAIR AND HE AND I SHOULD JUST SAY NO SO HES IN FACT HIS WORDS WERE ID LIKE TO SLEEP WITH DEBBIE REYNOLDS BUT YOUR MOMS NOT GONNA LET ME WHICH I WAS LIKE BUT WHAT IF YOU WANTED TO SLEEP WITH BURT REYNOLDS SO AND UM AND TO HIS CREDIT HE HAD NO EXPERIENCE WITH THIS IN COLLEGE HE HAD ONE YOU KNOW THERE WAS ONE GUY IN HIS FRATERNITY THAT EVERYONE KNEW HAD REALIZED HE WAS GAY AND LEFT HIS WIFE AND KIDS JERRY HOBBLEMAN AND NO ONE HAD EVER HEARD FROM HIM AGAIN THAT WAS LIKE HIS WHOLE EXPERIENCE WITH THE GAY POPULATION SO HE WAS NO HELP AND UM SOMEHOW THOUGH SAM AND I SURVIVED OUR UH MY HIGHSCHOOL REUNION BUT UM MR KAUFMAN WHO LIVED DOWNSTAIRS DID NOT SURVIVE THE WEEKEND HE HAD DIED IN HIS SLEEP OF A HEART ATTACK AND THERE WAS A FUNERAL AND UM AND I REMEMBER IT WAS KIND OF A HIGHLIGHT FOR ME BECAUSE I HAD BEEN CRYING IN SUCH INAPPROPRIATE PLACES ALL WEEK AND FINALLY I WAS AT A FUNERAL AND I COULD JUST SOB EVEN THOUGH I THINK IT WAS ODD TO PEOPLE CAUSE THEY WERE LIKE IS SHE THE TENNANT BECAUSE I WAS KIND OF LOSING IT LIKE GRABBING KLEENEX FROM THE MOTHER YOU KNOW UM BUT UM BUT I REMEMBER I WAS THERE WITH SAM AND WE WERE HOLDING HANDS AND WE WERE THINKING UM I WAS THINKING IF AT LEAST AT A FUNERAL THERES A BODY AND A GRAVE AND UM SOMETHING TANGIBLE TO MARK THE END AND WITH A RELATIONSHIP ITS NEVER SO CLEARLY MARKED AND UM IT WAS A RELIEF TO BE THERE WITH WITH SAM FOR CLOSURE AND THEN BEING AT A JEWISH FUNERAL THERE WAS A NEED FOR A MINION WHERE THEY NEEDED TEN MEN TO GO AND I REMEMBER THINKING DONT GO WITH THE MEN TO SAM I DID NOT WANT HIM TO GO WITH THE MEN BUT THEN FINALLY I SAID GO AND I REALIZED I MEANT IT IN THE LARGEST SENSE POSSIBLE AND ABOUT A WEEK LATER UM MY DAD CALLED ME AND HE S HE SAID YOU KNOW ITS A REALLY NINETY NINE PERCENT GENETIC THIS WHOLE HOMOSEXUALITY THING AND I WAS COMPLETELY THROWN AND THOUGHT THAT MAYBE HE HAD BEEN ON THE INTERNET AND RESEARCHING AND AND IT TURNED OUT THAT MY DAD HAD CALLED JERRY HOBBLEMAN AND ASKED HIM TO LUNCH HE HAD TRACKED DOWN THIS MAN AND TOOK HIM TO DENNYS AND UM AND UM IM SURE THERE WERE LOTS OF DISCLAIMERS CAUSE MY DAD DOES NOT TAKE MEN TO LUNCH SO HE PROBABLY WAS AFRAID IT WOULD SOUND LIKE A DATE OR SOMETHING AND UM IM SURE WHEN HE SHOWED UP IN SHORTS AND BLACK DRESS SOCKS AND LOAFERS IT WAS CLEAR HE WAS NOT OF THE GAY PERSUASION BUT HE UM BUT HE ASKED JERRY ALL THE THINGS HE WANTED TO ASK UM MY I GUESS AND COULDNT LIKE COULD YOU HAVE AVOIDED THIS AND DID YOU EVER REGRET IT AND IS YOUR WIFE OKAY AND IT MAYBE WAS THE NICEST THING A FATHER EVER DID TAKING JERRY HOBBLEMAN TO LUNCH AND UM JUST ABOUT A WEEK AFTER THAT SAM WAS FINALLY MOVING OUT AND UM I REMEMBER WE WERE IN THE TOP FLOOR OF OUR DUPLEX AND DOWNSTAIRS MRS KAUFMAN WAS GARDENING LIKE SHE ALWAYS DID AND UM SAM HADNT TALKED TO HER YET BECAUSE SHE WAS LIKE A PARENT FIGURE AND HE STILL WASNT READY TO COME OUT AND HE WASNT DEALING WITH THINGS AS HE HADNT DEALT WITH MANY THINGS UM AND SO I SAID YOU HAVE TO TELL HER CAUSE THE MOVING VAN IS GOING TO BE HERE ANY MINUTE AND SHES GONNA WONDER CAUSE AND HE WOULDNT SO I WENT DOWNSTAIRS TO TALK TO HER AND UM I REMEMBER SHE WAS SHED ALWAYS LOVED GARDENING BUT IT WAS REALLY ABOUT K SHE SEEMED MORE DESPERATE THAN EVER TO KIND OF KEEP THINGS ALIVE NURTURE THE LIVING THINGS AND NOT TO LET THINGS SLIP AWAY AND SHE COULDNT IMAGINE WHY I WAS LETTING MY HUSBAND SLIP AWAY AND I COULDNT EXPLAIN TO HER UM AND SO WE JUST SAT TOGETHER ON THIS BENCH UM SHOULDER TO SHOULDER TWO WOMEN ALONE BUT NOT REALLY ALONE AS THE MOVING VAN LUMBERED OVER TO THE SIDEWALK THANK YOU\n"
     ]
    }
   ],
   "source": [
    "def get_textgrid_words(textgrid):\n",
    "    '''\n",
    "    Extracts the words in the textgrid to show in a legible format\n",
    "    '''\n",
    "    words = [strip_punctuation(x[-1]) for x in textgrid.getTier('word').entries]\n",
    "    return words\n",
    "\n",
    "# load the textgrid removing all enunciations\n",
    "textgrid = load_clean_textgrid(praat_fn)\n",
    "\n",
    "# gets all the words in the textgrid as an interpretable string\n",
    "tg_words = get_textgrid_words(textgrid)\n",
    "print (' '.join(tg_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b0cf1",
   "metadata": {},
   "source": [
    "## Create a transcript file\n",
    "\n",
    "ChatGPT will then print out a verion of the transcript with punctuation. However, we need to double-check that the words match the original transcript. After getting the transcript from ChatGPT:\n",
    "1. Go to the directory '/stimuli/transcripts/' \n",
    "2. Create a text file names \"STIMULUSNAME.txt\" (where STIMULUSNAME is the name of the stimulus - printed out above)\n",
    "3. Paste the transcript from ChatGPT into the text file\n",
    "\n",
    "You should now be able to load the file in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "fbb04d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_praat_to_transcript(words_original, words_transcribed):\n",
    "    '''\n",
    "    Compares words from TextGrid and ChatGPT transcript word by word\n",
    "    '''\n",
    "    \n",
    "    for i, (word_orig, word_transc) in enumerate(zip(words_original, words_transcribed)):\n",
    "        if word_orig.lower() != word_transc.lower():\n",
    "            print (f'Word index: {i}')\n",
    "            print (f'TextGrid word: {word_orig}')\n",
    "            print (f'Transcript word: {word_transc}')\n",
    "            print (f'Word context: {words_original[i-5:i+5]}')\n",
    "            break\n",
    "    \n",
    "    if i+1 == len(words_original):\n",
    "        print (f'Finished transcript!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25aa20",
   "metadata": {},
   "source": [
    "## Check the transcript with the original file\n",
    "\n",
    "Run the following cell to compare words from the TextGrid to words from the ChatGPT transcript.\n",
    "\n",
    "Sometimes words will be misaligned:\n",
    "- ChatGPT may have missed some words\n",
    "- The Praat words may be misspelled, or hyphenated words may have been treated separately (e.g., eighty-four --> eighty four)\n",
    "\n",
    "You will need to correct this in either 1) the transcript or 2) the Praat file and make note of the change within the tracking document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "b6bd1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished transcript!\n"
     ]
    }
   ],
   "source": [
    "transcript_fn = os.path.join(stim_dir, 'transcripts', f'{stim_name}_transcript.txt')\n",
    "\n",
    "# load the textgrid and get all words\n",
    "textgrid = load_clean_textgrid(praat_fn)\n",
    "words_original = get_textgrid_words(textgrid)\n",
    "\n",
    "# load the ChatGPT created transcript\n",
    "_, words_transcribed = load_transcription(transcript_fn)\n",
    "\n",
    "compare_praat_to_transcript(words_original, words_transcribed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a518f12",
   "metadata": {},
   "source": [
    "## Create a gentle align file from Praat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "e074245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gentle_stim_dir = os.path.join(stim_dir, 'gentle', stim_name)\n",
    "\n",
    "# if the directory does not exist, make the directory\n",
    "if not os.path.exists(gentle_stim_dir):\n",
    "    os.makedirs(gentle_stim_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91240a9c",
   "metadata": {},
   "source": [
    "Now that the directory is created, we will do the following:\n",
    "- Write the aligned file to the directory\n",
    "- Move a copy of the stimulus audio to the directory\n",
    "- Move a copy of the transcript to the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "819e0684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dartfs/rc/lab/F/FinnLab/datasets/huth-moth/stimuli/gentle/tildeath/a.wav'"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "praat_fn = praat_fns[file_num]\n",
    "transcript_fn = os.path.join(stim_dir, 'transcripts', f'{stim_name}_transcript.txt')\n",
    "\n",
    "# given the two files, creates a file in gentle aligned format\n",
    "align_json = textgrid_to_gentle(praat_fn, transcript_fn)\n",
    "\n",
    "# write the file out to the directory\n",
    "with open(os.path.join(gentle_stim_dir, 'align.json'), 'w') as f:\n",
    "    json.dump(align_json, f)\n",
    "    \n",
    "# copy the transcript file renaming it to \"transcript.txt\" matching gentle convention\n",
    "shutil.copyfile(\n",
    "    transcript_fn, \n",
    "    os.path.join(gentle_stim_dir, 'transcript.txt')\n",
    ")\n",
    "\n",
    "# copy the stimulus audio file renaming it to \"a.wav\" matching gentle convention\n",
    "shutil.copyfile(\n",
    "    os.path.join(stim_dir, 'audio', f'{stim_name}.wav'), \n",
    "    os.path.join(gentle_stim_dir, 'a.wav')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f700b7",
   "metadata": {},
   "source": [
    "### old for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "id": "118b1058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740\n",
      "2742\n"
     ]
    }
   ],
   "source": [
    "print (len(tg_words))\n",
    "print (len (words_transcribed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "id": "63bb53f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praatio.data_classes.interval_tier.IntervalTier at 0x2b22e9c7f880>"
      ]
     },
     "execution_count": 1590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "id": "33d81c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'story',\n",
       " 'is',\n",
       " 'about',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'jobs',\n",
       " 'that',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'shaped',\n",
       " 'my',\n",
       " 'life',\n",
       " 'and',\n",
       " 'shaped',\n",
       " 'my',\n",
       " 'whole',\n",
       " 'destiny',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'jobs',\n",
       " 'I',\n",
       " 'had',\n",
       " 'uh',\n",
       " 'during',\n",
       " 'the',\n",
       " 'ages',\n",
       " 'of',\n",
       " 'twenty',\n",
       " 'to',\n",
       " 'twentyone',\n",
       " 'So',\n",
       " 'the',\n",
       " 'story',\n",
       " 'begins',\n",
       " 'in',\n",
       " 'in',\n",
       " 'uh',\n",
       " 'yes',\n",
       " 'I',\n",
       " 'we',\n",
       " 'yes',\n",
       " 'I',\n",
       " 'was',\n",
       " 'employed',\n",
       " 'back',\n",
       " 'then',\n",
       " 'Ok',\n",
       " 'I',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'why',\n",
       " 'you',\n",
       " 'laughed',\n",
       " 'but',\n",
       " 'Ill',\n",
       " 'Ill',\n",
       " 'accept',\n",
       " 'that',\n",
       " 'Its',\n",
       " 'a',\n",
       " 'good',\n",
       " 'sign',\n",
       " 'Ok',\n",
       " 'thinking',\n",
       " 'out',\n",
       " 'loud',\n",
       " 'here',\n",
       " 'Alright',\n",
       " 'so',\n",
       " 'in',\n",
       " 'nineteen',\n",
       " 'eightyfour',\n",
       " 'I',\n",
       " 'was',\n",
       " 'a',\n",
       " 'sophomore',\n",
       " 'at',\n",
       " 'Princeton',\n",
       " 'You',\n",
       " 'can',\n",
       " 'laugh',\n",
       " 'at',\n",
       " 'that',\n",
       " 'if',\n",
       " 'you',\n",
       " 'like',\n",
       " 'No',\n",
       " 'Alright',\n",
       " 'So',\n",
       " 'in',\n",
       " 'nineteen',\n",
       " 'eightyfour',\n",
       " 'I',\n",
       " 'was',\n",
       " 'a',\n",
       " 'sophomore',\n",
       " 'at',\n",
       " 'Princeton',\n",
       " 'I',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'take',\n",
       " 'a',\n",
       " 'year',\n",
       " 'off',\n",
       " 'because',\n",
       " 'I',\n",
       " 'had',\n",
       " 'I',\n",
       " 'had',\n",
       " 'a',\n",
       " 'very',\n",
       " 'bad',\n",
       " 'reputation',\n",
       " 'at',\n",
       " 'school',\n",
       " 'I',\n",
       " 'was',\n",
       " 'drinking',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'getting',\n",
       " 'in',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'trouble',\n",
       " 'So',\n",
       " 'I',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'take',\n",
       " 'a',\n",
       " 'year',\n",
       " 'off',\n",
       " 'Also',\n",
       " 'I',\n",
       " 'had',\n",
       " 'joined',\n",
       " 'the',\n",
       " 'army',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'for',\n",
       " 'Princeton',\n",
       " 'and',\n",
       " 'I',\n",
       " 'was',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'four',\n",
       " 'years',\n",
       " 'of',\n",
       " 'active',\n",
       " 'duty',\n",
       " 'after',\n",
       " 'school',\n",
       " 'and',\n",
       " 'eight',\n",
       " 'years',\n",
       " 'of',\n",
       " 'reserve',\n",
       " 'duty',\n",
       " 'So',\n",
       " 'this',\n",
       " 'was',\n",
       " 'my',\n",
       " 'last',\n",
       " 'chance',\n",
       " 'at',\n",
       " 'freedom',\n",
       " 'was',\n",
       " 'after',\n",
       " 's',\n",
       " 'you',\n",
       " 'know',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'this',\n",
       " 'year',\n",
       " 'off',\n",
       " 'from',\n",
       " 'school',\n",
       " 'Later',\n",
       " 'just',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Harpers',\n",
       " 'crowd',\n",
       " 'I',\n",
       " 'did',\n",
       " 'become',\n",
       " 'a',\n",
       " 'conscientious',\n",
       " 'objector',\n",
       " 'and',\n",
       " 'so',\n",
       " 'I',\n",
       " 'got',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'military',\n",
       " 'So',\n",
       " 'and',\n",
       " 'avoided',\n",
       " 'the',\n",
       " 'Golf',\n",
       " 'War',\n",
       " 'unlike',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'ROTC',\n",
       " 'guys',\n",
       " 'which',\n",
       " 'was',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'Alright',\n",
       " 'so',\n",
       " 'but',\n",
       " 'this',\n",
       " 'was',\n",
       " 'before',\n",
       " 'I',\n",
       " 'knew',\n",
       " 'I',\n",
       " 'was',\n",
       " 'getting',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'army',\n",
       " 'This',\n",
       " 'was',\n",
       " 'gonna',\n",
       " 'be',\n",
       " 'my',\n",
       " 'year',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'I',\n",
       " 'nee',\n",
       " 'I',\n",
       " 'needed',\n",
       " 'to',\n",
       " 'make',\n",
       " 'money',\n",
       " 'though',\n",
       " 'during',\n",
       " 'this',\n",
       " 'year',\n",
       " 'off',\n",
       " 'And',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'I',\n",
       " 'know',\n",
       " 'its',\n",
       " 'going',\n",
       " 'to',\n",
       " 'seem',\n",
       " 'absurd',\n",
       " 'suggested',\n",
       " 'that',\n",
       " 'I',\n",
       " 'be',\n",
       " 'a',\n",
       " 'model',\n",
       " 'And',\n",
       " 'he',\n",
       " 'took',\n",
       " 'some',\n",
       " 'pictures',\n",
       " 'of',\n",
       " 'me',\n",
       " 'I',\n",
       " 'know',\n",
       " 'I',\n",
       " 'have',\n",
       " 'rings',\n",
       " 'under',\n",
       " 'my',\n",
       " 'eyes',\n",
       " 'that',\n",
       " 'go',\n",
       " 'all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'my',\n",
       " 'skull',\n",
       " 'and',\n",
       " 'I',\n",
       " 'have',\n",
       " 'no',\n",
       " 'hair',\n",
       " 'But',\n",
       " 'at',\n",
       " 'twenty',\n",
       " 'he',\n",
       " 'had',\n",
       " 'it',\n",
       " 'in',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'that',\n",
       " 'I',\n",
       " 'should',\n",
       " 'be',\n",
       " 'a',\n",
       " 'model',\n",
       " 'So',\n",
       " 'he',\n",
       " 'takes',\n",
       " 'some',\n",
       " 'pictures',\n",
       " 'of',\n",
       " 'me',\n",
       " 'and',\n",
       " 'I',\n",
       " 'must',\n",
       " 'admit',\n",
       " 'I',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'was',\n",
       " 'ugly',\n",
       " 'but',\n",
       " 'I',\n",
       " 'was',\n",
       " 'vain',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'try',\n",
       " 'it',\n",
       " 'I',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'what',\n",
       " 'I',\n",
       " 'was',\n",
       " 'thinking',\n",
       " 'So',\n",
       " 'I',\n",
       " 'go',\n",
       " 'I',\n",
       " 'look',\n",
       " 'up',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Princeton',\n",
       " 'library',\n",
       " 'they',\n",
       " 'had',\n",
       " 'a',\n",
       " 'Manhattan',\n",
       " 'phone',\n",
       " 'book',\n",
       " 'and',\n",
       " 'I',\n",
       " 'look',\n",
       " 'up',\n",
       " 'modeling',\n",
       " 'and',\n",
       " 'I',\n",
       " 'choose',\n",
       " 'a',\n",
       " 'modeling',\n",
       " 'agency',\n",
       " 'And',\n",
       " 'I',\n",
       " 'go',\n",
       " 'into',\n",
       " 'New',\n",
       " 'York',\n",
       " 'with',\n",
       " 'these',\n",
       " 'pictures',\n",
       " 'This',\n",
       " 'fellow',\n",
       " 'takes',\n",
       " 'them',\n",
       " 'He',\n",
       " 'says',\n",
       " 'Can',\n",
       " 'I',\n",
       " 'hold',\n",
       " 'these',\n",
       " 'overnight',\n",
       " 'I',\n",
       " 'said',\n",
       " 'yes',\n",
       " 'And',\n",
       " 'uh',\n",
       " 'the',\n",
       " 'next',\n",
       " 'morning',\n",
       " 'he',\n",
       " 'calls',\n",
       " 'me',\n",
       " 'Come',\n",
       " 'into',\n",
       " 'New',\n",
       " 'York',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'sign',\n",
       " 'you',\n",
       " 'to',\n",
       " 'a',\n",
       " 'contract',\n",
       " 'Hed',\n",
       " 'sent',\n",
       " 'my',\n",
       " 'pictures',\n",
       " 'to',\n",
       " 'the',\n",
       " 'photographer',\n",
       " 'Bruce',\n",
       " 'Weber',\n",
       " 'who',\n",
       " 'does',\n",
       " 'the',\n",
       " 'Abercormbie',\n",
       " 'and',\n",
       " 'Fitch',\n",
       " 'and',\n",
       " 'Vanity',\n",
       " 'Fair',\n",
       " 'However',\n",
       " 'you',\n",
       " 'say',\n",
       " 'Abercrombie',\n",
       " 'whatever',\n",
       " 'And',\n",
       " 'uh',\n",
       " 'that',\n",
       " 'this',\n",
       " 'fellow',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'photograph',\n",
       " 'me',\n",
       " 'So',\n",
       " 'suddenly',\n",
       " 'with',\n",
       " 'this',\n",
       " 'small',\n",
       " 'agency',\n",
       " 'which',\n",
       " 'existed',\n",
       " 'for',\n",
       " 'about',\n",
       " 'a',\n",
       " 'year',\n",
       " 'and',\n",
       " 'then',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'scandal',\n",
       " 'with',\n",
       " 'young',\n",
       " 'female',\n",
       " 'models',\n",
       " 'from',\n",
       " 'Minnesota',\n",
       " 'closed',\n",
       " 'down',\n",
       " 'But',\n",
       " 'so',\n",
       " 'suddenly',\n",
       " 'Im',\n",
       " 'a',\n",
       " 'model',\n",
       " 'and',\n",
       " 'Im',\n",
       " 'going',\n",
       " 'off',\n",
       " 'to',\n",
       " 'this',\n",
       " 'Bruce',\n",
       " 'Weber',\n",
       " 'photo',\n",
       " 'shoot',\n",
       " 'And',\n",
       " 'I',\n",
       " 'remember',\n",
       " 'we',\n",
       " 'met',\n",
       " 'early',\n",
       " 'in',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'us',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'male',\n",
       " 'models',\n",
       " 'and',\n",
       " 'a',\n",
       " 'van',\n",
       " 'And',\n",
       " 'as',\n",
       " 'were',\n",
       " 'going',\n",
       " 'for',\n",
       " 'to',\n",
       " 'uh',\n",
       " 'the',\n",
       " 'Hamptons',\n",
       " 'for',\n",
       " 'this',\n",
       " 'photo',\n",
       " 'shoot',\n",
       " 'its',\n",
       " 'like',\n",
       " 'six',\n",
       " 'am',\n",
       " 'this',\n",
       " 'one',\n",
       " 'guy',\n",
       " 'looks',\n",
       " 'around',\n",
       " 'hes',\n",
       " 'from',\n",
       " 'Texas',\n",
       " 'he',\n",
       " 'goes',\n",
       " 'Hey',\n",
       " 'were',\n",
       " 'all',\n",
       " 'blond',\n",
       " 'you',\n",
       " 'know',\n",
       " 'just',\n",
       " 'it',\n",
       " 'dawned',\n",
       " 'on',\n",
       " 'him',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'uh',\n",
       " 'as',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'interesting',\n",
       " 'And',\n",
       " 'so',\n",
       " 'we',\n",
       " 'get',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Hamptons',\n",
       " 'and',\n",
       " 'were',\n",
       " 'at',\n",
       " 'this',\n",
       " 'farmhouse',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'like',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'out',\n",
       " 'of',\n",
       " 'Christopher',\n",
       " 'Isherwood',\n",
       " 'The',\n",
       " 'Berlin',\n",
       " 'Stories',\n",
       " 'All',\n",
       " 'these',\n",
       " 'blond',\n",
       " 'boys',\n",
       " 'about',\n",
       " 'ten',\n",
       " 'of',\n",
       " 'us',\n",
       " 'running',\n",
       " 'around',\n",
       " 'doing',\n",
       " 'pushups',\n",
       " 'so',\n",
       " 'that',\n",
       " 'our',\n",
       " 'muscles',\n",
       " 'would',\n",
       " 'swell',\n",
       " 'and',\n",
       " 'in',\n",
       " 'and',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'pool',\n",
       " 'and',\n",
       " 'a',\n",
       " 'big',\n",
       " 'buffet',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'waiting',\n",
       " 'for',\n",
       " 'the',\n",
       " 'light',\n",
       " 'to',\n",
       " 'change',\n",
       " 'And',\n",
       " 'uh',\n",
       " 'so',\n",
       " 'I',\n",
       " 'get',\n",
       " 'my',\n",
       " 'picture',\n",
       " 'taken',\n",
       " 'by',\n",
       " 'Bruce',\n",
       " 'Weber',\n",
       " 'Wonderful',\n",
       " 'guy',\n",
       " 'very',\n",
       " 'talented',\n",
       " 'obviously',\n",
       " 'And',\n",
       " 'he',\n",
       " 'wanted',\n",
       " 'me',\n",
       " 'to',\n",
       " 'uh',\n",
       " 'drop',\n",
       " 'my',\n",
       " 'shorts',\n",
       " 'and',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'embarrassed',\n",
       " 'I',\n",
       " 'didnt',\n",
       " 'think',\n",
       " 'I',\n",
       " 'could',\n",
       " 'do',\n",
       " 'that',\n",
       " 'And',\n",
       " 'so',\n",
       " 'I',\n",
       " 'anyways',\n",
       " 'I',\n",
       " 'hid',\n",
       " 'everything',\n",
       " 'I',\n",
       " 'I',\n",
       " 'wasnt',\n",
       " 'able',\n",
       " 'to',\n",
       " 'expose',\n",
       " 'myself',\n",
       " 'So',\n",
       " 'anyways',\n",
       " 'he',\n",
       " 'took',\n",
       " 'these',\n",
       " 'pictures',\n",
       " 'of',\n",
       " 'me',\n",
       " 'and',\n",
       " 'I',\n",
       " 'have',\n",
       " 'one',\n",
       " 'and',\n",
       " 'Ill',\n",
       " 'uh',\n",
       " 'Im',\n",
       " 'going',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'it',\n",
       " 'out',\n",
       " 'as',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'gift',\n",
       " 'for',\n",
       " 'you',\n",
       " 'Uh',\n",
       " 'I',\n",
       " 'only',\n",
       " 'have',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'and',\n",
       " 'fifty',\n",
       " 'of',\n",
       " 'them',\n",
       " 'so',\n",
       " 'if',\n",
       " 'one',\n",
       " 'per',\n",
       " 'table',\n",
       " 'But',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'Bruce',\n",
       " 'Weber',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'me',\n",
       " 'and',\n",
       " 'uh',\n",
       " 'I',\n",
       " 'was',\n",
       " 'the',\n",
       " 'uh',\n",
       " 'anyway',\n",
       " 'the',\n",
       " 'physique',\n",
       " 'was',\n",
       " 'looking',\n",
       " 'good',\n",
       " 'then',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'see',\n",
       " 'I',\n",
       " 'had',\n",
       " 'hair',\n",
       " 'Its',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'depressing',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'that',\n",
       " 'now',\n",
       " 'I',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'but',\n",
       " 'uh',\n",
       " 'anyway',\n",
       " 'So',\n",
       " 'I',\n",
       " 'ended',\n",
       " 'up',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Whitney',\n",
       " 'Biennial',\n",
       " 'I',\n",
       " 'like',\n",
       " 'to',\n",
       " 'say',\n",
       " 'to',\n",
       " 'my',\n",
       " 'artist',\n",
       " 'friends',\n",
       " 'uh',\n",
       " 'Ive',\n",
       " 'been',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Biennial',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'in',\n",
       " 'this',\n",
       " 'picture',\n",
       " 'And',\n",
       " 'uh',\n",
       " 'in',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'from',\n",
       " 'my',\n",
       " 'uh',\n",
       " 'nursery',\n",
       " 'school',\n",
       " 'just',\n",
       " 'so',\n",
       " 'you',\n",
       " 'can',\n",
       " 'study',\n",
       " 'that',\n",
       " 'if',\n",
       " 'you',\n",
       " 'like',\n",
       " 'So',\n",
       " 'ns',\n",
       " 'so',\n",
       " 'pass',\n",
       " 'those',\n",
       " 'around',\n",
       " 'so',\n",
       " 'maybe',\n",
       " 'one',\n",
       " 'per',\n",
       " 'table',\n",
       " 'since',\n",
       " 'theres',\n",
       " 'only',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'and',\n",
       " 'fifty',\n",
       " 'But',\n",
       " 'so',\n",
       " 'it',\n",
       " 'can',\n",
       " 'get',\n",
       " 'to',\n",
       " 'the',\n",
       " 'back',\n",
       " 'Alright',\n",
       " 'so',\n",
       " 'here',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'model',\n",
       " 'and',\n",
       " 'I',\n",
       " 'got',\n",
       " 'several',\n",
       " 'jobs',\n",
       " 'And',\n",
       " 'but',\n",
       " 'at',\n",
       " 'that',\n",
       " 'photo',\n",
       " 'shoot',\n",
       " 'at',\n",
       " 'at',\n",
       " 'Bruce',\n",
       " 'Webers',\n",
       " 'farmhouse',\n",
       " 'I',\n",
       " 'met',\n",
       " 'a',\n",
       " 'very',\n",
       " 'pretty',\n",
       " 'girl',\n",
       " 'She',\n",
       " 'was',\n",
       " 'his',\n",
       " 'assistant',\n",
       " 'and',\n",
       " 'she',\n",
       " 'gave',\n",
       " 'me',\n",
       " 'her',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'So',\n",
       " 'about',\n",
       " 'a',\n",
       " 'week',\n",
       " 'later',\n",
       " 'Im',\n",
       " 'sp',\n",
       " 'doing',\n",
       " 'my',\n",
       " 'modeling',\n",
       " 'appointments',\n",
       " 'which',\n",
       " 'are',\n",
       " 'called',\n",
       " 'gosees',\n",
       " 'which',\n",
       " 'was',\n",
       " 'made',\n",
       " 'very',\n",
       " 'simple',\n",
       " 'for',\n",
       " 'the',\n",
       " 'models',\n",
       " 'It',\n",
       " 'was',\n",
       " 'go',\n",
       " 'see',\n",
       " 'someone',\n",
       " 'And',\n",
       " 'so',\n",
       " 'this',\n",
       " 'was',\n",
       " 'what',\n",
       " 'they',\n",
       " 'called',\n",
       " 'appoi',\n",
       " 'uh',\n",
       " 'appointments',\n",
       " 'were',\n",
       " 'gosees',\n",
       " 'So',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'a',\n",
       " 'day',\n",
       " 'of',\n",
       " 'gosees',\n",
       " 'and',\n",
       " 'I',\n",
       " 'found',\n",
       " 'myself',\n",
       " 'in',\n",
       " 'the',\n",
       " 'West',\n",
       " 'Village',\n",
       " 'and',\n",
       " 'uh',\n",
       " 'right',\n",
       " 'by',\n",
       " 'Cornelia',\n",
       " 'Street',\n",
       " 'And',\n",
       " 'I',\n",
       " 'remembered',\n",
       " 'that',\n",
       " 'that',\n",
       " 'girl',\n",
       " 'lived',\n",
       " 'on',\n",
       " 'Cornelia',\n",
       " 'Street',\n",
       " 'And',\n",
       " 'I',\n",
       " 'my',\n",
       " 'high',\n",
       " 'school',\n",
       " 'love',\n",
       " 'was',\n",
       " 'a',\n",
       " 'girl',\n",
       " 'named',\n",
       " 'Cornelia',\n",
       " 'And',\n",
       " 'so',\n",
       " 'suddenly',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'fusing',\n",
       " 'in',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'So',\n",
       " 'I',\n",
       " 'call',\n",
       " 'her',\n",
       " 'and',\n",
       " 'uh',\n",
       " 'I',\n",
       " 'get',\n",
       " 'her',\n",
       " 'roommate',\n",
       " 'and',\n",
       " 'I',\n",
       " 'explain',\n",
       " 'that',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'neighborhood',\n",
       " 'and',\n",
       " 'is',\n",
       " 'I',\n",
       " 'wont',\n",
       " ...]"
      ]
     },
     "execution_count": 1591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "id": "fd5e007c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1589], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m tg_words \u001b[38;5;241m=\u001b[39m textgrid\u001b[38;5;241m.\u001b[39mgetTier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m contents, words_transcribed \u001b[38;5;241m=\u001b[39m load_transcription(transcript_fn)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(tg_words) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(words_transcribed))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# create the dictionary to store things in\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# put the transcript in the raw form\u001b[39;00m\n\u001b[1;32m     10\u001b[0m align \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "textgrid = load_clean_textgrid(praat_fn)\n",
    "tg_words = textgrid.getTier('word')\n",
    "\n",
    "contents, words_transcribed = load_transcription(transcript_fn)\n",
    "\n",
    "for tg_word, transcribed_word \n",
    "\n",
    "assert (len(tg_words) == len(words_transcribed))\n",
    "\n",
    "# create the dictionary to store things in\n",
    "# put the transcript in the raw form\n",
    "align = {}\n",
    "align['transcript'] = contents[0]\n",
    "align['words'] = []\n",
    "\n",
    "# Taken from Kaldi metasentence tokenizer\n",
    "# splits the transcript based on any punctuation besides for apostrophes and hyphens\n",
    "regex_split_pattern = r'(\\w|\\.\\w|\\:\\w|\\â€™\\w|\\'\\w|\\-\\w)+'\n",
    "\n",
    "iterator = list(re.finditer(regex_split_pattern, ''.join(contents), re.UNICODE))\n",
    "n_items = len(list(iterator))\n",
    "# make sure the iterator matches the length\n",
    "# assert (n_items == len(tg_words) == len(words_transcribed))\n",
    "\n",
    "\n",
    "## this block helps find what words are wrong\n",
    "for word_info, m in zip(tg_words, iterator):\n",
    "    \n",
    "    if word_info[-1].lower() != m.group().lower():\n",
    "        print (m)\n",
    "    \n",
    "sys.exit(0)\n",
    "\n",
    "# # if all matches we're good to go\n",
    "# for word_info, m in zip(tg_words, iterator):\n",
    "    \n",
    "#     # span of the word in characters relative to the overall string\n",
    "#     start_offset, end_offset = m.span()\n",
    "#     word = m.group()\n",
    "    \n",
    "#     # crop textgrid to the word\n",
    "#     cropped_grid = textgrid.crop(cropStart=word_info[0], cropEnd=word_info[1], mode='truncated', rebaseToZero=False)\n",
    "#     tg_phones = cropped_grid.getTier('phone').entries\n",
    "#     word_phones = []\n",
    "    \n",
    "#     for phone_info in tg_phones:\n",
    "#         phone = re.sub(r'\\d+', '', phone_info[-1])\n",
    "#         duration = phone_info[1] - phone_info[0]\n",
    "#         word_phones.append({'duration': duration, 'phone': phone})\n",
    "    \n",
    "#     word_align = {\n",
    "#         'alignedWord': word.lower(),\n",
    "#         \"case\": \"success\",\n",
    "#         'word': word,\n",
    "#         'start': word_info[0],\n",
    "#         'end': word_info[1],\n",
    "#         'phones': word_phones,\n",
    "#         \"startOffset\": start_offset,\n",
    "#         \"endOffset\": end_offset,\n",
    "#     }\n",
    "\n",
    "#     align['words'].append(word_align)\n",
    "\n",
    "# return align"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
