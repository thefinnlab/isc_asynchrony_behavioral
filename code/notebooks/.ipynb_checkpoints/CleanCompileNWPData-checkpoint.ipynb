{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b725b6a9-6017-48a7-b5ab-1560acd02d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "import os, sys, glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import tqdm\n",
    "from manual_spellchecker import spell_checker\n",
    "\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/utils/')\n",
    "\n",
    "from config import *\n",
    "import dataset_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8686534e-82eb-4c11-b928-505ea7d9248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'next-word-prediction'\n",
    "EXPERIMENT_VERSION = 'final-multimodal-01'\n",
    "TASK = 'wheretheressmoke'\n",
    "\n",
    "gentle_dir = os.path.join(BASE_DIR, 'stimuli', 'gentle')\n",
    "results_dir = os.path.join(BASE_DIR, 'experiments',  EXPERIMENT_NAME, 'results', EXPERIMENT_VERSION)\n",
    "preproc_dir = os.path.join(BASE_DIR, 'stimuli', 'preprocessed')\n",
    "\n",
    "# set the directories we need\n",
    "models_dir = os.path.join(BASE_DIR, 'derivatives/model-predictions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93d039-283d-4bb3-8362-0b65856dd62e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367f4587-3b80-40f1-8b48-934bf4e6e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing shutil module  \n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def check_used_files(experiment_name, experiment_version, task, clean_errors=False, max_missing_responses=5):\n",
    "    '''\n",
    "    Grabs used files based on the meta file and results directory\n",
    "    Returns list of subjects that were used and ones that had errors\n",
    "    '''\n",
    "    \n",
    "    checker = {\n",
    "        'complete': [],\n",
    "        'incomplete': [],\n",
    "        'error': [],\n",
    "        'missing': [],\n",
    "    }\n",
    "\n",
    "    meta_dir = os.path.join('/dartfs/rc/lab/F/FinnLab/tommy/jspsych_experiments/utils/experiment_meta/', experiment_name)\n",
    "    meta_file = pd.read_csv(os.path.join(meta_dir, f'{experiment_version}-{task}.csv'))\n",
    "    \n",
    "    source_dir = os.path.join(BASE_DIR, 'stimuli',  'presentation_orders', experiment_version, task, 'jspsych')\n",
    "    results_dir = os.path.join(BASE_DIR, 'experiments',  experiment_name, 'results', experiment_version)\n",
    "    \n",
    "    # grab the used files\n",
    "    used_fns = meta_file[meta_file['used'].fillna(0).astype(bool)]\n",
    "    \n",
    "    approve_ids = []\n",
    "    \n",
    "    # go through each used file\n",
    "    for i, fn in used_fns.iterrows():\n",
    "        # grab info regarding subject name and modality\n",
    "        curr_path = Path(fn['subject_fns'])\n",
    "        sub = curr_path.stem.split('_')[0]\n",
    "        modality = curr_path.parents[0].stem\n",
    "        \n",
    "        # find the corresponding parameter file for the current subject\n",
    "        parameter_fn = glob.glob(os.path.join(source_dir, f'{sub}*.json'))\n",
    "        assert (len(parameter_fn) == 1)\n",
    "        \n",
    "        # load the parameter file to compare to the subject's results\n",
    "        df_parameters = pd.read_json(parameter_fn[0], orient='records')\n",
    "        df_parameters = df_parameters.dropna()\n",
    "        df_parameters['word_index'] = df_parameters['word_index'].dropna().astype(int)\n",
    "        \n",
    "        # then grab the subject results\n",
    "        sub_results_dir = os.path.join(results_dir, task, modality, sub)\n",
    "        \n",
    "        # load results from the completed experiment\n",
    "        try:\n",
    "            current_id, demographics, experience, responses = load_participant_results(sub_results_dir, sub)\n",
    "            \n",
    "            # append if approving\n",
    "            approve_ids.append(current_id)\n",
    "        except:\n",
    "#             if os.path.exists(sub_results_dir):\n",
    "            checker['error'].append((i, modality, sub))\n",
    "            continue\n",
    "            \n",
    "        # check that all indices of trials match and all responses are there\n",
    "        all_trials_complete = np.all(responses['word_index'] == df_parameters['word_index'])\n",
    "        missing_response_threshold = sum(pd.isnull(responses['response'])) <= max_missing_responses\n",
    "        \n",
    "#         all_responses_complete = np.all(~pd.isnull(responses['response']))\n",
    "        \n",
    "        # also ensure that we have the right amount of demographics/experience questions\n",
    "        all_checks_complete = np.all([\n",
    "            all_trials_complete, \n",
    "            missing_response_threshold, \n",
    "            len(demographics)==4,\n",
    "            len(experience)==2,\n",
    "        ])\n",
    "        \n",
    "        if all_trials_complete and missing_response_threshold:\n",
    "            # add to list of people completed\n",
    "            checker['complete'].append((i, modality, sub, current_id))\n",
    "        else:\n",
    "            checker['incomplete'].append((i, modality, sub, current_id))\n",
    "            \n",
    "        del current_id\n",
    "        \n",
    "    if clean_errors:\n",
    "        clean_meta_errors(checker, experiment_name, experiment_version, task)\n",
    "        \n",
    "        # run again and return from here now that its updated\n",
    "        return check_used_files(experiment_name, experiment_version, task, clean_errors=False)\n",
    "    else:\n",
    "        return checker, approve_ids\n",
    "\n",
    "def clean_meta_errors(checker, experiment_name, experiment_version, task):\n",
    "    \n",
    "    meta_dir = os.path.join('/dartfs/rc/lab/F/FinnLab/tommy/jspsych_experiments/utils/experiment_meta/', experiment_name)\n",
    "    meta_fn = os.path.join(meta_dir, f'{experiment_version}-{task}.csv')\n",
    "    \n",
    "    meta_file = pd.read_csv(meta_fn)\n",
    "    \n",
    "    results_dir = os.path.join(BASE_DIR, 'experiments',  experiment_name, 'results', experiment_version)\n",
    "    \n",
    "    errors = checker['error']\n",
    "    modalities = ['text', 'audio']\n",
    "    \n",
    "    if any(checker['error']):\n",
    "        \n",
    "        remove_idxs, _, _ = zip(*checker['error']) \n",
    "        remove_idxs = list(remove_idxs)\n",
    "        \n",
    "        for modality in modalities:\n",
    "\n",
    "            # get errors for the current modality\n",
    "            modality_errors = [error for error in errors if error[1] == modality]\n",
    "            errors_dir = os.path.join(results_dir, task, modality, 'error')\n",
    "\n",
    "            # get new errors dir if previous has files in it\n",
    "            batch_errors = sorted(glob.glob(os.path.join(errors_dir, '*')))\n",
    "\n",
    "            if any(batch_errors):\n",
    "                last_error_dir = Path(batch_errors[-1]).stem\n",
    "            else:\n",
    "                last_error_dir = 'batch_1'\n",
    "\n",
    "            if any(glob.glob(os.path.join(errors_dir, last_error_dir, '*'))):\n",
    "                curr_batch_num = int(last_error_dir.split('_')[-1]) + 1\n",
    "                curr_error_dir = os.path.join(errors_dir, f'batch_{curr_batch_num}')\n",
    "                os.makedirs(curr_error_dir)\n",
    "            else:\n",
    "                curr_error_dir = os.path.join(errors_dir, last_error_dir)\n",
    "\n",
    "            for item in modality_errors:\n",
    "                file_idx, modality, sub = item\n",
    "\n",
    "                # then grab the subject results\n",
    "                sub_results_dir = os.path.join(results_dir, task, modality, sub)\n",
    "\n",
    "                if os.path.exists(sub_results_dir):\n",
    "                    print ('Here')\n",
    "                    shutil.move(sub_results_dir, curr_error_dir)\n",
    "\n",
    "\n",
    "        print (f'Cleaned meta file!')\n",
    "        meta_file.loc[list(remove_idxs), 'used'] = None\n",
    "        meta_file['used'] = meta_file['used'].astype('Int64')\n",
    "        meta_file.to_csv(meta_fn, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16181d1a-e19e-4785-add4-dac79b93a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_results(sub_dir, sub):\n",
    "    \n",
    "    # load and filter down to response trials\n",
    "    df_results = pd.read_csv(os.path.join(sub_dir, f'{sub}_next-word-prediction.csv')).fillna(False)\n",
    "    df_results['word_index'] = df_results['word_index'].astype(int)\n",
    "    \n",
    "    # grab the prolific id\n",
    "    prolific_id = list(set(df_results['prolific_id']))   \n",
    "\n",
    "    # filter down demographics\n",
    "    demographics = df_results[df_results['experiment_phase'].str.contains('demographics').fillna(False)]\n",
    "    demographics = demographics[['experiment_phase', 'response']].reset_index(drop=True)\n",
    "    \n",
    "    # age, race, ethnicity, gender\n",
    "    assert (len(demographics) == 4)\n",
    "    \n",
    "    # filter down to questinos about moth/story experience\n",
    "    experience = df_results[df_results['experiment_phase'].str.contains('experience').fillna(False)]\n",
    "    experience = experience[['experiment_phase', 'response']].reset_index(drop=True)\n",
    "    \n",
    "    # moth experience + story experience\n",
    "    assert (len(experience) == 2)\n",
    "    \n",
    "    # filter down to get the responses\n",
    "    responses = df_results[df_results['experiment_phase'] == 'test']\n",
    "    responses.loc[:,'response'] = responses['response'].str.lower()\n",
    "    responses = responses[['critical_word', 'word_index', 'entropy_group', 'accuracy_group', 'response']].reset_index(drop=True)\n",
    "    \n",
    "    return prolific_id[0], demographics, experience, responses\n",
    "\n",
    "def add_word_response(dict, key, value):\n",
    "    \n",
    "    if key in dict:\n",
    "        dict[key].append(value)\n",
    "    else:\n",
    "        dict[key] = [value]\n",
    "        \n",
    "    return dict\n",
    "\n",
    "def aggregate_participant_responses(results_dir, task, sub_mod_list):\n",
    "    \n",
    "#     MODALITIES = ['audio', 'text']\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['prolific_id', 'modality', 'subject',  'word_index', 'response', 'ground_truth', 'entropy_group', 'accuracy_group'])\n",
    "    \n",
    "    all_ids = []\n",
    "    \n",
    "    for sub, mod in sub_mod_list: \n",
    "        # go through each task and get participant data\n",
    "        sub_dir = os.path.join(results_dir, task, mod, sub)\n",
    "        print (sub, mod)\n",
    "        if os.path.exists(sub_dir):\n",
    "            current_id, demographics, experience, responses = load_participant_results(sub_dir, sub)\n",
    "            responses['response'] = responses['response'].fillna('')\n",
    "\n",
    "            # for right now only focus on responses\n",
    "            for index, response, critical_word, entropy_group, accuracy_group in responses[['word_index', 'response', 'critical_word', 'entropy_group', 'accuracy_group']].values:\n",
    "\n",
    "                df_results.loc[len(df_results)] = {\n",
    "                    'prolific_id': current_id,\n",
    "                    'modality': mod,\n",
    "                    'subject': sub,\n",
    "                    'word_index': index,\n",
    "                    'response': response,\n",
    "                    'ground_truth': critical_word.lower(),\n",
    "                    'entropy_group': entropy_group, \n",
    "                    'accuracy_group': accuracy_group\n",
    "                }\n",
    "            \n",
    "            all_ids.append(current_id)\n",
    "        else:\n",
    "            print (f'File not exists: {mod}, {sub}')\n",
    "            \n",
    "    return df_results\n",
    "\n",
    "def get_human_probs(responses):\n",
    "    \n",
    "    unique, counts = np.unique(responses, return_counts=True)\n",
    "    probs = counts / sum(counts)\n",
    "    \n",
    "    return probs, unique\n",
    "\n",
    "def strip_punctuation(text):\n",
    "    \n",
    "    full_text = re.sub('[^A-Za-z0-9]+', '', text)\n",
    "    \n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43977641-aee7-4c9b-bfc4-3934fbba87ff",
   "metadata": {},
   "source": [
    "## Functions for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddf517-3859-4826-853f-3d7b1ae80791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant, string, time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def clean_participant_responses(df_results, df_transcript):\n",
    "    \n",
    "    # grab indices of responses --> used to index back in\n",
    "    response_indices = df_results['experiment_phase'] == 'test'\n",
    "    response_indices = np.where(response_indices)[0]\n",
    "\n",
    "    checked_indices = []\n",
    "    \n",
    "    # filter down to get the responses\n",
    "    df_responses = df_results.iloc[response_indices, :].reset_index(drop=True)\n",
    "    \n",
    "    ##############################\n",
    "    ###### Run spell-check #######\n",
    "    ##############################\n",
    "\n",
    "    print (f'##########################\\n' +\n",
    "           f'### Running spellcheck ###\\n' +\n",
    "           f'##########################\\n\\n')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    enc_dict = enchant.Dict(\"en_US\")\n",
    "    \n",
    "    for index, df in df_responses.iterrows():\n",
    "\n",
    "        response = df['response']\n",
    "        \n",
    "        # tokens = df['response'].split()\n",
    "        if not enc_dict.check(response) or response in string.punctuation and index not in checked_indices:\n",
    "            df = prompt_correct_response(df, df_transcript, enc_dict, prompt_correction=False)\n",
    "            df_responses.iloc[df.name] = df\n",
    "            checked_indices.append(index)\n",
    "            \n",
    "\n",
    "    ##############################\n",
    "    ######## Find phrases ########\n",
    "    ##############################\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    print (f'##########################\\n' +\n",
    "           f'####### Find phrases #####\\n' +\n",
    "           f'##########################\\n\\n')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # go through each row\n",
    "    for index, df in df_responses.iterrows():\n",
    "        response = df['response'].split()\n",
    "\n",
    "        if len(response) > 1 and index not in checked_indices:\n",
    "            df = prompt_correct_response(df, df_transcript, enc_dict, prompt_correction=False)\n",
    "            df_responses.iloc[df.name] = df\n",
    "            checked_indices.append(index)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ##############################\n",
    "    ######## Final check #########\n",
    "    ##############################\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    print (f'##########################\\n' +\n",
    "           f'####### Final check ######\\n' +\n",
    "           f'##########################\\n\\n')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # go through each row\n",
    "    for index, df in df_responses.iterrows():\n",
    "\n",
    "        if index not in checked_indices:\n",
    "            df = prompt_correct_response(df, df_transcript, enc_dict, prompt_correction=True)\n",
    "            df_responses.iloc[df.name] = df\n",
    "            checked_indices.append(index)\n",
    "        \n",
    "    df_results.iloc[response_indices] = df_responses\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def prompt_correct_response(df_response, df_transcript, enc_dict, range_display=7, prompt_correction=False):\n",
    "    \n",
    "    word_index = df_response['word_index']\n",
    "    response = df_response['response']\n",
    "    ground_truth = df_response['critical_word']\n",
    "    \n",
    "    start_index = (word_index - range_display) if (word_index - range_display) >= 0 else 0 \n",
    "    end_index = (word_index + range_display) if (word_index + range_display) - len(df_transcript) <= 0 else None\n",
    "    \n",
    "    # grab the context    \n",
    "    start_context = df_transcript['Word_Written'].iloc[start_index:word_index]\n",
    "    end_context = df_transcript['Word_Written'].iloc[word_index + 1:end_index]\n",
    "    \n",
    "    # display the word\n",
    "    string_to_print = \"\"\n",
    "    \n",
    "    if start_index > 0:\n",
    "        string_to_print+= \".... \"\n",
    "    \n",
    "    string_to_print+= \" \".join(start_context) + \" \" + \"\\033[43;30m\" + response + \"\\033[m\" + \" \" + \" \".join(end_context)\n",
    "    \n",
    "    if end_index < len(df_transcript):\n",
    "        string_to_print+= \" ....\"\n",
    "\n",
    "    clear_output(wait=False)\n",
    "\n",
    "    print(\"\\n\\nCurrent Word: \" + string_to_print)\n",
    "    print (\"Ground Truth: \", ground_truth)\n",
    "    \n",
    "    # suggestions = enc_dict.suggest(misspelled_word)\n",
    "    if prompt_correction:\n",
    "        prompt_correction = input('\\nNeeds correction? [y/n]: ')\n",
    "    \n",
    "    if prompt_correction == 'y' or prompt_correction == False:\n",
    "        suggestions = enc_dict.suggest(response)\n",
    "        print(\"\\Suggestions: \", suggestions)\n",
    "        correct_word = input(\"\\nCorrect Version: \")\n",
    "        \n",
    "        if correct_word == \"-999\":\n",
    "            break_flag = True\n",
    "            sys.exit(0)\n",
    "        elif correct_word.isdigit() and int(correct_word) < len(suggestions): # User wants to use suggestion\n",
    "            df_response['response'] = df_response['response'].replace(response, suggestions[int(correct_word)-1])\n",
    "        elif len(correct_word) == 0: # User wants to Skip\n",
    "            return df_response\n",
    "        elif correct_word == \"''\" or correct_word == '\"\"': # User wants to remove the word\n",
    "            df_response['response'] = df_response['response'].replace(response, \"\")\n",
    "        else:\n",
    "            df_response['response'] = df_response['response'].replace(response, correct_word)\n",
    "\n",
    "    return df_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0e227-28e5-4b2f-b756-6b8e9c31d916",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load and clean data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee51f6fe-992a-4f00-9bf0-ad534435870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "5df0932af9a01d0dabd9313d\n",
      "658dc5ae8ed0c5190d385266\n",
      "60bf4ae16dbab59c9fdd4218\n",
      "6346f314592ee4d8c3d84e57\n",
      "5dccabc026eb869389043084\n",
      "65a3ec70fa2315c1f83c19af\n",
      "62a999b8ed876efe5ffe9599\n",
      "654658c94edb85e1de07f87a\n",
      "62b2f74cf3794e252cc7d1a7\n",
      "644963b432e6a701b58ea4ac\n",
      "65a19b9691a3f0e753743321\n",
      "5e1297656e8aab8e8a1b3b76\n",
      "62682277645054f5802459b8\n",
      "56a8930d7f2472000c93764e\n",
      "659aba3aa97e20e203171594\n",
      "5e3afe879d5f1e30b75b9ca6\n",
      "596155a998cf77000106f8d8\n",
      "599a9252bbe848000179676e\n",
      "5d8e154af2858200171fdb95\n",
      "591c70f8f399850001c51444\n",
      "59d4c100078dbe0001951236\n",
      "5e3723a2c0b2896ad554be73\n",
      "5ecd4b104b4dc408fcf4eb16\n",
      "5c4b4d5c2cfe4d00018485cc\n",
      "5dcddf9f4d51e40a5292727d\n",
      "62a212208e8395cfb1c4e42b\n",
      "643e64c922e6c2f53d73975f\n",
      "5967e9a831394d0001abdb3f\n",
      "61502dee7a3a5468adbb2222\n",
      "5bec4ebcf2dba6000166d420\n",
      "5a1342b7f2e3460001edbfd2\n",
      "65a68cb02b70524088c53064\n",
      "59d4b084115096000190dbce\n",
      "62f108ab1d119c891d45ae6a\n",
      "5f9e03f3517e0d3ad1eab67b\n",
      "62eac867210f0e2e8d322d44\n",
      "6147c5874b61952e42e9b2bd\n",
      "5ea4cebb8944a8495280db42\n",
      "5c60501d767686000100150c\n",
      "60a6b2ed58d0aaed52f1dcf4\n",
      "5eb7094fbb8ed70b61398cff\n",
      "5cd726aab1fa62001a8de584\n",
      "65562141ae0a6660324ce572\n",
      "5cc99062d918560016acf6ac\n",
      "5bf1de1556a321000106fae0\n",
      "5e85f278c880ee1edb7e96ee\n",
      "632892646eb1fff474584dd7\n",
      "5f778d553167a12eae0e1c00\n",
      "6002e90144049f32edaf9ccf\n",
      "5ecae23b40dae00008174c32\n",
      "5c738c1738ff4500017ba1fd\n",
      "62e401504b743abad9f8b11c\n",
      "651c617c3970ec3872c3b643\n",
      "60f84b82661faf6c4a0c56a5\n",
      "5c9623dd35599200175642e4\n",
      "6483b216f5f21f0463109ac7\n",
      "5e96185ae3d45508abe19a36\n",
      "6579c16c8fc1d05be830eb13\n",
      "5a2ef9bbfd28e9000102ee68\n",
      "6396044f6ae489bb820c67a5\n",
      "5ce9b0e4be5a6b00163f6870\n",
      "5fd9227fbeeb773aa4d6c986\n",
      "5c60adbd4fde3d00014748bf\n",
      "659969f4ce23a5b8af24ceeb\n",
      "62e02b26e879244a99e852fa\n",
      "5b7bf6c98c721a00015d1feb\n",
      "5fd8ea198512a801831f6b85\n",
      "63cd84b96c0d2867bf761f49\n",
      "5bbb5e3f118c0600013c3202\n",
      "5fcf9c90465b1c09b44e6588\n",
      "5c1d234d89f035000172aeb7\n",
      "5b97f70161c19e00018db4a8\n",
      "5ebeeaaf1f300410fffb8d9e\n",
      "655e0b2c5ca089384a828fbf\n",
      "6137753896c9b6b5813a2432\n",
      "5e879ef6785373412156181e\n",
      "60819ba1a8862e33495f8914\n",
      "5d87aa1f1af55f00010adb4b\n",
      "6547a4f91dc8dbde395fe617\n",
      "5e4761e624b17f2239a6473a\n",
      "6357a92c14a05d21ebdd897f\n",
      "5f8ea1044999a9000ae5a0e9\n",
      "62b629edb7c97d5de8516ad0\n",
      "5803cb9a3073510001231d82\n",
      "654d3b4c7746d227147f3a12\n",
      "60fe7bf61c7567f5cca9ade6\n",
      "5f4d968cacc80fa73143cdf3\n",
      "5ebc0abd2cc5f1054c82a0d7\n",
      "63af557b3d4f219c3226b7d6\n",
      "653c88e34739d6bcfc9d8252\n",
      "57d88513995a0b0001635002\n",
      "60ce4fceb13609a2c039248e\n",
      "5bb756696322c5000159756c\n",
      "6101eeecbfd86b113fe98d3b\n",
      "6447a21bdb359b012f49465b\n",
      "5fa07c635b16f50d21483d5e\n",
      "65107bf7698f1e129de87140\n",
      "5eaee5791eaaad06ab45818c\n",
      "5adef850eb60400001539109\n",
      "5f3d6975ef131710ed519c7a\n",
      "65412a1e33be6763f5c949fa\n",
      "63e632b888bcbe9376df4f62\n",
      "5be59ce3520a3300010e28a9\n",
      "5c50efd2cc71f4000125ce0d\n",
      "5bc668e2d52843000153fb2b\n",
      "63ebbb358ff6781d8dc68cdb\n",
      "656ca9f8ab25b756c7af6ffe\n",
      "5b266738007d870001c7c360\n",
      "5e7dba4f1d6961436474c8f2\n",
      "5c78f007998fb70001efcb33\n",
      "612f4efe7a2e36e60e3254a7\n",
      "6326e63755a0f49a9c4b9063\n",
      "6100105892a2248ae5d48498\n",
      "6414ed796f1e738ff722d812\n",
      "6579e03fad6f19194fa44c26\n",
      "6536a9f1978ba198e27ba3bf\n",
      "62728a4122289635e97d12f2\n",
      "5d8b66f5d189bd001a378273\n",
      "60a6a76aca6c98b970de90f2\n",
      "615a170c6eca532c6f57e09c\n",
      "5e14f72f557425b04528df9a\n",
      "6156fef09d1ab07148870099\n",
      "6346a9acc2a832b58c8e7229\n",
      "55d8389069dbc30005b67b57\n",
      "65a2a37325b0569bdc0c795e\n",
      "5eac3c1950fecd25d2d6d5ed\n",
      "63cfee94707bca4ddee3eb05\n",
      "5d63179aa3b94d0001da4bb6\n",
      "6136001fcd0e07e6f5f66bc1\n",
      "650af66915d3196ad7367e8b\n",
      "5f48329af7606d1b45b2e726\n",
      "6425ffdf7fd742839b924ac5\n",
      "5f20817e92b4d83793b52912\n",
      "5f501d8211a2531866f6fb6d\n",
      "63d13c076dd249ca3a6bffbb\n",
      "60fd1f3510ad12e40aa95564\n",
      "5c5208dee3209c000177e957\n",
      "5db1b1b6cd3329000ba29566\n",
      "659c0c2dc64119b56219c743\n",
      "58d283fcbfaa440001d1f097\n",
      "5ea19dcac30e0005e6e6b6e3\n",
      "576020968ddaf40006ce9746\n",
      "5e1ed72fb0285720462a8649\n",
      "5dc47e95b1dabb3535d03ea4\n",
      "5f61f7f59df6ca1bfe6a8a89\n",
      "5d863f244d401800016ece02\n",
      "5d271ba32350070001871592\n",
      "63b6cee06aaa9fc9669b8cc2\n",
      "5d6513f46f5284000118ef1d\n",
      "6531958a74d39ace86a60bd9\n",
      "5b258c9ba7cee100011d8aad\n",
      "57d0a0bee3221e00015fe385\n",
      "6532eac81d381a2334adee8d\n",
      "60171c9b1a726593103182b3\n",
      "5c75c7c92c662600014eb328\n",
      "6109482350367148ce0aa834\n",
      "65676fba8308e02bbd3675bf\n",
      "5fecdbad0b1a449e3288b07b\n",
      "643adb4a213b87bfc7e21e3f\n",
      "5d8cef3c28e183001a335ab0\n",
      "5b20fb104c72120001f26359\n",
      "656f4452d05acaacffa68c8f\n",
      "5ff45beefdb6e6b063b4c520\n",
      "5c98c51774cc7f0001e67c8c\n",
      "6172cf92f2ea6613f717abb6\n",
      "5bcedec641f0710001c74dd5\n",
      "659ea43fea7c0cc45bbe771f\n",
      "655f8b313aadb767f13fddeb\n",
      "60f816ff1fa74fcfab532378\n",
      "5bf368846edd7200017136c7\n",
      "5e7a2ccd69a7770604dfb352\n",
      "54f4e2d1fdf99b4e913fdf01\n",
      "5c92f797803bff0017fef8dd\n",
      "639f294882a3797f77a3dd81\n",
      "6581a367a62877b8742ec59a\n",
      "63d79eb140827bcc78bcce66\n",
      "5928947add1a250001b4e859\n",
      "5d41d708128a05000183c461\n",
      "5f049ae64a92a573b2624a18\n",
      "5f6e2f793c9b1032dbe72def\n",
      "5eac84ff4efbe80ffd3962f1\n",
      "5e0b388b15ef4037cebdecc9\n",
      "63d4019999c9ab839156014c\n",
      "60f4a8cec0899207895635cb\n",
      "603bbf426ba69e8af20ace6f\n",
      "58ff31a1d10e2b000108579e\n",
      "5ed2bb7a67d51b24b2ac4037\n",
      "5c0fcccc1f6f150001487111\n",
      "5b4b0e8d94020800016323ed\n",
      "62713336883f41f7f3fb1b6a\n",
      "6450ca7370b4914f3e8822c6\n",
      "5e0fdde8b638537085d51b6c\n",
      "63ed35a73e8bacd8d4661f91\n",
      "637fbedd06b96e980ee37a6d\n",
      "6566d90835fd00183bd5989b\n",
      "5a8f13595292b80001235e09\n",
      "63d29a1e50cf0f82998d2564\n",
      "652d36303f3a453baa07dc1c\n",
      "6122b9ffce05d8e56860755a\n",
      "63f85b1c3124fd03faff2126\n",
      "5c44cf2da5487b00011d0b80\n",
      "63d508e7cfc3204304a949e2\n",
      "5aeabf2c15a9c300011acbc3\n",
      "62d6d87d91cf24a3c1c0f10c\n",
      "5f8e16511b3c641de0918ccd\n",
      "5dd42e7f35cf744223c60d1b\n",
      "6576349f6e119563e8473f61\n",
      "6598142ac036fb7fffc400a3\n",
      "6563955180c3c85a94b35a4f\n",
      "63d7cd776c3b50b48eabd288\n",
      "5e1a39f62b01352b6c9e14bf\n",
      "65a54037a9c2c5d66a3601b2\n",
      "659ff67b392280e39ead5360\n",
      "55d4d11258c35800113dc2ab\n",
      "652aa12e31990667f51df862\n",
      "65389f0b0f181197c4218f6d\n",
      "58d3d69a47aa1e00010476f4\n",
      "654271457fbdad2bd2df362b\n",
      "63d193c45e01ccb694993e7f\n",
      "646e53ef6c1dac9a13cd2985\n",
      "659ea40d452c933f20961716\n",
      "5685850c333cbd000d4e042f\n",
      "6575c69e259bc98ce720601c\n",
      "5ae9cde00335e200019e9eed\n",
      "5dbd96bc80dbee2c71a8c9d6\n",
      "64087b8444f656e9e2b74446\n",
      "653e666cc034dbb89a5b83ce\n",
      "6533d9ae7044b1ee2d07c719\n",
      "63e6132468f99695fc58b132\n",
      "63d15e1be853005ff591b935\n",
      "615df15772fbf6ba104032fe\n",
      "6441795624090301ddeba81e\n",
      "5ca5fb084f3e9d0015440d1d\n",
      "63e61d24e1c77b4b584e879f\n",
      "656ddbbc2e1b03788c77a652\n",
      "5d6a924a9e02d2001514311a\n",
      "645ab2ad1d9df4d16511cd71\n",
      "63de88d74d63ce321662f029\n",
      "65577b529ee538baa6f0093a\n",
      "5f985f3a4bc1cf120675f408\n",
      "63d7bea144b8a11f63c2a763\n",
      "634d76cccd09d8bfe5061cc3\n",
      "62714a240ed387f760f6741b\n",
      "61017941304cf7ac38c2e110\n",
      "6304e1c6e359b6e618e00ada\n",
      "5f105b47d36c8701ec112317\n",
      "5f11eb333c6e2c0df5b92270\n",
      "6400e0dd862feacb579475a8\n",
      "58a470a2ef58a9000119c101\n",
      "633599d83df1823b08ae2e61\n",
      "5bc73b9f821054000181a853\n",
      "652be58c7d5885fc2d4abe9e\n",
      "5d612ae16512d700159face7\n",
      "55a43c83fdf99b02ff6cb0aa\n",
      "602c42fcd6ab3e5033c45951\n",
      "5eee77689e63ac330681ffe9\n",
      "6560adbbe3d0b2465d4e4b89\n",
      "6346d43493a4f14e735bc630\n",
      "6346be8dc544a1c320c370d3\n",
      "5d5c6d2def3921001a47ec02\n",
      "5c4207e8f35ed30001a737d7\n",
      "65a5372ee7a6f4f7ed04f2e6\n",
      "600f46f6c513db11698a960d\n",
      "63f78703fbd3a523a963d860\n",
      "5e24fbd4e1f467771c234e5f\n",
      "5b1966a168a5ed0001735813\n",
      "5cf1824f1ae74d00015fbd39\n",
      "6160717242827a64a55d99ad\n",
      "5e83247a6d7daf01d9a33632\n",
      "6018a5c0e1600b187ccb8693\n",
      "5b14532ce9270900013c5bf6\n",
      "6527ee1286cbfa79299de373\n",
      "65352d870dfbcccbe48634fe\n",
      "5c9d81d42d9a05001690c490\n",
      "5e19b24b2bf9512392d6dd90\n",
      "63d7ac4c9acdaa357a0ae2d3\n",
      "63f77cac11a2ddb8e7276c44\n",
      "5ee18255395f8655ae190e48\n",
      "63fa2f029381a13d9f2a36a8\n",
      "633c74ad6178784ed5b52104\n",
      "5cf12ddbf17e370017a278c5\n",
      "628fa4639666e8550aa139d5\n",
      "6117efedb574017076d5b499\n",
      "610c0032948e1026ee7eb3e1\n",
      "6577160267390ce01afc7fad\n",
      "6575c562d749c56ad88dbeda\n",
      "5e9593f997af0e19c6073957\n",
      "5c7c6a0e28933500015ec7da\n",
      "5c26ac6163e1d8000103824f\n",
      "5c559af233ed050001dffa66\n",
      "5c8d4db8c6eef00001bd2510\n",
      "554bfda7fdf99b14da73ce54\n",
      "659ada02ac94d554396360f9\n",
      "60ddcc052137212419247c3c\n",
      "5e5521580ee1b951df544c3c\n",
      "5755c957eb80c4000741a9ce\n",
      "5d6f332829c25100188a4a27\n",
      "5c0873675b32d500012e3f2c\n",
      "6085bb66296b0a411198d8fd\n",
      "655fa05b1303f59972ea6555\n"
     ]
    }
   ],
   "source": [
    "# check all the files\n",
    "checker, approve_ids = check_used_files(EXPERIMENT_NAME, EXPERIMENT_VERSION, TASK, clean_errors=True)\n",
    "\n",
    "# find the subject list based on complete files\n",
    "file_idx, modality, sub_list, prolific_ids = zip(*checker['complete'])\n",
    "sub_mod_list = list(zip(sub_list, modality))\n",
    "\n",
    "print (len(set(approve_ids)))\n",
    "print ('\\n'.join(approve_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45622ad-6ac0-48e9-aea9-9fc79fdeb81c",
   "metadata": {},
   "source": [
    "## Load and clean participants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "85401d28-b9fa-4761-b943-b2f11aceb13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/experiments/next-word-prediction/results/final-multimodal-01'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9b4c8563-8fcd-45ec-8c5d-5c0e162dfa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current Word: .... as the door opens I hear the \u001b[43;30mtv\u001b[m of television come out and on ....\n",
      "Ground Truth:  blare\n",
      "\\Suggestions:  ['TV', 't', 'v', 'ts', 'ti', 'iv', 'ta', 'av', 'tn', 'tr', 'to', 'Av']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Dict.__del__ at 0x2ade688c0af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/dark_matter/lib/python3.9/site-packages/enchant/__init__.py\", line 555, in __del__\n",
      "    try:\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[281], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m###### Check responses #####\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m df_results \u001b[38;5;241m=\u001b[39m \u001b[43mclean_participant_responses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_transcript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#### Save cleaned data #####\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m     38\u001b[0m df_results\u001b[38;5;241m.\u001b[39mto_csv(out_fn, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[275], line 33\u001b[0m, in \u001b[0;36mclean_participant_responses\u001b[0;34m(df_results, df_transcript)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# tokens = df['response'].split()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m enc_dict\u001b[38;5;241m.\u001b[39mcheck(response) \u001b[38;5;129;01mor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m checked_indices:\n\u001b[0;32m---> 33\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_correct_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_transcript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_correction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     df_responses\u001b[38;5;241m.\u001b[39miloc[df\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m     35\u001b[0m     checked_indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "Cell \u001b[0;32mIn[275], line 119\u001b[0m, in \u001b[0;36mprompt_correct_response\u001b[0;34m(df_response, df_transcript, enc_dict, range_display, prompt_correction)\u001b[0m\n\u001b[1;32m    117\u001b[0m suggestions \u001b[38;5;241m=\u001b[39m enc_dict\u001b[38;5;241m.\u001b[39msuggest(response)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSuggestions: \u001b[39m\u001b[38;5;124m\"\u001b[39m, suggestions)\n\u001b[0;32m--> 119\u001b[0m correct_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCorrect Version: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m correct_word \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-999\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    122\u001b[0m     break_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/dark_matter/lib/python3.9/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/dark_matter/lib/python3.9/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "cleaned_results_dir = os.path.join(BASE_DIR, 'experiments',  EXPERIMENT_NAME, 'cleaned-results', EXPERIMENT_VERSION)\n",
    "\n",
    "df_transcript = pd.read_csv(os.path.join(preproc_dir, TASK, f'{TASK}_transcript-preprocessed.csv'))\n",
    "\n",
    "for i, (sub, modality) in enumerate(sub_mod_list):\n",
    "\n",
    "    sub_cleaned_dir = os.path.join(cleaned_results_dir, TASK, modality, sub)\n",
    "    out_fn = os.path.join(sub_cleaned_dir, f'{sub}_next-word-prediction.csv')\n",
    "    \n",
    "    utils.attempt_makedirs(sub_cleaned_dir)\n",
    "\n",
    "    if os.path.exists(out_fn):\n",
    "        print (f'File exists: {modality} {sub}')\n",
    "        continue\n",
    "    else:\n",
    "        print (f'Correcting: {modality} {sub}')\n",
    "\n",
    "    ############################\n",
    "    #### Load subject data #####\n",
    "    ############################\n",
    "    \n",
    "    sub_dir = os.path.join(results_dir, TASK, modality, sub)\n",
    "\n",
    "    # load and filter down to response trials\n",
    "    df_results = pd.read_csv(os.path.join(sub_dir, f'{sub}_next-word-prediction.csv')).fillna(False)\n",
    "    df_results['word_index'] = df_results['word_index'].astype(int)\n",
    "\n",
    "    ############################\n",
    "    ###### Check responses #####\n",
    "    ############################\n",
    "\n",
    "    df_results = clean_participant_responses(df_results, df_transcript)\n",
    "\n",
    "    ############################\n",
    "    #### Save cleaned data #####\n",
    "    ############################\n",
    "    \n",
    "    df_results.to_csv(out_fn, index=False)\n",
    "\n",
    "    print (f'Saved file for {modality} {sub}')\n",
    "    # if os.path.exists(sub_dir):\n",
    "    #     current_id, demographics, experience, responses = load_participant_results(sub_dir, sub)\n",
    "    #     responses['response'] = responses['response'].fillna('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
