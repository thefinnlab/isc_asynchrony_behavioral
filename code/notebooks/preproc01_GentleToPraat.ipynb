{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4491ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, glob\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from praatio import textgrid as tgio\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import *\n",
    "from preproc_utils import gentle_fill_missing_words, create_word_prediction_df, clean_hyphenated_words, clean_named_entities, dataframe_to_textgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d72a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wheretheressmoke'\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769edc24",
   "metadata": {},
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c8f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "stim_dir = os.path.join(BASE_DIR, 'stimuli')\n",
    "gentle_dir = os.path.join(stim_dir, 'gentle')\n",
    "preproc_dir = os.path.join(stim_dir,'preprocessed')\n",
    "task_out_dir = os.path.join(preproc_dir, task)\n",
    "backup_dir = os.path.join(task_out_dir, 'src')\n",
    "\n",
    "audio_fn = glob.glob(os.path.join(stim_dir, 'audio', f'*{task}*.wav'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a8b08",
   "metadata": {},
   "source": [
    "### Load adjusted file\n",
    "\n",
    "Currently we only mapped the word tier from gentle to praat -- need to map the phoneme tier as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1273dd20-b7e3-457b-90f2-7f3b2cf1d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gentle_to_textgrid(alignment_fn):\n",
    "\t\"\"\"\n",
    "\tTake a filename and its associated transcription and fill in all the gaps\n",
    "\t\"\"\"\n",
    "    \n",
    "\trearranged_words = []\n",
    "\tfile_ons = 0\n",
    "\t\n",
    "\t# load the alignment file\n",
    "\twith open(alignment_fn, encoding='utf-8') as f:\n",
    "\t\tcontent = json.load(f)\n",
    "\tall_ons = content['words'][0]['start']\n",
    "\t\n",
    "\tfor ix, word in enumerate(content['words']):\n",
    "\t\t# if the word was successfully aligned\n",
    "\t\tif word['case'] == 'success' or word['case'] == 'assumed':\n",
    "\t\t\tword_ons = np.round(word['start'], 3)\n",
    "\t\t\tword_off = np.round(word['end'], 3)\n",
    "\t\t\ttarget = word['word']\n",
    "\t\t\trearranged_words.append((word_ons, word_off, target))\n",
    "\t\telse:\n",
    "\t\t\t# search forwards and backwards to find the previous and next word\n",
    "\t\t\t# use the end and start times to get word times \n",
    "\t\t\ttarget = content['words'][ix]['word']\n",
    "\t\t\tprev_end, next_start = align_missing_word(content, ix)\n",
    "\t\t\t\n",
    "\t\t\trearranged_words.append((prev_end, next_start, target))\n",
    "\t\n",
    "\t# adjust for overlap in times\n",
    "\tfor ix, word_times in enumerate(rearranged_words):\n",
    "\t\tif ix != 0:\n",
    "\t\t\tprev_start, prev_end, prev_word = rearranged_words[ix-1]\n",
    "\t\t\tcurr_start, curr_end, curr_word = word_times\n",
    "\n",
    "\t\t\t# if the current start time is before the previous end --> adjust\n",
    "\t\t\t# to be the previous end time\n",
    "\t\t\tif curr_start < prev_end:\n",
    "\t\t\t\trearranged_words[ix] = (prev_end, curr_end, curr_word)\n",
    "\t\t\t\tcurr_start, curr_end, curr_word = rearranged_words[ix]\n",
    "\n",
    "\t\t\t# if the current end time is after the current start time\n",
    "\t\t\t# set to be the next start time\n",
    "\t\t\tif curr_end < curr_start and (ix+1 != len(rearranged_words)):\n",
    "\t\t\t\tnext_start, next_end, next_word = rearranged_words[ix+1]\n",
    "\t\t\t\trearranged_words[ix] = (curr_start, next_start, curr_word)\n",
    "\t\t\t\tcurr_start, curr_end, curr_word = rearranged_words[ix]\n",
    "\n",
    "\t\t\t# final catch is adding a tiny bit of padding to the end word to adjust\n",
    "\t\t\tif curr_end == curr_start:\n",
    "\t\t\t\trearranged_words[ix] = (curr_start, curr_end+0.0001, curr_word)\n",
    "\t\n",
    "\ttg = tgio.Textgrid()\n",
    "\ttg.addTier(tgio.IntervalTier('word', rearranged_words))\n",
    "\treturn content, tg\n",
    "\n",
    "def gentle_fill_missing_words(alignment_fn):\n",
    "\t'''\n",
    "\tA simple way to fill missing aligned words\n",
    "\t'''\n",
    "\t\n",
    "\t# load the alignment file\n",
    "\twith open(alignment_fn, encoding='utf-8') as f:\n",
    "\t\tcontent = json.load(f)\n",
    "\t\t\n",
    "\tfor ix, word in enumerate(content['words']):\n",
    "\t\tif word['case'] != 'success':\n",
    "\t\t\tprev_end, next_start = align_missing_word(content, ix)\n",
    "\t\t\tcontent['words'][ix].update({'start': prev_end, 'end': next_start, 'case': 'assumed'})\n",
    "\t\t\t\n",
    "\treturn content\n",
    "\n",
    "def align_missing_word(content, ix):\n",
    "\t'''\n",
    "\tSearches from a word in both directions and then distributes time evenly\n",
    "\t'''\n",
    "\t# keep track of how many are missing\n",
    "\tforward_ix = ix\n",
    "\tforward_missing = 0\n",
    "\t\n",
    "\t# search forward\n",
    "\twhile True:\n",
    "\t\t# move one forward\n",
    "\t\tforward_ix += 1\n",
    "\t\tif content['words'][forward_ix]['case'] == 'success':\n",
    "\t\t\tnext_start = np.round(content['words'][forward_ix]['start'], 3)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tforward_missing += 1\n",
    "\t\n",
    "\t# keep track of how many are missing\n",
    "\tback_ix = ix\n",
    "\tback_missing = 0\n",
    "\t\n",
    "\twhile True:\n",
    "\t\t# move one backwards\n",
    "\t\tback_ix -= 1\n",
    "\t\t\n",
    "\t\tif content['words'][back_ix]['case'] == 'success':\n",
    "\t\t\tprev_end = np.round(content['words'][back_ix]['end'], 3)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tback_missing += 1\n",
    "\t\n",
    "\t# space evenly between the number of missing items\n",
    "\ttotal_missing = back_missing + forward_missing + 1 # add one to include current item\n",
    "\tx_vals = np.linspace(prev_end, next_start, total_missing + 2)[1:-1] # add 2 to pad the points on either side\n",
    "\t\n",
    "\t# if there is anything missing\n",
    "\t# normalize indices to 0\n",
    "\tmissing_ixs = np.arange(ix-back_missing,ix+forward_missing+1)\n",
    "\t\n",
    "\t# index of the value in the interpolated array\n",
    "\tarr_ix = np.argwhere(ix == missing_ixs)\n",
    "\t\n",
    "\t# then extract value from that array and round\n",
    "\tnext_start = x_vals[arr_ix].squeeze()\n",
    "\tnext_start = np.round(next_start, 3)\n",
    "\t\n",
    "\t# have to adjust prev end to be the interpolated value\n",
    "\tif len(missing_ixs) > 1 and arr_ix:\n",
    "\t\tprev_end = x_vals[np.argwhere(ix == missing_ixs)-1].squeeze()\n",
    "\t\tprev_end = np.round(prev_end, 3)\n",
    "\t\n",
    "\treturn prev_end, next_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab9c6ba-4b62-4059-87b2-66d20afaca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_phonemes_to_word(word_start, word_end, phonemes):\n",
    "    \"\"\"\n",
    "    Scale phoneme timings to match the word boundaries.\n",
    "    \"\"\"\n",
    "    word_duration = word_end - word_start\n",
    "    phoneme_duration = sum(p['duration'] for p in phonemes)\n",
    "    scale_factor = word_duration / phoneme_duration\n",
    "\n",
    "    scaled_phonemes = []\n",
    "    current_time = word_start\n",
    "    for phone in phonemes:\n",
    "        scaled_duration = phone['duration'] * scale_factor\n",
    "        phone_end = current_time + scaled_duration\n",
    "        scaled_phonemes.append({\n",
    "            'start': current_time,\n",
    "            'end': phone_end,\n",
    "            'phone': phone['phone']\n",
    "        })\n",
    "        current_time = phone_end\n",
    "\n",
    "    # Adjust the last phoneme to exactly match the word end time\n",
    "    if scaled_phonemes:\n",
    "        scaled_phonemes[-1]['end'] = word_end\n",
    "\n",
    "    return scaled_phonemes\n",
    "\n",
    "def gentle_to_textgrid_phoneme(alignment_fn, word_textgrid):\n",
    "    \"\"\"\n",
    "    Take a filename of a Gentle alignment JSON and a word TextGrid, and return a Praat TextGrid for the phoneme tier,\n",
    "    including CMU phoneme categories, with phonemes scaled to match word boundaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the alignment file\n",
    "    with open(align_fn, encoding='utf-8') as f:\n",
    "        content = json.load(f)\n",
    "    \n",
    "    word_tier = word_textgrid.getTier('word')\n",
    "    rearranged_phones = []\n",
    "    \n",
    "    word_index = 0\n",
    "    gentle_index = 0\n",
    "    while gentle_index < len(content['words']) and word_index < len(word_tier):\n",
    "        gentle_word = content['words'][gentle_index]\n",
    "        word_interval = word_tier.entries[word_index]\n",
    "                \n",
    "        # Check if we need to combine hyphenated words\n",
    "        if '-' in word_interval.label.lower() and gentle_word['word'] != word_interval.label.lower():\n",
    "\n",
    "            combined_word = gentle_word['word']\n",
    "            combined_phones = gentle_word['phones'] if 'phones' in gentle_word else []\n",
    "            next_gentle_index = gentle_index + 1\n",
    "            \n",
    "            while next_gentle_index < len(content['words']):\n",
    "                next_word = content['words'][next_gentle_index]\n",
    "                combined_word += next_word['word']\n",
    "                if 'phones' in next_word:\n",
    "                    combined_phones.extend(next_word['phones'])\n",
    "                \n",
    "                if combined_word.lower() == word_interval.label.lower().replace('-', ''):\n",
    "                    # We've found a match for the hyphenated word\n",
    "                    gentle_word = {\n",
    "                        'word': word_interval.label.lower(),\n",
    "                        'phones': combined_phones,\n",
    "                        'case': 'success' if all(w['case'] == 'success' for w in content['words'][gentle_index:next_gentle_index+1]) else 'partial'\n",
    "                    }\n",
    "                    gentle_index = next_gentle_index\n",
    "                    break\n",
    "                next_gentle_index += 1\n",
    "        \n",
    "        if gentle_word['case'] == 'success' and 'phones' in gentle_word and gentle_word['word'].lower() == word_interval.label.lower():\n",
    "            word_start, word_end = word_interval.start, word_interval.end\n",
    "            \n",
    "            # Scale phonemes to match the word boundaries\n",
    "            scaled_phonemes = scale_phonemes_to_word(word_start, word_end, gentle_word['phones'])\n",
    "            \n",
    "            for phone in scaled_phonemes:\n",
    "                phone_start = np.round(phone['start'], 3)\n",
    "                phone_end = np.round(phone['end'], 3)\n",
    "                phone_label = phone['phone']\n",
    "                \n",
    "                # only get the first phoneme --> this maps to CMU phoneme dictionary\n",
    "                phone_label = phone_label.split('_')[0].upper()\n",
    "                \n",
    "                rearranged_phones.append((phone_start, phone_end, phone_label))\n",
    "            \n",
    "            word_index += 1\n",
    "        else:\n",
    "            # If we can't find a match, move to the next word in both Gentle and TextGrid\n",
    "            word_index += 1\n",
    "        \n",
    "        gentle_index += 1\n",
    "    \n",
    "    # Sort phones by start time (in case they're not already in order)\n",
    "    rearranged_phones.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Fill gaps with silence\n",
    "    final_phones = []\n",
    "    for ix in range(len(rearranged_phones)):\n",
    "        curr_start, curr_end, curr_phone = rearranged_phones[ix]\n",
    "        if ix > 0:\n",
    "            prev_start, prev_end, prev_phone = final_phones[-1]\n",
    "            if curr_start > prev_end:\n",
    "                # Insert silence\n",
    "                final_phones.append((prev_end, curr_start, \"\"))\n",
    "        final_phones.append((curr_start, curr_end, curr_phone))\n",
    "    \n",
    "    # tg = tgio.Textgrid()\n",
    "    word_textgrid.addTier(tgio.IntervalTier('phone', final_phones))\n",
    "    return word_textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64538882-b841-4e9c-b042-cf43cab9f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wheretheressmoke'\n",
    "\n",
    "praat_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat.TextGrid')\n",
    "align_fn = os.path.join(gentle_dir, task, 'align.json')\n",
    "\n",
    "word_textgrid = tgio.openTextgrid(praat_fn, False)\n",
    "phone_textgrid = gentle_to_textgrid(align_fn) #, word_textgrid)\n",
    "\n",
    "# tg_phone.getTier('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "30070e23-2562-4b25-84b9-a8940d9507e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = tgio.Textgrid()\n",
    "\n",
    "for tier_name in ['phone', 'word']:\n",
    "    tier = phone_textgrid.getTier(tier_name)\n",
    "    tg.addTier(tier)\n",
    "\n",
    "praat_phone_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat_phone.TextGrid')\n",
    "tg.save(praat_phone_fn, 'long_textgrid', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe2405",
   "metadata": {},
   "source": [
    "### Convert preprocessed CSV to textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5155fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'howtodraw'\n",
    "\n",
    "# Use the preprocessed dataframe to make a textgrid\n",
    "preproc_fn = os.path.join(preproc_dir, task, f'{task}_transcript-preprocessed.csv')\n",
    "audio_fn = glob.glob(os.path.join(stim_dir, 'audio', f'*{task}*.wav'))[0]\n",
    "\n",
    "df_preproc = pd.read_csv(preproc_fn)\n",
    "tg = dataframe_to_textgrid(df_preproc, audio_fn)\n",
    "\n",
    "tg_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat.TextGrid')\n",
    "tg.save(tg_fn, 'long_textgrid', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca554b",
   "metadata": {},
   "source": [
    "### Set up file structure for AudioTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5ae591c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosody_utils as prosody\n",
    "\n",
    "window_size = 25\n",
    "\n",
    "df_preproc = pd.read_csv(os.path.join(BASE_DIR, 'stimuli/preprocessed/', task, f'{task}_transcript-preprocessed.csv'))\n",
    "# df_preproc = df_preproc.rename(columns={'Word_Written': 'word', 'Punctuation': 'punctuation'})\n",
    "\n",
    "###########################################\n",
    "#### Create a dataset for processing  #####\n",
    "###########################################\n",
    "\n",
    "# create a list of indices that we will iterate through to sample the transcript\n",
    "segments = prosody.get_segment_indices(n_words=len(df_preproc), window_size=window_size)[:-1]\n",
    "# inputs = [prosody.transcript_to_input(df_preproc, segment, add_punctuation=True) for segment in segments]\n",
    "# inputs, labels = zip(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83669867",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, df = prosody.transcript_to_input(df_preproc, segments[1], add_punctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "50573b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# Process every segment\n",
    "for i, segment in enumerate(segments):\n",
    "    # Crop dataframe to the current set of indices\n",
    "    df_segment = df_preproc.iloc[segment]\n",
    "\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "364119a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc_utils import cut_audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3974916",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# Candidate segments are one index before the candidate index (e.g., predict the upcoming word)\n",
    "candidate_idxs = np.where(df_preproc['NWP_Candidate'].to_numpy())[0]\n",
    "\n",
    "for idx in candidate_idxs[-1:]:\n",
    "\n",
    "    candidate_segment = segments[idx-1]\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72abc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential pairs\n",
    "candidate_idxs = np.where(df_preproc['NWP_Candidate'].to_numpy())[0] # First get indices\n",
    "candidate_idxs = np.concatenate([[0], candidate_idxs], axis=0) # Add the first item for the first cut\n",
    "segments = np.vstack((candidate_idxs[:-1], candidate_idxs[1:]-1)).T # Stack and make pairs\n",
    "\n",
    "# Convert to a list of lists (if needed)\n",
    "segment_indices = segments.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bd712264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all segments except the first (which can't be cut) and the last (which isn't a word in the transcript)\n",
    "segments = prosody.get_segment_indices(n_words=len(df_preproc), window_size=window_size)[1:-1]\n",
    "segment_idxs = [[min(segment), max(segment)]for segment in segments]\n",
    "\n",
    "# cut_audio_segments(df_preproc, task, audio_fn, audio_out_dir, segment_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "386df329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the audio\n",
    "audio_fns, df_segments = cut_audio_segments(df_preproc, task, audio_fn, audio_out_dir, segment_idxs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9a5352e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praatio.data_classes.textgrid.Textgrid at 0x14665af7db20>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4b009266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['Onset', 'Offset']] = df.loc[:, ['Onset', 'Offset']] - df.iloc[0]['Onset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a694a63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "df_transcript = df_preproc.rename(columns={'Word_Written': 'word', 'Punctuation': 'punctuation'})\n",
    "\n",
    "for segment, audio_fn in zip(segments, audio_fns):\n",
    "\n",
    "    # For some reason I made a stupid naming convention conversion somewhere so need to flip\n",
    "    # back and forth\n",
    "    inputs, df = prosody.transcript_to_input(df_transcript, segment, add_punctuation=True)\n",
    "    df = df.rename(columns={'word': 'Word_Written'})\n",
    "\n",
    "    # Normalize to the start of the clip (e.g., make the first onset here 0s)\n",
    "    df.loc[:, ['Onset', 'Offset']] = df.loc[:, ['Onset', 'Offset']] - df.iloc[0]['Onset']\n",
    "\n",
    "    # Make a textgrid file\n",
    "    textgrid_fn = audio_fn.replace('audio', 'textgrids').replace('.wav', '.TextGrid')\n",
    "    tg = dataframe_to_textgrid(df, audio_fn)\n",
    "\n",
    "    tg.save(textgrid_fn, 'long_textgrid', True)\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "06c088b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = dataframe_to_textgrid(df, audio_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "42a7dc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dartfs/rc/lab/F/FinnLab/datasets/nlp-datasets/pfka-moth-stories/textgrids/howtodraw_segment-00001TextGrid'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgrid_fn = audio_fn.replace('audio', 'textgrids').replace('.wav', 'TextGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a694a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_segments = [segments[idx-1] for idx in candidate_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "52a4ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [prosody.transcript_to_input(df_preproc, segment, add_punctuation=True) for segment in segments]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark_matter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
