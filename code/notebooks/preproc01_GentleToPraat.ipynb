{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4491ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, glob\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from praatio import textgrid as tgio\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import *\n",
    "from preproc_utils import gentle_fill_missing_words, create_word_prediction_df, clean_hyphenated_words, clean_named_entities, dataframe_to_textgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d72a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wheretheressmoke'\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769edc24",
   "metadata": {},
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c8f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "stim_dir = os.path.join(BASE_DIR, 'stimuli')\n",
    "gentle_dir = os.path.join(stim_dir, 'gentle')\n",
    "preproc_dir = os.path.join(stim_dir,'preprocessed')\n",
    "task_out_dir = os.path.join(preproc_dir, task)\n",
    "backup_dir = os.path.join(task_out_dir, 'src')\n",
    "\n",
    "audio_fn = glob.glob(os.path.join(stim_dir, 'audio', f'*{task}*.wav'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a8b08",
   "metadata": {},
   "source": [
    "### Load adjusted file\n",
    "\n",
    "Currently we only mapped the word tier from gentle to praat -- need to map the phoneme tier as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1273dd20-b7e3-457b-90f2-7f3b2cf1d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gentle_to_textgrid(alignment_fn):\n",
    "\t\"\"\"\n",
    "\tTake a filename and its associated transcription and fill in all the gaps\n",
    "\t\"\"\"\n",
    "    \n",
    "\trearranged_words = []\n",
    "\tfile_ons = 0\n",
    "\t\n",
    "\t# load the alignment file\n",
    "\twith open(alignment_fn, encoding='utf-8') as f:\n",
    "\t\tcontent = json.load(f)\n",
    "\tall_ons = content['words'][0]['start']\n",
    "\t\n",
    "\tfor ix, word in enumerate(content['words']):\n",
    "\t\t# if the word was successfully aligned\n",
    "\t\tif word['case'] == 'success' or word['case'] == 'assumed':\n",
    "\t\t\tword_ons = np.round(word['start'], 3)\n",
    "\t\t\tword_off = np.round(word['end'], 3)\n",
    "\t\t\ttarget = word['word']\n",
    "\t\t\trearranged_words.append((word_ons, word_off, target))\n",
    "\t\telse:\n",
    "\t\t\t# search forwards and backwards to find the previous and next word\n",
    "\t\t\t# use the end and start times to get word times \n",
    "\t\t\ttarget = content['words'][ix]['word']\n",
    "\t\t\tprev_end, next_start = align_missing_word(content, ix)\n",
    "\t\t\t\n",
    "\t\t\trearranged_words.append((prev_end, next_start, target))\n",
    "\t\n",
    "\t# adjust for overlap in times\n",
    "\tfor ix, word_times in enumerate(rearranged_words):\n",
    "\t\tif ix != 0:\n",
    "\t\t\tprev_start, prev_end, prev_word = rearranged_words[ix-1]\n",
    "\t\t\tcurr_start, curr_end, curr_word = word_times\n",
    "\n",
    "\t\t\t# if the current start time is before the previous end --> adjust\n",
    "\t\t\t# to be the previous end time\n",
    "\t\t\tif curr_start < prev_end:\n",
    "\t\t\t\trearranged_words[ix] = (prev_end, curr_end, curr_word)\n",
    "\t\t\t\tcurr_start, curr_end, curr_word = rearranged_words[ix]\n",
    "\n",
    "\t\t\t# if the current end time is after the current start time\n",
    "\t\t\t# set to be the next start time\n",
    "\t\t\tif curr_end < curr_start and (ix+1 != len(rearranged_words)):\n",
    "\t\t\t\tnext_start, next_end, next_word = rearranged_words[ix+1]\n",
    "\t\t\t\trearranged_words[ix] = (curr_start, next_start, curr_word)\n",
    "\t\t\t\tcurr_start, curr_end, curr_word = rearranged_words[ix]\n",
    "\n",
    "\t\t\t# final catch is adding a tiny bit of padding to the end word to adjust\n",
    "\t\t\tif curr_end == curr_start:\n",
    "\t\t\t\trearranged_words[ix] = (curr_start, curr_end+0.0001, curr_word)\n",
    "\t\n",
    "\ttg = tgio.Textgrid()\n",
    "\ttg.addTier(tgio.IntervalTier('word', rearranged_words))\n",
    "\treturn content, tg\n",
    "\n",
    "def gentle_fill_missing_words(alignment_fn):\n",
    "\t'''\n",
    "\tA simple way to fill missing aligned words\n",
    "\t'''\n",
    "\t\n",
    "\t# load the alignment file\n",
    "\twith open(alignment_fn, encoding='utf-8') as f:\n",
    "\t\tcontent = json.load(f)\n",
    "\t\t\n",
    "\tfor ix, word in enumerate(content['words']):\n",
    "\t\tif word['case'] != 'success':\n",
    "\t\t\tprev_end, next_start = align_missing_word(content, ix)\n",
    "\t\t\tcontent['words'][ix].update({'start': prev_end, 'end': next_start, 'case': 'assumed'})\n",
    "\t\t\t\n",
    "\treturn content\n",
    "\n",
    "def align_missing_word(content, ix):\n",
    "\t'''\n",
    "\tSearches from a word in both directions and then distributes time evenly\n",
    "\t'''\n",
    "\t# keep track of how many are missing\n",
    "\tforward_ix = ix\n",
    "\tforward_missing = 0\n",
    "\t\n",
    "\t# search forward\n",
    "\twhile True:\n",
    "\t\t# move one forward\n",
    "\t\tforward_ix += 1\n",
    "\t\tif content['words'][forward_ix]['case'] == 'success':\n",
    "\t\t\tnext_start = np.round(content['words'][forward_ix]['start'], 3)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tforward_missing += 1\n",
    "\t\n",
    "\t# keep track of how many are missing\n",
    "\tback_ix = ix\n",
    "\tback_missing = 0\n",
    "\t\n",
    "\twhile True:\n",
    "\t\t# move one backwards\n",
    "\t\tback_ix -= 1\n",
    "\t\t\n",
    "\t\tif content['words'][back_ix]['case'] == 'success':\n",
    "\t\t\tprev_end = np.round(content['words'][back_ix]['end'], 3)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tback_missing += 1\n",
    "\t\n",
    "\t# space evenly between the number of missing items\n",
    "\ttotal_missing = back_missing + forward_missing + 1 # add one to include current item\n",
    "\tx_vals = np.linspace(prev_end, next_start, total_missing + 2)[1:-1] # add 2 to pad the points on either side\n",
    "\t\n",
    "\t# if there is anything missing\n",
    "\t# normalize indices to 0\n",
    "\tmissing_ixs = np.arange(ix-back_missing,ix+forward_missing+1)\n",
    "\t\n",
    "\t# index of the value in the interpolated array\n",
    "\tarr_ix = np.argwhere(ix == missing_ixs)\n",
    "\t\n",
    "\t# then extract value from that array and round\n",
    "\tnext_start = x_vals[arr_ix].squeeze()\n",
    "\tnext_start = np.round(next_start, 3)\n",
    "\t\n",
    "\t# have to adjust prev end to be the interpolated value\n",
    "\tif len(missing_ixs) > 1 and arr_ix:\n",
    "\t\tprev_end = x_vals[np.argwhere(ix == missing_ixs)-1].squeeze()\n",
    "\t\tprev_end = np.round(prev_end, 3)\n",
    "\t\n",
    "\treturn prev_end, next_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab9c6ba-4b62-4059-87b2-66d20afaca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_phonemes_to_word(word_start, word_end, phonemes):\n",
    "    \"\"\"\n",
    "    Scale phoneme timings to match the word boundaries.\n",
    "    \"\"\"\n",
    "    word_duration = word_end - word_start\n",
    "    phoneme_duration = sum(p['duration'] for p in phonemes)\n",
    "    scale_factor = word_duration / phoneme_duration\n",
    "\n",
    "    scaled_phonemes = []\n",
    "    current_time = word_start\n",
    "    for phone in phonemes:\n",
    "        scaled_duration = phone['duration'] * scale_factor\n",
    "        phone_end = current_time + scaled_duration\n",
    "        scaled_phonemes.append({\n",
    "            'start': current_time,\n",
    "            'end': phone_end,\n",
    "            'phone': phone['phone']\n",
    "        })\n",
    "        current_time = phone_end\n",
    "\n",
    "    # Adjust the last phoneme to exactly match the word end time\n",
    "    if scaled_phonemes:\n",
    "        scaled_phonemes[-1]['end'] = word_end\n",
    "\n",
    "    return scaled_phonemes\n",
    "\n",
    "def gentle_to_textgrid_phoneme(alignment_fn, word_textgrid):\n",
    "    \"\"\"\n",
    "    Take a filename of a Gentle alignment JSON and a word TextGrid, and return a Praat TextGrid for the phoneme tier,\n",
    "    including CMU phoneme categories, with phonemes scaled to match word boundaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the alignment file\n",
    "    with open(align_fn, encoding='utf-8') as f:\n",
    "        content = json.load(f)\n",
    "    \n",
    "    word_tier = word_textgrid.getTier('word')\n",
    "    rearranged_phones = []\n",
    "    \n",
    "    word_index = 0\n",
    "    gentle_index = 0\n",
    "    while gentle_index < len(content['words']) and word_index < len(word_tier):\n",
    "        gentle_word = content['words'][gentle_index]\n",
    "        word_interval = word_tier.entries[word_index]\n",
    "                \n",
    "        # Check if we need to combine hyphenated words\n",
    "        if '-' in word_interval.label.lower() and gentle_word['word'] != word_interval.label.lower():\n",
    "\n",
    "            combined_word = gentle_word['word']\n",
    "            combined_phones = gentle_word['phones'] if 'phones' in gentle_word else []\n",
    "            next_gentle_index = gentle_index + 1\n",
    "            \n",
    "            while next_gentle_index < len(content['words']):\n",
    "                next_word = content['words'][next_gentle_index]\n",
    "                combined_word += next_word['word']\n",
    "                if 'phones' in next_word:\n",
    "                    combined_phones.extend(next_word['phones'])\n",
    "                \n",
    "                if combined_word.lower() == word_interval.label.lower().replace('-', ''):\n",
    "                    # We've found a match for the hyphenated word\n",
    "                    gentle_word = {\n",
    "                        'word': word_interval.label.lower(),\n",
    "                        'phones': combined_phones,\n",
    "                        'case': 'success' if all(w['case'] == 'success' for w in content['words'][gentle_index:next_gentle_index+1]) else 'partial'\n",
    "                    }\n",
    "                    gentle_index = next_gentle_index\n",
    "                    break\n",
    "                next_gentle_index += 1\n",
    "        \n",
    "        if gentle_word['case'] == 'success' and 'phones' in gentle_word and gentle_word['word'].lower() == word_interval.label.lower():\n",
    "            word_start, word_end = word_interval.start, word_interval.end\n",
    "            \n",
    "            # Scale phonemes to match the word boundaries\n",
    "            scaled_phonemes = scale_phonemes_to_word(word_start, word_end, gentle_word['phones'])\n",
    "            \n",
    "            for phone in scaled_phonemes:\n",
    "                phone_start = np.round(phone['start'], 3)\n",
    "                phone_end = np.round(phone['end'], 3)\n",
    "                phone_label = phone['phone']\n",
    "                \n",
    "                # only get the first phoneme --> this maps to CMU phoneme dictionary\n",
    "                phone_label = phone_label.split('_')[0].upper()\n",
    "                \n",
    "                rearranged_phones.append((phone_start, phone_end, phone_label))\n",
    "            \n",
    "            word_index += 1\n",
    "        else:\n",
    "            # If we can't find a match, move to the next word in both Gentle and TextGrid\n",
    "            word_index += 1\n",
    "        \n",
    "        gentle_index += 1\n",
    "    \n",
    "    # Sort phones by start time (in case they're not already in order)\n",
    "    rearranged_phones.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Fill gaps with silence\n",
    "    final_phones = []\n",
    "    for ix in range(len(rearranged_phones)):\n",
    "        curr_start, curr_end, curr_phone = rearranged_phones[ix]\n",
    "        if ix > 0:\n",
    "            prev_start, prev_end, prev_phone = final_phones[-1]\n",
    "            if curr_start > prev_end:\n",
    "                # Insert silence\n",
    "                final_phones.append((prev_end, curr_start, \"\"))\n",
    "        final_phones.append((curr_start, curr_end, curr_phone))\n",
    "    \n",
    "    # tg = tgio.Textgrid()\n",
    "    word_textgrid.addTier(tgio.IntervalTier('phone', final_phones))\n",
    "    return word_textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64538882-b841-4e9c-b042-cf43cab9f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wheretheressmoke'\n",
    "\n",
    "praat_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat.TextGrid')\n",
    "align_fn = os.path.join(gentle_dir, task, 'align.json')\n",
    "\n",
    "word_textgrid = tgio.openTextgrid(praat_fn, False)\n",
    "phone_textgrid = gentle_to_textgrid(align_fn) #, word_textgrid)\n",
    "\n",
    "# tg_phone.getTier('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "30070e23-2562-4b25-84b9-a8940d9507e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = tgio.Textgrid()\n",
    "\n",
    "for tier_name in ['phone', 'word']:\n",
    "    tier = phone_textgrid.getTier(tier_name)\n",
    "    tg.addTier(tier)\n",
    "\n",
    "praat_phone_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat_phone.TextGrid')\n",
    "tg.save(praat_phone_fn, 'long_textgrid', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe2405",
   "metadata": {},
   "source": [
    "### Convert preprocessed CSV to textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5155fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'howtodraw'\n",
    "\n",
    "# Use the preprocessed dataframe to make a textgrid\n",
    "preproc_fn = os.path.join(preproc_dir, task, f'{task}_transcript-preprocessed.csv')\n",
    "audio_fn = glob.glob(os.path.join(stim_dir, 'audio', f'*{task}*.wav'))[0]\n",
    "\n",
    "df_preproc = pd.read_csv(preproc_fn)\n",
    "tg = dataframe_to_textgrid(df_preproc, audio_fn)\n",
    "\n",
    "tg_fn = os.path.join(preproc_dir, task, f'{task}_transcript-praat.TextGrid')\n",
    "tg.save(tg_fn, 'long_textgrid', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca554b",
   "metadata": {},
   "source": [
    "### Set up file structure for AudioTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5ae591c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosody_utils as prosody\n",
    "\n",
    "window_size = 25\n",
    "\n",
    "df_preproc = pd.read_csv(os.path.join(BASE_DIR, 'stimuli/preprocessed/', task, f'{task}_transcript-preprocessed.csv'))\n",
    "# df_preproc = df_preproc.rename(columns={'Word_Written': 'word', 'Punctuation': 'punctuation'})\n",
    "\n",
    "###########################################\n",
    "#### Create a dataset for processing  #####\n",
    "###########################################\n",
    "\n",
    "# create a list of indices that we will iterate through to sample the transcript\n",
    "segments = prosody.get_segment_indices(n_words=len(df_preproc), window_size=window_size)[:-1]\n",
    "# inputs = [prosody.transcript_to_input(df_preproc, segment, add_punctuation=True) for segment in segments]\n",
    "# inputs, labels = zip(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83669867",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, df = prosody.transcript_to_input(df_preproc, segments[1], add_punctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "50573b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# Process every segment\n",
    "for i, segment in enumerate(segments):\n",
    "    # Crop dataframe to the current set of indices\n",
    "    df_segment = df_preproc.iloc[segment]\n",
    "\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "364119a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc_utils import cut_audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3974916",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# Candidate segments are one index before the candidate index (e.g., predict the upcoming word)\n",
    "candidate_idxs = np.where(df_preproc['NWP_Candidate'].to_numpy())[0]\n",
    "\n",
    "for idx in candidate_idxs[-1:]:\n",
    "\n",
    "    candidate_segment = segments[idx-1]\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "eda81e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def cut_audio_segments(df_preproc, task, audio_fn, audio_out_dir, segment_indices):\n",
    "    \"\"\"\n",
    "    Cut audio segments based on a nested list of indices.\n",
    "\n",
    "    :param df_preproc: DataFrame containing preprocessed data.\n",
    "    :param task: Task identifier (used in naming output files).\n",
    "    :param audio_fn: Path to the input audio file.\n",
    "    :param audio_out_dir: Directory to save the output audio segments.\n",
    "    :param segment_indices: Nested list of indices where each sublist contains [start_idx, end_idx].\n",
    "    :return: List of output filenames and a DataFrame with segment information.\n",
    "    \"\"\"\n",
    "    # Load the stimulus and find the length in time\n",
    "    stim_length = librosa.get_duration(path=audio_fn)\n",
    "\n",
    "    # Initialize DataFrame to store segment information\n",
    "    df_segments = pd.DataFrame(columns=['filename', 'word_index', 'critical_word', 'checked', 'adjusted'])\n",
    "    out_fns = []\n",
    "\n",
    "    for i, (start_idx, end_idx) in enumerate(segment_indices):\n",
    "        # Calculate onset and duration based on the segment indices\n",
    "        onset, _, duration = get_cut_times(df_preproc, start_idx, end_idx)\n",
    "\n",
    "        # Ensure the duration does not exceed the remaining audio length\n",
    "        if onset + duration > stim_length:\n",
    "            duration = stim_length - onset\n",
    "\n",
    "        # Generate output filename\n",
    "        out_fn = os.path.join(audio_out_dir, f'{task}_segment-{str(i+1).zfill(5)}.wav')\n",
    "        out_fns.append(out_fn)\n",
    "\n",
    "        # Use ffmpeg to cut the audio segment\n",
    "        cmd = f'ffmpeg -hide_banner -loglevel error -y -ss {onset} -t {duration} -i {audio_fn} {out_fn}'\n",
    "        subprocess.run(cmd, shell=True)\n",
    "\n",
    "        # Store segment information in the DataFrame\n",
    "        df_segments.loc[len(df_segments)] = {\n",
    "            'filename': out_fn,\n",
    "            'word_index': end_idx,\n",
    "            'critical_word': df_preproc.loc[end_idx]['Word_Written'] if end_idx < len(df_preproc) else None,\n",
    "            'checked': 0,\n",
    "            'adjusted': 0\n",
    "        }\n",
    "\n",
    "    return out_fns, df_segments\n",
    "\n",
    "def get_cut_times(df_preproc, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Calculate the onset, offset, and duration for a segment.\n",
    "\n",
    "    :param df_preproc: DataFrame containing preprocessed data.\n",
    "    :param start_idx: Start index of the segment.\n",
    "    :param end_idx: End index of the segment.\n",
    "    :return: Onset, offset, and duration of the segment.\n",
    "    \"\"\"\n",
    "    onset = df_preproc.loc[start_idx]['Onset']\n",
    "    offset = df_preproc.loc[end_idx]['Offset']\n",
    "    duration = offset - onset\n",
    "    return onset, offset, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72abc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential pairs\n",
    "candidate_idxs = np.where(df_preproc['NWP_Candidate'].to_numpy())[0]\n",
    "\n",
    "candidate_idxs = np.concatenate([[0], candidate_idxs], axis=0)\n",
    "segments = np.vstack((candidate_idxs[:-1], candidate_idxs[1:]-1)).T\n",
    "\n",
    "# Convert to a list of lists (if needed)\n",
    "segment_indices = segments.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dbb293c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/dartfs/rc/lab/F/FinnLab/datasets/nlp-datasets/pfka-moth-stories/audio/howtodraw_segment-00001.wav',\n",
       "  '/dartfs/rc/lab/F/FinnLab/datasets/nlp-datasets/pfka-moth-stories/audio/howtodraw_segment-00002.wav'],\n",
       "                                             filename word_index critical_word  \\\n",
       " 0  /dartfs/rc/lab/F/FinnLab/datasets/nlp-datasets...          1             I   \n",
       " 1  /dartfs/rc/lab/F/FinnLab/datasets/nlp-datasets...          9             a   \n",
       " \n",
       "   checked adjusted  \n",
       " 0       0        0  \n",
       " 1       0        0  )"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "cut_audio_segments(df_preproc, task, audio_fn, audio_out_dir, segment_indices[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "16031294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 10],\n",
       " [10, 11],\n",
       " [11, 14],\n",
       " [14, 17],\n",
       " [17, 18],\n",
       " [18, 21],\n",
       " [21, 24],\n",
       " [24, 25],\n",
       " [25, 31],\n",
       " [31, 33],\n",
       " [33, 34],\n",
       " [34, 40],\n",
       " [40, 41],\n",
       " [41, 45],\n",
       " [45, 46],\n",
       " [46, 48],\n",
       " [48, 49],\n",
       " [49, 53],\n",
       " [53, 56],\n",
       " [56, 60],\n",
       " [60, 62],\n",
       " [62, 63],\n",
       " [63, 65],\n",
       " [65, 67],\n",
       " [67, 68],\n",
       " [68, 75],\n",
       " [75, 76],\n",
       " [76, 79],\n",
       " [79, 81],\n",
       " [81, 83],\n",
       " [83, 84],\n",
       " [84, 86],\n",
       " [86, 89],\n",
       " [89, 91],\n",
       " [91, 93],\n",
       " [93, 94],\n",
       " [94, 98],\n",
       " [98, 100],\n",
       " [100, 102],\n",
       " [102, 104],\n",
       " [104, 106],\n",
       " [106, 110],\n",
       " [110, 112],\n",
       " [112, 114],\n",
       " [114, 115],\n",
       " [115, 118],\n",
       " [118, 122],\n",
       " [122, 126],\n",
       " [126, 128],\n",
       " [128, 130],\n",
       " [130, 135],\n",
       " [135, 138],\n",
       " [138, 142],\n",
       " [142, 145],\n",
       " [145, 148],\n",
       " [148, 150],\n",
       " [150, 152],\n",
       " [152, 157],\n",
       " [157, 158],\n",
       " [158, 160],\n",
       " [160, 161],\n",
       " [161, 167],\n",
       " [167, 168],\n",
       " [168, 170],\n",
       " [170, 173],\n",
       " [173, 179],\n",
       " [179, 181],\n",
       " [181, 183],\n",
       " [183, 185],\n",
       " [185, 188],\n",
       " [188, 190],\n",
       " [190, 192],\n",
       " [192, 193],\n",
       " [193, 194],\n",
       " [194, 195],\n",
       " [195, 196],\n",
       " [196, 197],\n",
       " [197, 198],\n",
       " [198, 199],\n",
       " [199, 202],\n",
       " [202, 204],\n",
       " [204, 208],\n",
       " [208, 210],\n",
       " [210, 211],\n",
       " [211, 214],\n",
       " [214, 215],\n",
       " [215, 218],\n",
       " [218, 219],\n",
       " [219, 220],\n",
       " [220, 222],\n",
       " [222, 225],\n",
       " [225, 227],\n",
       " [227, 231],\n",
       " [231, 235],\n",
       " [235, 238],\n",
       " [238, 242],\n",
       " [242, 244],\n",
       " [244, 245],\n",
       " [245, 249],\n",
       " [249, 256],\n",
       " [256, 257],\n",
       " [257, 258],\n",
       " [258, 261],\n",
       " [261, 263],\n",
       " [263, 277],\n",
       " [277, 281],\n",
       " [281, 282],\n",
       " [282, 285],\n",
       " [285, 288],\n",
       " [288, 291],\n",
       " [291, 299],\n",
       " [299, 302],\n",
       " [302, 304],\n",
       " [304, 307],\n",
       " [307, 310],\n",
       " [310, 312],\n",
       " [312, 314],\n",
       " [314, 319],\n",
       " [319, 320],\n",
       " [320, 321],\n",
       " [321, 324],\n",
       " [324, 327],\n",
       " [327, 329],\n",
       " [329, 333],\n",
       " [333, 334],\n",
       " [334, 336],\n",
       " [336, 337],\n",
       " [337, 341],\n",
       " [341, 343],\n",
       " [343, 344],\n",
       " [344, 346],\n",
       " [346, 349],\n",
       " [349, 350],\n",
       " [350, 354],\n",
       " [354, 355],\n",
       " [355, 358],\n",
       " [358, 359],\n",
       " [359, 362],\n",
       " [362, 365],\n",
       " [365, 367],\n",
       " [367, 371],\n",
       " [371, 375],\n",
       " [375, 376],\n",
       " [376, 378],\n",
       " [378, 379],\n",
       " [379, 384],\n",
       " [384, 385],\n",
       " [385, 387],\n",
       " [387, 388],\n",
       " [388, 391],\n",
       " [391, 393],\n",
       " [393, 394],\n",
       " [394, 399],\n",
       " [399, 404],\n",
       " [404, 405],\n",
       " [405, 408],\n",
       " [408, 409],\n",
       " [409, 413],\n",
       " [413, 417],\n",
       " [417, 419],\n",
       " [419, 421],\n",
       " [421, 423],\n",
       " [423, 425],\n",
       " [425, 427],\n",
       " [427, 430],\n",
       " [430, 431],\n",
       " [431, 434],\n",
       " [434, 436],\n",
       " [436, 438],\n",
       " [438, 443],\n",
       " [443, 445],\n",
       " [445, 447],\n",
       " [447, 452],\n",
       " [452, 455],\n",
       " [455, 456],\n",
       " [456, 461],\n",
       " [461, 462],\n",
       " [462, 463],\n",
       " [463, 466],\n",
       " [466, 471],\n",
       " [471, 478],\n",
       " [478, 480],\n",
       " [480, 485],\n",
       " [485, 487],\n",
       " [487, 490],\n",
       " [490, 494],\n",
       " [494, 495],\n",
       " [495, 498],\n",
       " [498, 499],\n",
       " [499, 501],\n",
       " [501, 503],\n",
       " [503, 506],\n",
       " [506, 509],\n",
       " [509, 510],\n",
       " [510, 513],\n",
       " [513, 515],\n",
       " [515, 516],\n",
       " [516, 518],\n",
       " [518, 519],\n",
       " [519, 520],\n",
       " [520, 523],\n",
       " [523, 527],\n",
       " [527, 528],\n",
       " [528, 530],\n",
       " [530, 533],\n",
       " [533, 534],\n",
       " [534, 535],\n",
       " [535, 536],\n",
       " [536, 538],\n",
       " [538, 540],\n",
       " [540, 541],\n",
       " [541, 543],\n",
       " [543, 544],\n",
       " [544, 546],\n",
       " [546, 547],\n",
       " [547, 548],\n",
       " [548, 551],\n",
       " [551, 553],\n",
       " [553, 555],\n",
       " [555, 558],\n",
       " [558, 561],\n",
       " [561, 564],\n",
       " [564, 568],\n",
       " [568, 571],\n",
       " [571, 573],\n",
       " [573, 577],\n",
       " [577, 580],\n",
       " [580, 584],\n",
       " [584, 587],\n",
       " [587, 588],\n",
       " [588, 590],\n",
       " [590, 593],\n",
       " [593, 598],\n",
       " [598, 600],\n",
       " [600, 601],\n",
       " [601, 604],\n",
       " [604, 606],\n",
       " [606, 609],\n",
       " [609, 610],\n",
       " [610, 613],\n",
       " [613, 620],\n",
       " [620, 622],\n",
       " [622, 624],\n",
       " [624, 626],\n",
       " [626, 627],\n",
       " [627, 628],\n",
       " [628, 633],\n",
       " [633, 635],\n",
       " [635, 639],\n",
       " [639, 640],\n",
       " [640, 643],\n",
       " [643, 645],\n",
       " [645, 646],\n",
       " [646, 648],\n",
       " [648, 650],\n",
       " [650, 652],\n",
       " [652, 655],\n",
       " [655, 656],\n",
       " [656, 660],\n",
       " [660, 664],\n",
       " [664, 668],\n",
       " [668, 669],\n",
       " [669, 671],\n",
       " [671, 674],\n",
       " [674, 676],\n",
       " [676, 678],\n",
       " [678, 682],\n",
       " [682, 684],\n",
       " [684, 688],\n",
       " [688, 692],\n",
       " [692, 693],\n",
       " [693, 697],\n",
       " [697, 699],\n",
       " [699, 700],\n",
       " [700, 702],\n",
       " [702, 707],\n",
       " [707, 709],\n",
       " [709, 713],\n",
       " [713, 715],\n",
       " [715, 718],\n",
       " [718, 719],\n",
       " [719, 720],\n",
       " [720, 727],\n",
       " [727, 728],\n",
       " [728, 731],\n",
       " [731, 734],\n",
       " [734, 737],\n",
       " [737, 739],\n",
       " [739, 742],\n",
       " [742, 744],\n",
       " [744, 745],\n",
       " [745, 747],\n",
       " [747, 750],\n",
       " [750, 751],\n",
       " [751, 753],\n",
       " [753, 755],\n",
       " [755, 760],\n",
       " [760, 761],\n",
       " [761, 764],\n",
       " [764, 766],\n",
       " [766, 767],\n",
       " [767, 768],\n",
       " [768, 770],\n",
       " [770, 771],\n",
       " [771, 772],\n",
       " [772, 774],\n",
       " [774, 775],\n",
       " [775, 776],\n",
       " [776, 779],\n",
       " [779, 785],\n",
       " [785, 789],\n",
       " [789, 794],\n",
       " [794, 799],\n",
       " [799, 801],\n",
       " [801, 802],\n",
       " [802, 803],\n",
       " [803, 805],\n",
       " [805, 807],\n",
       " [807, 812],\n",
       " [812, 816],\n",
       " [816, 817],\n",
       " [817, 820],\n",
       " [820, 823],\n",
       " [823, 826],\n",
       " [826, 831],\n",
       " [831, 832],\n",
       " [832, 835],\n",
       " [835, 838],\n",
       " [838, 839],\n",
       " [839, 841],\n",
       " [841, 842],\n",
       " [842, 843],\n",
       " [843, 844],\n",
       " [844, 845],\n",
       " [845, 846],\n",
       " [846, 850],\n",
       " [850, 852],\n",
       " [852, 854],\n",
       " [854, 855],\n",
       " [855, 856],\n",
       " [856, 858],\n",
       " [858, 859],\n",
       " [859, 860],\n",
       " [860, 862],\n",
       " [862, 865],\n",
       " [865, 866],\n",
       " [866, 870],\n",
       " [870, 872],\n",
       " [872, 874],\n",
       " [874, 875],\n",
       " [875, 877],\n",
       " [877, 880],\n",
       " [880, 882],\n",
       " [882, 885],\n",
       " [885, 888],\n",
       " [888, 894],\n",
       " [894, 898],\n",
       " [898, 899],\n",
       " [899, 900],\n",
       " [900, 901],\n",
       " [901, 903],\n",
       " [903, 904],\n",
       " [904, 905],\n",
       " [905, 906],\n",
       " [906, 910],\n",
       " [910, 911],\n",
       " [911, 912],\n",
       " [912, 916],\n",
       " [916, 920],\n",
       " [920, 921],\n",
       " [921, 923],\n",
       " [923, 925],\n",
       " [925, 926],\n",
       " [926, 931],\n",
       " [931, 937],\n",
       " [937, 940],\n",
       " [940, 943],\n",
       " [943, 944],\n",
       " [944, 949],\n",
       " [949, 953],\n",
       " [953, 959],\n",
       " [959, 963],\n",
       " [963, 965],\n",
       " [965, 967],\n",
       " [967, 968],\n",
       " [968, 972],\n",
       " [972, 977],\n",
       " [977, 979],\n",
       " [979, 982],\n",
       " [982, 984],\n",
       " [984, 986],\n",
       " [986, 987],\n",
       " [987, 990],\n",
       " [990, 991],\n",
       " [991, 993],\n",
       " [993, 997],\n",
       " [997, 1000],\n",
       " [1000, 1003],\n",
       " [1003, 1004],\n",
       " [1004, 1008],\n",
       " [1008, 1011],\n",
       " [1011, 1012],\n",
       " [1012, 1017],\n",
       " [1017, 1019],\n",
       " [1019, 1020],\n",
       " [1020, 1025],\n",
       " [1025, 1027],\n",
       " [1027, 1028],\n",
       " [1028, 1031],\n",
       " [1031, 1036],\n",
       " [1036, 1038],\n",
       " [1038, 1040],\n",
       " [1040, 1041],\n",
       " [1041, 1043],\n",
       " [1043, 1045],\n",
       " [1045, 1046],\n",
       " [1046, 1048],\n",
       " [1048, 1051],\n",
       " [1051, 1052],\n",
       " [1052, 1053],\n",
       " [1053, 1056],\n",
       " [1056, 1059],\n",
       " [1059, 1062],\n",
       " [1062, 1065],\n",
       " [1065, 1066],\n",
       " [1066, 1068],\n",
       " [1068, 1070],\n",
       " [1070, 1072],\n",
       " [1072, 1076],\n",
       " [1076, 1077],\n",
       " [1077, 1082],\n",
       " [1082, 1083],\n",
       " [1083, 1087],\n",
       " [1087, 1088],\n",
       " [1088, 1090],\n",
       " [1090, 1091],\n",
       " [1091, 1094],\n",
       " [1094, 1098],\n",
       " [1098, 1100],\n",
       " [1100, 1101],\n",
       " [1101, 1104],\n",
       " [1104, 1106],\n",
       " [1106, 1107],\n",
       " [1107, 1110],\n",
       " [1110, 1111],\n",
       " [1111, 1112],\n",
       " [1112, 1116],\n",
       " [1116, 1117],\n",
       " [1117, 1118],\n",
       " [1118, 1120],\n",
       " [1120, 1122],\n",
       " [1122, 1124],\n",
       " [1124, 1126],\n",
       " [1126, 1127],\n",
       " [1127, 1130],\n",
       " [1130, 1131],\n",
       " [1131, 1132],\n",
       " [1132, 1135],\n",
       " [1135, 1136],\n",
       " [1136, 1139],\n",
       " [1139, 1140],\n",
       " [1140, 1144],\n",
       " [1144, 1148],\n",
       " [1148, 1149],\n",
       " [1149, 1150],\n",
       " [1150, 1154],\n",
       " [1154, 1156],\n",
       " [1156, 1157],\n",
       " [1157, 1158],\n",
       " [1158, 1160],\n",
       " [1160, 1161],\n",
       " [1161, 1168],\n",
       " [1168, 1169],\n",
       " [1169, 1176],\n",
       " [1176, 1177],\n",
       " [1177, 1180],\n",
       " [1180, 1184],\n",
       " [1184, 1185],\n",
       " [1185, 1188],\n",
       " [1188, 1189],\n",
       " [1189, 1190],\n",
       " [1190, 1192],\n",
       " [1192, 1195],\n",
       " [1195, 1196],\n",
       " [1196, 1197],\n",
       " [1197, 1201],\n",
       " [1201, 1203],\n",
       " [1203, 1207],\n",
       " [1207, 1208],\n",
       " [1208, 1212],\n",
       " [1212, 1218],\n",
       " [1218, 1220],\n",
       " [1220, 1227],\n",
       " [1227, 1229],\n",
       " [1229, 1230],\n",
       " [1230, 1235],\n",
       " [1235, 1238],\n",
       " [1238, 1241],\n",
       " [1241, 1243],\n",
       " [1243, 1244],\n",
       " [1244, 1247],\n",
       " [1247, 1248],\n",
       " [1248, 1256],\n",
       " [1256, 1257],\n",
       " [1257, 1259],\n",
       " [1259, 1260],\n",
       " [1260, 1263],\n",
       " [1263, 1264],\n",
       " [1264, 1267],\n",
       " [1267, 1268],\n",
       " [1268, 1272],\n",
       " [1272, 1276],\n",
       " [1276, 1278],\n",
       " [1278, 1284],\n",
       " [1284, 1285],\n",
       " [1285, 1290],\n",
       " [1290, 1295],\n",
       " [1295, 1296],\n",
       " [1296, 1299],\n",
       " [1299, 1300],\n",
       " [1300, 1303],\n",
       " [1303, 1309],\n",
       " [1309, 1310],\n",
       " [1310, 1313],\n",
       " [1313, 1314],\n",
       " [1314, 1315],\n",
       " [1315, 1318],\n",
       " [1318, 1322],\n",
       " [1322, 1323],\n",
       " [1323, 1326],\n",
       " [1326, 1329],\n",
       " [1329, 1330],\n",
       " [1330, 1333],\n",
       " [1333, 1334],\n",
       " [1334, 1336],\n",
       " [1336, 1340],\n",
       " [1340, 1342],\n",
       " [1342, 1347],\n",
       " [1347, 1348],\n",
       " [1348, 1349],\n",
       " [1349, 1352],\n",
       " [1352, 1359],\n",
       " [1359, 1361],\n",
       " [1361, 1363],\n",
       " [1363, 1366],\n",
       " [1366, 1370],\n",
       " [1370, 1371],\n",
       " [1371, 1376],\n",
       " [1376, 1380],\n",
       " [1380, 1381],\n",
       " [1381, 1382],\n",
       " [1382, 1384],\n",
       " [1384, 1388],\n",
       " [1388, 1390],\n",
       " [1390, 1393],\n",
       " [1393, 1394],\n",
       " [1394, 1399],\n",
       " [1399, 1403],\n",
       " [1403, 1405],\n",
       " [1405, 1411],\n",
       " [1411, 1416],\n",
       " [1416, 1418],\n",
       " [1418, 1421],\n",
       " [1421, 1422],\n",
       " [1422, 1424],\n",
       " [1424, 1428],\n",
       " [1428, 1430],\n",
       " [1430, 1431],\n",
       " [1431, 1434],\n",
       " [1434, 1435],\n",
       " [1435, 1438],\n",
       " [1438, 1439],\n",
       " [1439, 1443],\n",
       " [1443, 1445],\n",
       " [1445, 1449],\n",
       " [1449, 1450],\n",
       " [1450, 1453],\n",
       " [1453, 1457],\n",
       " [1457, 1459],\n",
       " [1459, 1462],\n",
       " [1462, 1465],\n",
       " [1465, 1466],\n",
       " [1466, 1469],\n",
       " [1469, 1473],\n",
       " [1473, 1474],\n",
       " [1474, 1478],\n",
       " [1478, 1481],\n",
       " [1481, 1483],\n",
       " [1483, 1484],\n",
       " [1484, 1487],\n",
       " [1487, 1492],\n",
       " [1492, 1497],\n",
       " [1497, 1498],\n",
       " [1498, 1501],\n",
       " [1501, 1502],\n",
       " [1502, 1504],\n",
       " [1504, 1506],\n",
       " [1506, 1509],\n",
       " [1509, 1513],\n",
       " [1513, 1515],\n",
       " [1515, 1516],\n",
       " [1516, 1517],\n",
       " [1517, 1518],\n",
       " [1518, 1520],\n",
       " [1520, 1522],\n",
       " [1522, 1526],\n",
       " [1526, 1528],\n",
       " [1528, 1530],\n",
       " [1530, 1535],\n",
       " [1535, 1536],\n",
       " [1536, 1537],\n",
       " [1537, 1539],\n",
       " [1539, 1540],\n",
       " [1540, 1543],\n",
       " [1543, 1544],\n",
       " [1544, 1547],\n",
       " [1547, 1548],\n",
       " [1548, 1549],\n",
       " [1549, 1551],\n",
       " [1551, 1552],\n",
       " [1552, 1555],\n",
       " [1555, 1561],\n",
       " [1561, 1564],\n",
       " [1564, 1565],\n",
       " [1565, 1568],\n",
       " [1568, 1569],\n",
       " [1569, 1571],\n",
       " [1571, 1572],\n",
       " [1572, 1573],\n",
       " [1573, 1577],\n",
       " [1577, 1580],\n",
       " [1580, 1581],\n",
       " [1581, 1585],\n",
       " [1585, 1588],\n",
       " [1588, 1590],\n",
       " [1590, 1594],\n",
       " [1594, 1598],\n",
       " [1598, 1599],\n",
       " [1599, 1601],\n",
       " [1601, 1602],\n",
       " [1602, 1603],\n",
       " [1603, 1605],\n",
       " [1605, 1606],\n",
       " [1606, 1608],\n",
       " [1608, 1610],\n",
       " [1610, 1614],\n",
       " [1614, 1615],\n",
       " [1615, 1618],\n",
       " [1618, 1621],\n",
       " [1621, 1622],\n",
       " [1622, 1627],\n",
       " [1627, 1630],\n",
       " [1630, 1633],\n",
       " [1633, 1634],\n",
       " [1634, 1636],\n",
       " [1636, 1640],\n",
       " [1640, 1642],\n",
       " [1642, 1643],\n",
       " [1643, 1645],\n",
       " [1645, 1649],\n",
       " [1649, 1650],\n",
       " [1650, 1651],\n",
       " [1651, 1654],\n",
       " [1654, 1655],\n",
       " [1655, 1659],\n",
       " [1659, 1660],\n",
       " [1660, 1661],\n",
       " [1661, 1663],\n",
       " [1663, 1667],\n",
       " [1667, 1668],\n",
       " [1668, 1670],\n",
       " [1670, 1673],\n",
       " [1673, 1677],\n",
       " [1677, 1681],\n",
       " [1681, 1682],\n",
       " [1682, 1684],\n",
       " [1684, 1688],\n",
       " [1688, 1690],\n",
       " [1690, 1693],\n",
       " [1693, 1694],\n",
       " [1694, 1695],\n",
       " [1695, 1698],\n",
       " [1698, 1700],\n",
       " [1700, 1701],\n",
       " [1701, 1704],\n",
       " [1704, 1707],\n",
       " [1707, 1710],\n",
       " [1710, 1713],\n",
       " [1713, 1715],\n",
       " [1715, 1718],\n",
       " [1718, 1721],\n",
       " [1721, 1722],\n",
       " [1722, 1724],\n",
       " [1724, 1725],\n",
       " [1725, 1730],\n",
       " [1730, 1732],\n",
       " [1732, 1735],\n",
       " [1735, 1737],\n",
       " [1737, 1740],\n",
       " [1740, 1741],\n",
       " [1741, 1744],\n",
       " [1744, 1747],\n",
       " [1747, 1750],\n",
       " [1750, 1752],\n",
       " [1752, 1753],\n",
       " [1753, 1755],\n",
       " [1755, 1757],\n",
       " [1757, 1758],\n",
       " [1758, 1760],\n",
       " [1760, 1765],\n",
       " [1765, 1768],\n",
       " [1768, 1770],\n",
       " [1770, 1772],\n",
       " [1772, 1775],\n",
       " [1775, 1777],\n",
       " [1777, 1778],\n",
       " [1778, 1781],\n",
       " [1781, 1786],\n",
       " [1786, 1791],\n",
       " [1791, 1793],\n",
       " [1793, 1794],\n",
       " [1794, 1796],\n",
       " [1796, 1800],\n",
       " [1800, 1801],\n",
       " [1801, 1803],\n",
       " [1803, 1804],\n",
       " [1804, 1806],\n",
       " [1806, 1807],\n",
       " [1807, 1809],\n",
       " [1809, 1810],\n",
       " [1810, 1812],\n",
       " [1812, 1820],\n",
       " [1820, 1822],\n",
       " [1822, 1823],\n",
       " [1823, 1825],\n",
       " [1825, 1826],\n",
       " [1826, 1827],\n",
       " [1827, 1830],\n",
       " [1830, 1831],\n",
       " [1831, 1834],\n",
       " [1834, 1840],\n",
       " [1840, 1841],\n",
       " [1841, 1844],\n",
       " [1844, 1845],\n",
       " [1845, 1849],\n",
       " [1849, 1850],\n",
       " [1850, 1853],\n",
       " [1853, 1858],\n",
       " [1858, 1859],\n",
       " [1859, 1864],\n",
       " [1864, 1868],\n",
       " [1868, 1871],\n",
       " [1871, 1874],\n",
       " [1874, 1875],\n",
       " [1875, 1878],\n",
       " [1878, 1881],\n",
       " [1881, 1883],\n",
       " [1883, 1885],\n",
       " [1885, 1888],\n",
       " [1888, 1889],\n",
       " [1889, 1891],\n",
       " [1891, 1892],\n",
       " [1892, 1896],\n",
       " [1896, 1897],\n",
       " [1897, 1901],\n",
       " [1901, 1903],\n",
       " [1903, 1904],\n",
       " [1904, 1907],\n",
       " [1907, 1910],\n",
       " [1910, 1913],\n",
       " [1913, 1915],\n",
       " [1915, 1916],\n",
       " [1916, 1919],\n",
       " [1919, 1920],\n",
       " [1920, 1923],\n",
       " [1923, 1926],\n",
       " [1926, 1932],\n",
       " [1932, 1935],\n",
       " [1935, 1938],\n",
       " [1938, 1941],\n",
       " [1941, 1943],\n",
       " [1943, 1944],\n",
       " [1944, 1946],\n",
       " [1946, 1947],\n",
       " [1947, 1949],\n",
       " [1949, 1951]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "38643983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Case</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS_Definition</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>Stop_Word</th>\n",
       "      <th>Digit</th>\n",
       "      <th>Word_Vocab</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Named_Entity</th>\n",
       "      <th>NWP_Candidate</th>\n",
       "      <th>Lg10WF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>one</td>\n",
       "      <td>success</td>\n",
       "      <td>CD</td>\n",
       "      <td>numeral, cardinal</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>one</td>\n",
       "      <td>711.025414</td>\n",
       "      <td>711.226077</td>\n",
       "      <td>0.200663</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.195027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>to</td>\n",
       "      <td>success</td>\n",
       "      <td>TO</td>\n",
       "      <td>\"to\" as preposition or infinitive marker</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>711.226077</td>\n",
       "      <td>711.285941</td>\n",
       "      <td>0.059864</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.063172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>my</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>pronoun, possessive</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>my</td>\n",
       "      <td>711.285941</td>\n",
       "      <td>711.505442</td>\n",
       "      <td>0.219501</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.537693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>Jeep</td>\n",
       "      <td>success</td>\n",
       "      <td>NNP</td>\n",
       "      <td>noun, proper, singular</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>711.505442</td>\n",
       "      <td>711.924490</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.720159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>that's</td>\n",
       "      <td>success</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, common, singular or mass</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>that's</td>\n",
       "      <td>711.924490</td>\n",
       "      <td>712.094104</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>been</td>\n",
       "      <td>success</td>\n",
       "      <td>VBN</td>\n",
       "      <td>verb, past participle</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>been</td>\n",
       "      <td>712.094104</td>\n",
       "      <td>712.268932</td>\n",
       "      <td>0.174828</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.947306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>stolen</td>\n",
       "      <td>success</td>\n",
       "      <td>VBN</td>\n",
       "      <td>verb, past participle</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>stolen</td>\n",
       "      <td>712.268932</td>\n",
       "      <td>712.992063</td>\n",
       "      <td>0.723131</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3.243286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>God</td>\n",
       "      <td>success</td>\n",
       "      <td>NNP</td>\n",
       "      <td>noun, proper, singular</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>God</td>\n",
       "      <td>714.378912</td>\n",
       "      <td>714.817914</td>\n",
       "      <td>0.439002</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.663343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>is</td>\n",
       "      <td>success</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>verb, present tense, 3rd person singular</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is</td>\n",
       "      <td>714.817914</td>\n",
       "      <td>715.037415</td>\n",
       "      <td>0.219501</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.662440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>banging</td>\n",
       "      <td>success</td>\n",
       "      <td>VBG</td>\n",
       "      <td>verb, present participle or gerund</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>banging</td>\n",
       "      <td>715.037415</td>\n",
       "      <td>715.446485</td>\n",
       "      <td>0.409070</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.640481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>on</td>\n",
       "      <td>success</td>\n",
       "      <td>IN</td>\n",
       "      <td>preposition or conjunction, subordinating</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>on</td>\n",
       "      <td>715.446485</td>\n",
       "      <td>715.656009</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.549914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>my</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>pronoun, possessive</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>my</td>\n",
       "      <td>715.656009</td>\n",
       "      <td>715.845578</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.537693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>hood</td>\n",
       "      <td>success</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, common, singular or mass</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>hood</td>\n",
       "      <td>715.845578</td>\n",
       "      <td>716.314512</td>\n",
       "      <td>0.468934</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.895423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>So</td>\n",
       "      <td>success</td>\n",
       "      <td>RB</td>\n",
       "      <td>adverb</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>So</td>\n",
       "      <td>718.399773</td>\n",
       "      <td>718.579365</td>\n",
       "      <td>0.179592</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.335364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>I</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun, personal</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>718.579365</td>\n",
       "      <td>718.719048</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.309317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>toss</td>\n",
       "      <td>success</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb, present tense, not 3rd person singular</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>toss</td>\n",
       "      <td>718.719048</td>\n",
       "      <td>719.128118</td>\n",
       "      <td>0.409070</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.801404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>the</td>\n",
       "      <td>success</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td>719.128118</td>\n",
       "      <td>719.227891</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.176644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>keys</td>\n",
       "      <td>success</td>\n",
       "      <td>NNS</td>\n",
       "      <td>noun, common, plural</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>keys</td>\n",
       "      <td>719.227891</td>\n",
       "      <td>719.896372</td>\n",
       "      <td>0.668481</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3.415307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>head</td>\n",
       "      <td>success</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb, present tense, not 3rd person singular</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>head</td>\n",
       "      <td>720.255556</td>\n",
       "      <td>720.495011</td>\n",
       "      <td>0.239456</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.277563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>to</td>\n",
       "      <td>success</td>\n",
       "      <td>TO</td>\n",
       "      <td>\"to\" as preposition or infinitive marker</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>720.495011</td>\n",
       "      <td>720.584103</td>\n",
       "      <td>0.089092</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.063172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>art</td>\n",
       "      <td>success</td>\n",
       "      <td>VB</td>\n",
       "      <td>verb, base form</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>art</td>\n",
       "      <td>720.584103</td>\n",
       "      <td>720.844218</td>\n",
       "      <td>0.260114</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3.557748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>school</td>\n",
       "      <td>success</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, common, singular or mass</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>school</td>\n",
       "      <td>720.844218</td>\n",
       "      <td>721.672336</td>\n",
       "      <td>0.828118</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.230193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>and</td>\n",
       "      <td>success</td>\n",
       "      <td>CC</td>\n",
       "      <td>conjunction, coordinating</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>and</td>\n",
       "      <td>721.802041</td>\n",
       "      <td>722.021542</td>\n",
       "      <td>0.219501</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.834281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>join</td>\n",
       "      <td>success</td>\n",
       "      <td>VB</td>\n",
       "      <td>verb, base form</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>join</td>\n",
       "      <td>722.021542</td>\n",
       "      <td>722.380726</td>\n",
       "      <td>0.359184</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3.629002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>my</td>\n",
       "      <td>success</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>pronoun, possessive</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>my</td>\n",
       "      <td>722.380726</td>\n",
       "      <td>722.520408</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.537693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     Case   POS                                POS_Definition  \\\n",
       "1926      one  success    CD                             numeral, cardinal   \n",
       "1927       to  success    TO      \"to\" as preposition or infinitive marker   \n",
       "1928       my  success  PRP$                           pronoun, possessive   \n",
       "1929     Jeep  success   NNP                        noun, proper, singular   \n",
       "1930   that's  success    NN                noun, common, singular or mass   \n",
       "1931     been  success   VBN                         verb, past participle   \n",
       "1932   stolen  success   VBN                         verb, past participle   \n",
       "1933      God  success   NNP                        noun, proper, singular   \n",
       "1934       is  success   VBZ      verb, present tense, 3rd person singular   \n",
       "1935  banging  success   VBG            verb, present participle or gerund   \n",
       "1936       on  success    IN     preposition or conjunction, subordinating   \n",
       "1937       my  success  PRP$                           pronoun, possessive   \n",
       "1938     hood  success    NN                noun, common, singular or mass   \n",
       "1939       So  success    RB                                        adverb   \n",
       "1940        I  success   PRP                             pronoun, personal   \n",
       "1941     toss  success   VBP  verb, present tense, not 3rd person singular   \n",
       "1942      the  success    DT                                    determiner   \n",
       "1943     keys  success   NNS                          noun, common, plural   \n",
       "1944     head  success   VBP  verb, present tense, not 3rd person singular   \n",
       "1945       to  success    TO      \"to\" as preposition or infinitive marker   \n",
       "1946      art  success    VB                               verb, base form   \n",
       "1947   school  success    NN                noun, common, singular or mass   \n",
       "1948      and  success    CC                     conjunction, coordinating   \n",
       "1949     join  success    VB                               verb, base form   \n",
       "1950       my  success  PRP$                           pronoun, possessive   \n",
       "\n",
       "     punctuation  Stop_Word  Digit Word_Vocab       Onset      Offset  \\\n",
       "1926                  False  False        one  711.025414  711.226077   \n",
       "1927                   True  False         to  711.226077  711.285941   \n",
       "1928                   True  False         my  711.285941  711.505442   \n",
       "1929                  False  False       Jeep  711.505442  711.924490   \n",
       "1930                   True  False     that's  711.924490  712.094104   \n",
       "1931                   True  False       been  712.094104  712.268932   \n",
       "1932          .       False  False     stolen  712.268932  712.992063   \n",
       "1933                  False  False        God  714.378912  714.817914   \n",
       "1934                   True  False         is  714.817914  715.037415   \n",
       "1935                  False  False    banging  715.037415  715.446485   \n",
       "1936                   True  False         on  715.446485  715.656009   \n",
       "1937                   True  False         my  715.656009  715.845578   \n",
       "1938          .       False  False       hood  715.845578  716.314512   \n",
       "1939          ,        True  False         So  718.399773  718.579365   \n",
       "1940                   True  False          I  718.579365  718.719048   \n",
       "1941                  False  False       toss  718.719048  719.128118   \n",
       "1942                   True  False        the  719.128118  719.227891   \n",
       "1943          ,       False  False       keys  719.227891  719.896372   \n",
       "1944                  False  False       head  720.255556  720.495011   \n",
       "1945                   True  False         to  720.495011  720.584103   \n",
       "1946                  False  False        art  720.584103  720.844218   \n",
       "1947          ,       False  False     school  720.844218  721.672336   \n",
       "1948                   True  False        and  721.802041  722.021542   \n",
       "1949                  False  False       join  722.021542  722.380726   \n",
       "1950                   True  False         my  722.380726  722.520408   \n",
       "\n",
       "      Duration  Named_Entity  NWP_Candidate    Lg10WF  \n",
       "1926  0.200663         False           True  5.195027  \n",
       "1927  0.059864         False          False  6.063172  \n",
       "1928  0.219501         False          False  5.537693  \n",
       "1929  0.419048          True          False  2.720159  \n",
       "1930  0.169615         False          False       NaN  \n",
       "1931  0.174828         False          False  4.947306  \n",
       "1932  0.723131         False           True  3.243286  \n",
       "1933  0.439002          True          False  4.663343  \n",
       "1934  0.219501         False          False  5.662440  \n",
       "1935  0.409070         False           True  2.640481  \n",
       "1936  0.209524         False          False  5.549914  \n",
       "1937  0.189569         False          False  5.537693  \n",
       "1938  0.468934         False           True  2.895423  \n",
       "1939  0.179592         False          False  5.335364  \n",
       "1940  0.139683         False          False  6.309317  \n",
       "1941  0.409070         False           True  2.801404  \n",
       "1942  0.099773         False          False  6.176644  \n",
       "1943  0.668481         False           True  3.415307  \n",
       "1944  0.239456         False           True  4.277563  \n",
       "1945  0.089092         False          False  6.063172  \n",
       "1946  0.260114         False           True  3.557748  \n",
       "1947  0.828118         False           True  4.230193  \n",
       "1948  0.219501         False          False  5.834281  \n",
       "1949  0.359184         False           True  3.629002  \n",
       "1950  0.139683         False          False  5.537693  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc.iloc[candidate_segment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cebb976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_segments = [segments[idx-1] for idx in candidate_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "52a4ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [prosody.transcript_to_input(df_preproc, segment, add_punctuation=True) for segment in segments]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark_matter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
