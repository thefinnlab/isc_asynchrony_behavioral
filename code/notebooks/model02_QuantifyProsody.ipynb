{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fd735d-a62b-4116-b83f-c9f1fb904d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /dartfs/rc/lab/F/FinnLab/tommy/models/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/lab/F/FinnLab/tommy/conda/envs/prosody/lib/python3.12/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/utils/')\n",
    "sys.path.append('/dartfs/rc/lab/F/FinnLab/tommy/isc_asynchrony_behavior/code/modeling/joint-clm-prosody/')\n",
    "\n",
    "from config import *\n",
    "from src.data.prominence_regression_datamodule import ProminenceRegressionDataModule\n",
    "from src.models.joint_clm_prosody import ProsodyCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f375be-52c2-40c4-ba03-52cb633f16b4",
   "metadata": {},
   "source": [
    "### Just try using wavelet prosody files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4811e014-c841-4c99-b10a-49a6abe538cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ff661fdd-a66c-40a4-8bcc-6cd164953075",
   "metadata": {},
   "outputs": [],
   "source": [
    "prosody_dir = os.path.join(BASE_DIR, 'stimuli/prosody')\n",
    "\n",
    "stim_names = ['black', 'wheretheressmoke', 'howtodraw', 'odetostepfather', 'demon']\n",
    "\n",
    "# for stim in stim_names:\n",
    "#     word_path = os.path.join(BASE_DIR, f'stimuli/adjusted/{stim}.TextGrid')\n",
    "#     wav_path = os.path.join(BASE_DIR, f'stimuli/audio/{stim}.wav')\n",
    "\n",
    "#     stim_data.loc[len(stim_data)] = {\n",
    "#         'words_path': word_path,\n",
    "#         'wav_path': wav_path\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "28d2d35f-f03a-40da-9b61-e32c71897ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = 'black'\n",
    "\n",
    "tg = textgrid.openTextgrid(os.path.join(BASE_DIR, f'stimuli/adjusted/{stim}.TextGrid'), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b7202df-3d96-46d3-9785-1f8ac0613572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tg.getTier('word').entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fccc9d26-216e-4813-8921-89c69a5c1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['stim', 'start', 'end', 'word', 'prominence', 'boundary']\n",
    "\n",
    "df_selected = pd.read_csv(os.path.join(BASE_DIR, f'stimuli/preprocessed/{stim}/{stim}_transcript-selected.csv'))\n",
    "df_prosody = pd.read_csv(os.path.join(prosody_dir, f'{stim_names[0]}.prom'), sep='\\t', names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774eb37-388b-437b-adaf-df48961a93d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test the prosody extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c714091-1e11-4691-9b54-344a60b0a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.feature_extractors import ProsodyFeatureExtractor\n",
    "from src.utils.text_processing import read_lab_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "347ebaa6-62dd-4fea-8075-e7e91bb90706",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'dev-clean'\n",
    "\n",
    "modeling_dir = os.path.join(BASE_DIR, 'code/modeling/joint-clm-prosody/')\n",
    "data_root = os.path.join(modeling_dir, 'data/LibriTTS/')\n",
    "\n",
    "lab_root = os.path.join(data_root, f'LibriTTSLabel/lab/word/{dtype}/')\n",
    "phoneme_lab_root = os.path.join(data_root, f'LibriTTSLabel/lab/phone/{dtype}/')\n",
    "wav_root = os.path.join(data_root, f'LibriTTS_R/{dtype}/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d33f168c-5ef9-4fb9-b96a-d3ec36c2ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stim_names = ['black', 'wheretheressmoke', 'howtodraw', 'odetostepfather', 'demon']\n",
    "\n",
    "stim_data = pd.DataFrame(columns=['words_path', 'wav_path'])\n",
    "\n",
    "for stim in stim_names:\n",
    "    word_path = os.path.join(BASE_DIR, f'stimuli/adjusted/{stim}.TextGrid')\n",
    "    wav_path = os.path.join(BASE_DIR, f'stimuli/audio/{stim}.wav')\n",
    "\n",
    "    stim_data.loc[len(stim_data)] = {\n",
    "        'words_path': word_path,\n",
    "        'wav_path': wav_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e57235a2-4620-4940-a8a8-6a717a2fff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71081405-f403-496a-8c3f-d7c7fe959ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ProsodyFeatureExtractor(\n",
    "    csv_path='test.csv',\n",
    "    data_cache='test-cache/',\n",
    "    extract_word_duration=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4a1facf-5b4b-47bb-9b27-79ae0aa29435",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, nb_syll_not_found = extractor._extract_features(\n",
    "    words_path=stim_data.iloc[0]['words_path'],\n",
    "    wav_path=stim_data.iloc[0]['wav_path'],\n",
    "    phonemes_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d97b4839-8613-4db9-97e7-19f29cf5e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('phone', 'word')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgrid.openTextgrid(stim_data.iloc[0]['words_path'], False).tierNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae218054-46a6-4704-aafe-453ae74cfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "from scipy.fftpack import dct, fft\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.text_processing import (\n",
    "    find_stress_syllable_start,\n",
    "    syllabify,\n",
    "    CelexReader,\n",
    "    read_textgrid_file,\n",
    "    read_lab_file,\n",
    "    remove_breaks_from_lab_lines,\n",
    "    python_lowercase_remove_punctuation,\n",
    "    nb_syllables,\n",
    ")\n",
    "from src.utils.helsinki_features import WordBreakExtractor\n",
    "from src.utils.utils import min_length_of_lists, sec_to_idx, equal_length_or_none\n",
    "from src.utils.prosody_tools.misc import read_wav, normalize_std\n",
    "from src.utils.prosody_tools import (\n",
    "    f0_processing,\n",
    "    smooth_and_interp,\n",
    "    energy_processing,\n",
    "    duration_processing,\n",
    ")\n",
    "\n",
    "INVALID_SYMBOLS = [\"<unk>\"]\n",
    "\n",
    "class ProsodyFeatureExtractor:\n",
    "    def __init__(self, csv_path, data_cache=None, language=None, \n",
    "                 extract_f0=False, f0_mode=\"dct\", f0_n_coeffs=4, f0_stress_localizer=None, \n",
    "                 f0_window=500, f0_resampling_length=100, celex_path=None, extract_energy=False, \n",
    "                 energy_mode=\"mean\", extract_word_duration=False, word_duration_mode=\"syllable_norm\", \n",
    "                 extract_duration=False, extract_pause_before=False, extract_pause_after=False, \n",
    "                 extract_prominence=False, prominence_mode=\"mean\", f0_min=50, f0_max=400, \n",
    "                 f0_voicing=50, energy_min_freq=200, energy_max_freq=5000, f0_weight=1.0, \n",
    "                 energy_weight=0.5, duration_weight=1, unallowed_symbols=INVALID_SYMBOLS):\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.csv_path = csv_path\n",
    "        self.data_cache = data_cache\n",
    "        self.language = language\n",
    "\n",
    "        # Feature extraction flags\n",
    "        self.extract_f0 = extract_f0\n",
    "        self.f0_mode = f0_mode\n",
    "        self.f0_n_coeffs = f0_n_coeffs\n",
    "        self.f0_stress_localizer = f0_stress_localizer\n",
    "        self.f0_window = f0_window\n",
    "        self.f0_resampling_length = f0_resampling_length\n",
    "        \n",
    "        # Initialize Celex manager if needed\n",
    "        if self.extract_f0 and self.language == 'stress':\n",
    "            self.celex_path = celex_path\n",
    "            self.celex_manager = CelexReader(celex_path)\n",
    "        \n",
    "        # More feature extraction flags\n",
    "        self.extract_energy = extract_energy\n",
    "        self.energy_mode = energy_mode\n",
    "        self.extract_word_duration = extract_word_duration\n",
    "        self.word_duration_mode = word_duration_mode\n",
    "        self.extract_duration = extract_duration\n",
    "        self.extract_pause_before = extract_pause_before\n",
    "        self.extract_pause_after = extract_pause_after\n",
    "        self.extract_prominence = extract_prominence\n",
    "        self.prominence_mode = prominence_mode\n",
    "\n",
    "        # F0 and energy parameters\n",
    "        self.f0_min = f0_min\n",
    "        self.f0_max = f0_max\n",
    "        self.f0_voicing = f0_voicing\n",
    "        self.energy_min_freq = energy_min_freq\n",
    "        self.energy_max_freq = energy_max_freq\n",
    "\n",
    "        # Feature weights\n",
    "        self.f0_weight = f0_weight\n",
    "        self.energy_weight = energy_weight\n",
    "        self.duration_weight = duration_weight\n",
    "\n",
    "        self.unallowed_symbols = unallowed_symbols\n",
    "\n",
    "        # Initialize pause extractors if needed\n",
    "        if self.extract_pause_before:\n",
    "            self.pause_before_extractor = WordBreakExtractor(modes=\"before\")\n",
    "        if self.extract_pause_after:\n",
    "            self.pause_after_extractor = WordBreakExtractor(modes=\"after\")\n",
    "\n",
    "        self.samples = []\n",
    "        self.file_name = os.path.splitext(os.path.basename(self.csv_path))[0]\n",
    "        self.extracted_features = self._get_extracted_features()\n",
    "\n",
    "    def _get_extracted_features(self):\n",
    "        \"\"\"Determine which features to extract based on class attributes.\"\"\"\n",
    "        features = [\n",
    "            \"f0\", \"energy\", \"word_duration\", \"duration\",\n",
    "            \"pause_before\", \"pause_after\", \"prominence\"\n",
    "        ]\n",
    "        return [f for f in features if getattr(self, f\"extract_{f}\", False)]\n",
    "\n",
    "    def extract_and_cache_features(self):\n",
    "        \"\"\"Extract features from files and cache the results.\"\"\"\n",
    "        print(f\"Extracted features: {self.extracted_features}\")\n",
    "\n",
    "        self.process_files()  # Assuming this method populates self.samples\n",
    "\n",
    "        d_correct = defaultdict(list)\n",
    "        for sample in self.samples:\n",
    "            d_correct['texts'].append(sample['text'])\n",
    "            for feature in self.extracted_features:\n",
    "                if feature == 'f0':\n",
    "                    d_correct['f0'].append(sample['features']['f0_parameterized'])\n",
    "                else:\n",
    "                    d_correct[feature].append(sample['features'][feature])\n",
    "\n",
    "        self._save_to_cache(dict(d_correct))\n",
    "\n",
    "    def _save_to_cache(self, data):\n",
    "        \"\"\"Save extracted features to a cache file.\"\"\"\n",
    "        feature_name = self.extracted_features[0] if self.extracted_features else 'unknown'\n",
    "        if feature_name == 'f0':\n",
    "            file_name = f\"{feature_name}_{self.f0_mode}_{self.f0_n_coeffs}.pkl\"\n",
    "        else:\n",
    "            file_name = f\"{feature_name}.pkl\"\n",
    "\n",
    "        self.cache_path = os.path.join(self.data_cache, self.file_name, file_name)\n",
    "        os.makedirs(os.path.dirname(self.cache_path), exist_ok=True)\n",
    "\n",
    "        with open(self.cache_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "        print(f\"Saved samples to {self.cache_path}\")\n",
    "\n",
    "    def process_files(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Process files based on the input CSV file and extract features.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of dictionaries containing extracted features and metadata.\n",
    "        \"\"\"\n",
    "        failed_alignments = 0\n",
    "        total_nb_syllables_not_found = 0\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "\n",
    "        # Ensure required columns are present\n",
    "        required_columns = ['words_path', 'wav_path']\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            raise ValueError(f\"CSV must contain the following columns: {required_columns}\")\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing files\"):\n",
    "            words_path = row['words_path']\n",
    "            wav_path = row['wav_path']\n",
    "            phonemes_path = row.get('phonemes_path', None)\n",
    "\n",
    "            if not os.path.exists(words_path) or not os.path.exists(wav_path):\n",
    "                print(f\"Error: File not found - {words_path} or {wav_path}\")\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Processing file {words_path}\")\n",
    "\n",
    "            try:\n",
    "                features, nb_syll_not_found = self._extract_features(\n",
    "                    words_path=words_path,\n",
    "                    wav_path=wav_path,\n",
    "                    phonemes_path=phonemes_path,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Error in feature extraction: {str(e)}')\n",
    "                failed_alignments += 1\n",
    "                continue\n",
    "\n",
    "            if features is None:\n",
    "                failed_alignments += 1\n",
    "                continue\n",
    "\n",
    "            total_nb_syllables_not_found += nb_syll_not_found\n",
    "\n",
    "            # Create a sample dictionary with all columns as metadata\n",
    "            sample = OrderedDict({\n",
    "                \"features\": features,\n",
    "                \"words_path\": words_path,\n",
    "                \"wav_path\": wav_path,\n",
    "                \"phonemes_path\": phonemes_path,\n",
    "            })\n",
    "\n",
    "            # Add all other columns as metadata\n",
    "            for col in df.columns:\n",
    "                if col not in ['words_path', 'wav_path', 'phonemes_path']:\n",
    "                    sample[col] = row[col]\n",
    "\n",
    "            self.samples.append(sample)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Failed alignments: {failed_alignments}\")\n",
    "            print(f\"Total number of syllables not found: {total_nb_syllables_not_found}\")\n",
    "            print(f\"Total processed utterances: {len(self.samples)}\")\n",
    "\n",
    "        return self.samples\n",
    "        \n",
    "    def _extract_features(self, words_path, wav_path, phonemes_path=None):\n",
    "        \"\"\"Extract all specified features from a single file.\"\"\"\n",
    "        features = {}\n",
    "        nb_syllables_not_found = 0\n",
    "\n",
    "        # Read audio file\n",
    "        fs, waveform = read_wav(wav_path)\n",
    "\n",
    "        # Load information for the current words\n",
    "        if words_path.endswith('.TextGrid'):\n",
    "            word_lines, end_time = read_textgrid_file(words_path, tier='word')\n",
    "        else:\n",
    "            word_lines = read_lab_file(words_path)\n",
    "            end_time = float(word_lines[-1][1])\n",
    "\n",
    "        # Remove breaks from lab lines\n",
    "        word_lines = remove_breaks_from_lab_lines(word_lines)\n",
    "\n",
    "        # Now load phonemes if applicable\n",
    "        if phonemes_path:\n",
    "            if phonemes_path.endswith('.TextGrid'):\n",
    "                phoneme_lines, _ = read_textgrid_file(words_path, tier='word')\n",
    "            else:\n",
    "                phoneme_lines = read_lab_file(phonemes_path)\n",
    "\n",
    "            # remove breaks from phoneme lines\n",
    "            phoneme_lines = remove_breaks_from_lab_lines(phoneme_lines)\n",
    "\n",
    "        # Extract pauses if needed\n",
    "        if self.extract_pause_before:\n",
    "            pause_before = self.pause_before_extractor.extract_from_lab_lines(word_lines)\n",
    "            if pause_before is None:\n",
    "                return None, None\n",
    "            features[\"pause_before\"] = [round(pause, 3) for pause in pause_before if pause is not None]\n",
    "\n",
    "        if self.extract_pause_after:\n",
    "            pause_after = self.pause_after_extractor.extract_from_lab_lines(word_lines)\n",
    "            if pause_after is None:\n",
    "                return None, None\n",
    "            features[\"pause_after\"] = [round(pause, 3) for pause in pause_after if pause is not None]\n",
    "        \n",
    "        # Check for invalid words\n",
    "        words = [word for _, _, word in word_lines]\n",
    "        if any(word in self.unallowed_symbols for word in words):\n",
    "            return None, None\n",
    "\n",
    "        features[\"words\"] = words\n",
    "\n",
    "        # Extract features\n",
    "        f0 = self._extract_f0(waveform, fs) if self.extract_f0 else None\n",
    "        energy = self._extract_energy(waveform, fs) if self.extract_energy else None\n",
    "        duration = self._extract_duration(waveform, fs, word_lines, min_length_of_lists([f0, energy])) if self.extract_duration else None\n",
    "        prominence = self._extract_prominence(f0, energy, duration) if self.extract_prominence else None\n",
    "\n",
    "        if self.extract_word_duration:\n",
    "            features[\"word_duration\"] = self._extract_word_duration(word_lines)\n",
    "\n",
    "        # Extract per-word features\n",
    "        if self.extract_f0:\n",
    "            f0_per_word, cnt_not_found = self._extract_f0_per_word(word_lines, f0, phoneme_lines, end_time)\n",
    "            nb_syllables_not_found += cnt_not_found\n",
    "            features[\"f0_parameterized\"] = [self._parameterize_f0(f) for f in f0_per_word]\n",
    "\n",
    "        if self.extract_energy:\n",
    "            energy_per_word = self._extract_feature_per_word(word_lines, energy, end_time)\n",
    "            features[\"energy\"] = (\n",
    "                [np.mean(e) for e in energy_per_word] if self.energy_mode == \"mean\" else\n",
    "                [np.max(e) for e in energy_per_word] if self.energy_mode == \"max\" else\n",
    "                energy_per_word\n",
    "            )\n",
    "\n",
    "        if self.extract_duration:\n",
    "            features[\"duration\"] = self._extract_feature_per_word(word_lines, duration, end_time)\n",
    "\n",
    "        if self.extract_prominence:\n",
    "            prominence_per_word = self._extract_feature_per_word(word_lines, prominence, end_time)\n",
    "            features[\"prominence\"] = (\n",
    "                [np.mean(p) for p in prominence_per_word] if self.prominence_mode == \"mean\" else\n",
    "                [np.max(p) for p in prominence_per_word] if self.prominence_mode == \"max\" else\n",
    "                prominence_per_word\n",
    "            )\n",
    "\n",
    "        return features, nb_syllables_not_found\n",
    "\n",
    "    def _parameterize_f0(self, f0):\n",
    "        \"\"\"Parameterize F0 curve based on specified mode.\"\"\"\n",
    "        if self.f0_mode == \"dct\":\n",
    "            return dct(f0, type=2, norm=\"ortho\")[: self.f0_n_coeffs]\n",
    "        elif self.f0_mode == \"fft\":\n",
    "            return fft(f0)[: self.f0_n_coeffs]\n",
    "        elif self.f0_mode == \"poly\":\n",
    "            return np.polyfit(np.arange(len(f0)), f0, self.f0_n_coeffs - 1)[: self.f0_n_coeffs]\n",
    "        elif self.f0_mode == \"mean\":\n",
    "            precision = len(f0) // self.f0_n_coeffs\n",
    "            return np.array([np.mean(f0[i:i+precision]) for i in range(0, len(f0), precision)])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown f0_mode: {self.f0_mode}\")\n",
    "\n",
    "    def _extract_f0(self, waveform, fs):\n",
    "        \"\"\"Extract and process F0 from waveform.\"\"\"\n",
    "        f0_raw = f0_processing.extract_f0(waveform=waveform, fs=fs, f0_min=self.f0_min, \n",
    "                                          f0_max=self.f0_max, voicing=self.f0_voicing)\n",
    "        f0_interpolated = f0_processing.process(f0_raw)\n",
    "        return normalize_std(f0_interpolated)\n",
    "\n",
    "    def _extract_energy(self, waveform, fs):\n",
    "        \"\"\"Extract and process energy from waveform.\"\"\"\n",
    "        energy = energy_processing.extract_energy(waveform=waveform, fs=fs, \n",
    "                                                  min_freq=self.energy_min_freq, \n",
    "                                                  max_freq=self.energy_max_freq, method=\"rms\")\n",
    "        energy_smooth = smooth_and_interp.peak_smooth(energy, 30, 3)\n",
    "        return normalize_std(energy_smooth)\n",
    "\n",
    "    def _extract_duration(self, waveform, fs, word_lines, resample_length):\n",
    "        \"\"\"Extract and process duration signal.\"\"\"\n",
    "        duration_signal = duration_processing.duration(word_lines, rate=fs)\n",
    "        duration_norm = normalize_std(duration_signal)\n",
    "        return signal.resample(duration_norm, resample_length)\n",
    "\n",
    "    def _extract_prominence(self, f0, energy, duration):\n",
    "        \"\"\"Extract prominence as a weighted combination of F0, energy, and duration.\"\"\"\n",
    "        min_length = min(len(f0), len(energy), len(duration))\n",
    "        f0, energy, duration = f0[:min_length], energy[:min_length], duration[:min_length]\n",
    "        prominence = (self.f0_weight * f0 + self.energy_weight * energy + \n",
    "                      self.duration_weight * duration)\n",
    "        prominence = smooth_and_interp.remove_bias(prominence, 800)\n",
    "        return normalize_std(prominence)\n",
    "\n",
    "    def _extract_word_duration(self, word_lines):\n",
    "        \"\"\"Extract word duration based on specified mode.\"\"\"\n",
    "        word_duration = [float(end) - float(start) for start, end, _ in word_lines]\n",
    "        if self.word_duration_mode == \"char_norm\":\n",
    "            return [duration / len(word) for duration, (_, _, word) in zip(word_duration, word_lines)]\n",
    "        elif self.word_duration_mode == \"absolute\":\n",
    "            return [round(duration, 3) for duration in word_duration]\n",
    "        elif self.word_duration_mode == \"syllable_norm\":\n",
    "            return [duration / nb_syllables(word) if nb_syllables(word) > 0 else 0\n",
    "                    for duration, (_, _, word) in zip(word_duration, word_lines)]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown word_duration_mode: {self.word_duration_mode}\")\n",
    "\n",
    "    def _extract_feature_per_word(self, word_lines, feature, end_time):\n",
    "        \"\"\"Extract feature values for each word.\"\"\"\n",
    "        return [feature[sec_to_idx(float(start), end_time, len(feature)):\n",
    "                        sec_to_idx(float(end), end_time, len(feature))]\n",
    "                for start, end, _ in word_lines]\n",
    "\n",
    "    def _extract_f0_per_word(self, word_lines, f0, phoneme_lines, end_time=0, verbose=False):\n",
    "        \"\"\"Extract F0 for each word, with optional stress localization.\"\"\"\n",
    "        cnt_not_found = 0\n",
    "        f0_per_word = []\n",
    "        for start, end, word in tqdm(word_lines, total=len(word_lines), desc=\"Extracting f0\"):\n",
    "            start_idx = sec_to_idx(float(start), end_time, len(f0))\n",
    "            end_idx = sec_to_idx(float(end), end_time, len(f0))\n",
    "\n",
    "            if self.f0_stress_localizer == \"celex\":\n",
    "                syllables = syllabify(word)\n",
    "                stressed_syllable_idx = self.celex_manager.get_stress_index(word)\n",
    "                stress_syllable_time = find_stress_syllable_start(\n",
    "                    syllables, stressed_syllable_idx, phoneme_lines, float(start), float(end))\n",
    "\n",
    "                if stress_syllable_time:\n",
    "                    stress_syllable_idx = sec_to_idx(stress_syllable_time, end_time, len(f0))\n",
    "                    new_start = max(start_idx, stress_syllable_idx - self.f0_window // 2)\n",
    "                    new_end = min(end_idx, stress_syllable_idx + self.f0_window // 2)\n",
    "                else:\n",
    "                    cnt_not_found += 1\n",
    "                    new_start, new_end = start_idx, end_idx\n",
    "            else:\n",
    "                new_start, new_end = start_idx, end_idx\n",
    "\n",
    "            f0_per_word.append(signal.resample(f0[new_start:new_end], self.f0_resampling_length))\n",
    "\n",
    "        return f0_per_word, cnt_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e353745-50da-4bd4-95ef-91d0167d6397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.data.components.feature_extractors.ProsodyFeatureExtractor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = ProsodyFeatureExtractor(\n",
    "    lab_root=os.path.join(self.hparams.lab_root, file_name),\n",
    "    wav_root=os.path.join(self.hparams.wav_root, file_name),\n",
    "    phoneme_lab_root=os.path.join(self.hparams.phoneme_lab_root, file_name),\n",
    "    data_cache=self.hparams.data_cache,\n",
    "    extract_f0=True,\n",
    "    f0_mode=self.hparams.f0_mode,\n",
    "    f0_n_coeffs=self.hparams.f0_n_coeffs,\n",
    "    celex_path=self.hparams.celex_path,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
