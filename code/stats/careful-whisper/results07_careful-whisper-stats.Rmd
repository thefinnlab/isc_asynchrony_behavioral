---
title: "careful-whisper_stats"
author: "Tommy Botch"
date: "2024-11-15"
output: html_document
---

# Setup environment

## Load packages and setup paths for analysis

Set up directories - since we're doing this locally (and mounting the server), 
we're going to use a different base_dir

```{r setup, include=FALSE}

# Source the utils.R file to load the functions
source("../utils/utils.R")

# Load required and additional packages
install_and_load()

# Set the paths for this notebook
set_paths(analysis_name="behavioral", plots_name="careful-whisper")
```

# Careful Whisper analyses

## Data loading

Load data and set factors. Our columns are the following:
- **modality:** which modality was the stimulus presented as (video, audio, text, or model name) 
- **word_index:** the word index within the story
- **task:** which of the three stories was the data from (black, wheretheressmoke, howtodraw)

We create a contrast of modality such that we test the hypothesis that multimodal (video) > spoken (audio) > written (text).

```{r}

results_fn <- file.path(results_dir, "all-dataset-av-main_careful-whisper_all-results_batch-size-32.csv")

# Load data and convert columns to factors
df_results <- load_and_prepare_data(
  file_path=results_fn,
  factor_columns=c('batch_number', 'model_name', 'dataset')
)

# Set the levels for the modality column
df_results <- set_factor_levels(
  df=df_results,
  column_name="model_name",
  levels=c("GPT2", "ProsodyXAttn", "AudioXAttn", "AudioVisualXAttn")
)

df_results <- create_column_contrast(
  df=df_results, 
  column_name="model_name",
  n_poly=2
)
```

## Analysis 1A - Accuracy of models

```{r}

accuracy_formula <- 'accuracy ~ model_name + (1|batch_number:dataset)'

# Fit the logistic mixed-effects model
model <- lmer(
  accuracy_formula, 
  data=df_results, 
)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)

# Display results of fixed effects
display_model_summary(model)

# Conduct pairwise comparisons between modalities
pairwise_comparisons <- emmeans(model, pairwise ~ model_name)
display_pairwise_comparisons(pairwise_comparisons)
```

## Analysis 1B - Perplexity of models

```{r}

perplexity_formula <- 'perplexity ~ model_name + (1|batch_number:dataset)'

# Fit the logistic mixed-effects model
model <- lmer(
  perplexity_formula, 
  data=df_results, 
)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)

# Display results of fixed effects
display_model_summary(model)

# Conduct pairwise comparisons between modalities
pairwise_comparisons <- emmeans(model, pairwise ~ model_name)
display_pairwise_comparisons(pairwise_comparisons)
```


## Analysis 2 - Subset analysis

```{r}

# Load the results file
results_fn <- file.path(results_dir, "all-subsets_careful-whisper_model-comparisons.csv")

# Load data and convert columns to factors
df_results <- load_and_prepare_data(
  file_path=results_fn,
  factor_columns=c('main_model', 'batch_number')
)

# Set the levels for the modality column
df_results <- set_factor_levels(
  df=df_results,
  column_name="main_model",
  levels=c("GPT2", "ProsodyXAttn", "AudioXAttn", "AudioVisualXAttn")
)

df_results <- create_column_contrast(
  df=df_results, 
  column_name="main_model",
  n_poly=2
)

```

## Analysis 2A - Model accuracy growth curve

```{r}

subsets_formula <- 'main_accuracy ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_results, 
  family=gaussian(link='log'),
  control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 2e5))
)


tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)

# Conduct pairwise comparisons between modalities
pairwise_comparisons <- emmeans(model, pairwise ~ model_name)
display_pairwise_comparisons(pairwise_comparisons)

plot_model(model, type='pred', terms=c('true_subset', 'main_model'))

```

<!-- # ```{r, fig.width=5, fig.height=8} -->
<!-- #  -->
<!-- # check_model(model) -->
<!-- #  -->
<!-- # ``` -->

### Model perpleixty decay

```{r}

# subject model for accuracy --> test if audio > text
# audio_greater_prosody <- c(1,-1)

df_cleaned <- remove_outliers(df_results, 'main_perplexity')

contrasts(df_cleaned$main_model, how.many=2) <- contr.poly(length(unique(df_cleaned$main_model)))

subsets_formula <- 'main_perplexity ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_cleaned, 
  family=Gamma(link='log'),
  # control = glmerControl(optimizer ="Nelder_Mead")
  )

print (BIC(model))

summary(model)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model'))

```

### Accuracy subset ratio

```{r}

# set order of variables
df_cleaned <- df_results[df_results$main_model != 'GPT2',]
df_cleaned <- remove_outliers(df_cleaned, 'subset_accuracy_ratio')

df_cleaned$main_model <- factor(df_cleaned$main_model, levels = 
                                  c("AudioXAttn", "ProsodyXAttn"))

audio_greater_prosody <- c(1, -1)
contrasts(df_cleaned$main_model) <- cbind(audio_greater_prosody)

subsets_formula <- 'subset_accuracy_ratio ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_cleaned, 
  )
print (BIC(model))

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model')) #, show.data=TRUE)

```

### Perplexity subset ratio

```{r}

# subject model for accuracy --> test if audio > text
# audio_greater_prosody <- c(1,-1)

# set order of variables
df_cleaned <- df_results[df_results$main_model != 'GPT2',]

df_cleaned <- df_cleaned[!is.na(df_cleaned$subset_perplexity_ratio),]

df_cleaned <- remove_outliers(df_cleaned, 'subset_perplexity_ratio')

df_cleaned$main_model <- factor(df_cleaned$main_model, levels = 
                                  c("AudioXAttn", "ProsodyXAttn"))

# df_cleaned[df_cleaned$subset_accuracy_ratio < 0,]$subset_accuracy_ratio <- 1e-2

audio_greater_prosody <- c(1, -1)
contrasts(df_cleaned$main_model) <- cbind(audio_greater_prosody)

subsets_formula <- 'subset_perplexity_ratio ~ main_model * log(true_subset)' # + (1|batch_number)'

model <- glm(
  subsets_formula, 
  data=df_cleaned, 
  family=gaussian(link='log'),
  )

print (BIC(model))

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model')) #, show.data=TRUE)

```

<!-- ## Load comparisons to humans -->

<!-- ```{r} -->

<!-- normalize <- function(x){(x-min(x))/(max(x)-min(x))} -->

<!-- # Load the results file -->
<!-- results_fn<-glue('{results_dir}/archive-121724/all-task_group-analyzed-behavior_window-size-25_human-prosody-model-distributions-lemmatized.csv') -->
<!-- df_results <- read.csv(results_fn) -->

<!-- df_results <- convert_columns_to_factors(df_results, c('dataset', 'model_name', 'task', 'word_index', 'modality')) -->


<!-- # set order of variables -->
<!-- df_results$model_name <- factor(df_results$model_name, levels = c("ProsodyPrediction", "ProsodyAccess", "ProsodyDeprived")) -->

<!-- # df_results <- remove_outliers(df_results, 'kl_divergence') -->
<!-- ``` -->

<!-- ### Test model KL Divergence -->

<!-- ```{r} -->

<!-- audio_greater_text <- c(1,-1) -->
<!-- contrasts(df_results$modality) <- cbind(audio_greater_text) -->

<!-- # access_greater_deprived <- c(1,-1) -->
<!-- # contrasts(df_results$model_name) <- cbind(access_greater_deprived) -->

<!-- # Test ordered contrast --> audio >  -->
<!-- contrasts(df_results$model_name, how.many=1) <- contr.poly(length(unique(df_results$model_name))) -->

<!-- kl_formula = 'kl_divergence ~ modality * model_name * prominence_mean + (1|word_index:task) + (1|dataset)' -->

<!-- model <- lmer(kl_formula, data=df_results, REML=TRUE) -->

<!-- tab_model(model) -->

<!-- summary(model) -->
<!-- plot_model(model, type='pred', terms=c('modality', 'model_name')) -->

<!-- # ggplot(df_results, aes(x=sqrt(prominence_mean))) + geom_density() -->
<!-- ``` -->

<!-- ```{r} -->

<!-- check_predictions(model) -->

<!-- testDispersion(model) -->
<!-- simulationOutput <- simulateResiduals(model, plot = F) -->
<!-- plot(simulationOutput) -->
<!-- ``` -->