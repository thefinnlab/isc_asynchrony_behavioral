---
title: "careful-whisper_stats"
author: "Tommy Botch"
date: "2024-11-15"
output: html_document
---

# Setup environment

## Load packages

```{r}
# remove all variables
rm(list=ls()) 

# install.packages(c("lmerTest", "emmeans", "glue", "ggeffects", "ggplot2", 
#                    "ggsignif", "ggpattern", "viridis", "forcats", "dplyr",
#                    "stringr", "tools", "lmer4", "combinat", "ggpubr", "report",
#                    "rcompanion", "sjPlot", "glmmTMB", "DHARMa", "tidyverse"))

library(lmerTest)
library(emmeans)
library(glue)
library(ggeffects)
library(ggplot2)
library(sjPlot)
library(report)
library(rcompanion)
library(sjPlot)
library(tidyverse)

library(DHARMa)
library(glmmTMB)
library(tidyverse)
library(performance)
library(ordinal)
```

## Prepare directories

Set up directories - since we're doing this locally (and mounting the server), 
we're going to use a different base_dir

```{r}

base_dir<-'/Volumes/FinnLab/tommy/isc_asynchrony_behavior/derivatives/'
results_dir<-glue('{base_dir}results/behavioral/')
plots_dir <- glue('{base_dir}plots/final/')

```

## Functions

```{r}
# Function to convert specified columns to factors
convert_columns_to_factors <- function(df, columns_to_convert) {
  # Check if all specified columns exist in the dataframe
  if (!all(columns_to_convert %in% names(df))) {
    missing_cols <- columns_to_convert[!columns_to_convert %in% names(df)]
    stop(paste("The following columns do not exist in the dataframe:", 
               paste(missing_cols, collapse = ", ")))
  }
  
  # Convert each specified column to factor
  for (col in columns_to_convert) {
    df[[col]] <- factor(df[[col]])
  }
  
  return(df)
}

# Function to process a single dataset
process_dataset <- function(dataset) {
  # Construct filename using glue
  results_fn <- glue('{results_dir}{dataset}_careful-whisper_all-results_batch-size-32.csv')
  
  # Read the CSV file
  df <- read.csv(results_fn)
  
  # Add dataset column
  df <- df %>%
    mutate(dataset_name = dataset)
  
  return(df)
}

# Function to remove outliers based on IQR of a specific column and print the number of removed values
remove_outliers <- function(df, column, ratio=1.5) {
  if (!column %in% names(df)) {
    stop("Column not found in dataframe.")
  }
  if (!is.numeric(df[[column]])) {
    stop("Selected column is not numeric.")
  }

  initial_rows <- nrow(df)  # Store the initial number of rows

  # Calculate IQR bounds for the specified column
  Q1 <- quantile(df[[column]], 0.25)
  Q3 <- quantile(df[[column]], 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - ratio * IQR
  upper_bound <- Q3 + ratio * IQR

  # Filter rows based on the specified column's bounds
  df_clean <- df[df[[column]] >= lower_bound & df[[column]] <= upper_bound, ]
  
  # Calculate and print number of rows removed
  removed_rows <- initial_rows - nrow(df_clean)
  cat("Number of rows removed due to outliers in column", column, ":", removed_rows, "\n")
  
  return(df_clean)
}

# Function to extract p-values and test statistics
extract_lme_results <- function(dataset, df_results, formula, include_intercept = FALSE) {
  # Subset data for the specific task
  df_dataset <- df_results[df_results$dataset_name == dataset,]
  
  # Fit the linear mixed-effects model
  model <- lmer(formula, data = df_dataset, REML = TRUE)
  
  return(model)
}




```

# Run human participant analysis

## Data loading

Load data and set factor columns 

```{r}

# Construct filename using glue
results_fn <- glue('{results_dir}all-dataset-main-main_careful-whisper_all-results_batch-size-32.csv')

# Read the CSV file
df_results <- read.csv(results_fn)

```

### Set up order of factors

```{r}

# Set the variable types
factor_columns <- c('batch_number', 'model_name', 'dataset')

df_results <- convert_columns_to_factors(df_results, factor_columns)

# set order of variables
df_results$model_name <- factor(df_results$model_name, levels = c("GPT2", "ProsodyXAttn", "AudioXAttn"))

```


## Accuracy

```{r}

# Test ordered contrast --> audio > 
contrasts(df_results$model_name, how.many=2) <- contr.poly(length(unique(df_results$model_name)))

accuracy_formula <- 'accuracy ~ model_name  + (1|batch_number:dataset)'

model <- lmer(accuracy_formula, data = df_results)

BIC(model)
report(model)
summary(model)
tab_model(model, show.stat=TRUE, show.est = TRUE, show.se=TRUE, show.r2=TRUE)
# 
plot_model(model, type='pred', terms=c('model_name'), show.data=TRUE)

```

```{r}
emmeans(model, pairwise ~ model_name, lmerTest.limit = 4932)
```

### Calculate task-wise accuracy

```{r}

dataset_accuracy_formula <- 'accuracy ~ model_name  + (1|batch_number)'
# Subset data for the specific task

dataset <- 'libritts-r'
model <- extract_lme_results(dataset, df_results, dataset_accuracy_formula)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
summary(model)

dataset <- 'peoples-speech'
model <- extract_lme_results(dataset, df_results, dataset_accuracy_formula)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
summary(model)

dataset <- 'tedlium'
model <- extract_lme_results(dataset, df_results, dataset_accuracy_formula)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
summary(model)

dataset <- 'gigaspeech'
model <- extract_lme_results(dataset, df_results, dataset_accuracy_formula)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
summary(model)
# # Extract results for all tasks (excluding intercept by default)
# model <- lapply(datasets, function(datasets) {
#   extract_lme_results(datasets, df_results, dataset_accuracy_formula)
# })



# results_list
# extract_lme_results('libritts-r', df_results, dataset_accuracy_formula)


# Combine results
# combined_results <- do.call(rbind, results_list)

# # Test ordered contrast --> audio > 
# contrasts(df_results$model_name) <- contr.poly(length(unique(df_results$model_name)))
# 
# accuracy_formula <- 'accuracy ~ model_name  + (1|batch_number:dataset_name)'
# 
# model <- lmer(accuracy_formula, data = df_results)

```
### Plot for each dataset

```{r}

ggplot(df_results, aes(x = model_name, y = accuracy, group = dataset_name, color = dataset_name)) +
 geom_line(stat = "summary", fun = mean) +
 geom_point(stat = "summary", fun = mean) +
 geom_errorbar(stat = "summary", fun.data = mean_se, width = 0.2) +
 theme_minimal() +
 theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
 labs(title = "Mean Accuracy by Model Name and Dataset")
```


```{r, fig.width=10, fig.height=8}

check_model(model)
```

## Perplexity

```{r} 
# Test ordered contrast --> audio > 
contrasts(df_results$model_name) <- contr.poly(length(unique(df_results$model_name)))


# Test ordered contrast --> audio > 
perplexity_formula <- 'perplexity ~ model_name + (1|batch_number:dataset)'

model <- lmer(perplexity_formula, data = df_results, REML=TRUE)

report(model)
summary(model)
tab_model(model, show.stat=TRUE, show.est = TRUE, show.se=TRUE, show.r2=TRUE)


print (AIC(model))

```

```{r}
emmeans(model, pairwise ~ model_name)
```
## Load model comparisons for subsets

```{r}


# Load the results file
results_fn<-glue('{results_dir}/all-subsets_careful-whisper_model-comparisons.csv')
df_results <- read.csv(results_fn)

df_results <- convert_columns_to_factors(df_results, c('main_model', 'batch_number'))

# set order of variables
df_results$main_model <- factor(df_results$main_model, levels = 
                                  c("AudioXAttn", "ProsodyXAttn", "GPT2"))

df_results <- df_results[df_results$true_subset >= 5,]

```

### Model accuracy growth

```{r}

# subject model for accuracy --> test if audio > text
# audio_greater_prosody <- c(1,-1)
df_cleaned <- df_results
contrasts(df_cleaned$main_model, how.many=2) <- contr.poly(length(unique(df_cleaned$main_model)))

subsets_formula <- 'main_accuracy ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_cleaned, 
  family=gaussian(link='log'),
  control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 2e5))
  )

print (BIC(model))

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model'))

```

<!-- # ```{r, fig.width=5, fig.height=8} -->
<!-- #  -->
<!-- # check_model(model) -->
<!-- #  -->
<!-- # ``` -->

### Model perpleixty decay

```{r}

# subject model for accuracy --> test if audio > text
# audio_greater_prosody <- c(1,-1)

df_cleaned <- remove_outliers(df_results, 'main_perplexity')

contrasts(df_cleaned$main_model, how.many=2) <- contr.poly(length(unique(df_cleaned$main_model)))

subsets_formula <- 'main_perplexity ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_cleaned, 
  family=Gamma(link='log'),
  # control = glmerControl(optimizer ="Nelder_Mead")
  )

print (BIC(model))

summary(model)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model'))

```

### Accuracy subset ratio

```{r}

# set order of variables
df_cleaned <- df_results[df_results$main_model != 'GPT2',]
df_cleaned <- remove_outliers(df_cleaned, 'subset_accuracy_ratio')

df_cleaned$main_model <- factor(df_cleaned$main_model, levels = 
                                  c("AudioXAttn", "ProsodyXAttn"))

audio_greater_prosody <- c(1, -1)
contrasts(df_cleaned$main_model) <- cbind(audio_greater_prosody)

subsets_formula <- 'subset_accuracy_ratio ~ main_model * log(true_subset) + (1|batch_number)'

model <- glmer(
  subsets_formula, 
  data=df_cleaned, 
  )
print (BIC(model))

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model')) #, show.data=TRUE)

```

### Perplexity subset ratio

```{r}

# subject model for accuracy --> test if audio > text
# audio_greater_prosody <- c(1,-1)

# set order of variables
df_cleaned <- df_results[df_results$main_model != 'GPT2',]

df_cleaned <- df_cleaned[!is.na(df_cleaned$subset_perplexity_ratio),]

df_cleaned <- remove_outliers(df_cleaned, 'subset_perplexity_ratio')

df_cleaned$main_model <- factor(df_cleaned$main_model, levels = 
                                  c("AudioXAttn", "ProsodyXAttn"))

# df_cleaned[df_cleaned$subset_accuracy_ratio < 0,]$subset_accuracy_ratio <- 1e-2

audio_greater_prosody <- c(1, -1)
contrasts(df_cleaned$main_model) <- cbind(audio_greater_prosody)

subsets_formula <- 'subset_perplexity_ratio ~ main_model * log(true_subset)' # + (1|batch_number)'

model <- glm(
  subsets_formula, 
  data=df_cleaned, 
  family=gaussian(link='log'),
  )

print (BIC(model))

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
# 
plot_model(model, type='pred', terms=c('true_subset', 'main_model')) #, show.data=TRUE)

```

<!-- ## Load comparisons to humans -->

<!-- ```{r} -->

<!-- normalize <- function(x){(x-min(x))/(max(x)-min(x))} -->

<!-- # Load the results file -->
<!-- results_fn<-glue('{results_dir}/archive-121724/all-task_group-analyzed-behavior_window-size-25_human-prosody-model-distributions-lemmatized.csv') -->
<!-- df_results <- read.csv(results_fn) -->

<!-- df_results <- convert_columns_to_factors(df_results, c('dataset', 'model_name', 'task', 'word_index', 'modality')) -->


<!-- # set order of variables -->
<!-- df_results$model_name <- factor(df_results$model_name, levels = c("ProsodyPrediction", "ProsodyAccess", "ProsodyDeprived")) -->

<!-- # df_results <- remove_outliers(df_results, 'kl_divergence') -->
<!-- ``` -->

<!-- ### Test model KL Divergence -->

<!-- ```{r} -->

<!-- audio_greater_text <- c(1,-1) -->
<!-- contrasts(df_results$modality) <- cbind(audio_greater_text) -->

<!-- # access_greater_deprived <- c(1,-1) -->
<!-- # contrasts(df_results$model_name) <- cbind(access_greater_deprived) -->

<!-- # Test ordered contrast --> audio >  -->
<!-- contrasts(df_results$model_name, how.many=1) <- contr.poly(length(unique(df_results$model_name))) -->

<!-- kl_formula = 'kl_divergence ~ modality * model_name * prominence_mean + (1|word_index:task) + (1|dataset)' -->

<!-- model <- lmer(kl_formula, data=df_results, REML=TRUE) -->

<!-- tab_model(model) -->

<!-- summary(model) -->
<!-- plot_model(model, type='pred', terms=c('modality', 'model_name')) -->

<!-- # ggplot(df_results, aes(x=sqrt(prominence_mean))) + geom_density() -->
<!-- ``` -->

<!-- ```{r} -->

<!-- check_predictions(model) -->

<!-- testDispersion(model) -->
<!-- simulationOutput <- simulateResiduals(model, plot = F) -->
<!-- plot(simulationOutput) -->
<!-- ``` -->