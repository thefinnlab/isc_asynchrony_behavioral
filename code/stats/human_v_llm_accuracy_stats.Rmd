---
title: "human_v_llm_accuracy_stats"
author: "Tommy Botch"
date: "2024-11-15"
output: html_document
---

# Setup environment

## Load packages

```{r}
# remove all variables
rm(list=ls()) 

# install.packages(c("lmerTest", "emmeans", "glue", "ggeffects", "ggplot2", 
#                    "ggsignif", "ggpattern", "viridis", "forcats", "dplyr",
#                    "stringr", "tools", "lmer4", "combinat", "ggpubr", "report",
#                    "rcompanion", "sjPlot", "glmmTMB", "DHARMa", "tidyverse"))

library(lmerTest)
library(emmeans)
library(glue)
library(ggeffects)
library(ggplot2)
library(sjPlot)
library(report)
library(rcompanion)
library(sjPlot)
library(tidyverse)

library(DHARMa)
library(glmmTMB)
library(tidyverse)
library(performance)
library(ordinal)
```

## Prepare directories

Set up directories - since we're doing this locally (and mounting the server), 
we're going to use a different base_dir

```{r}

base_dir<-'/Volumes/FinnLab/tommy/isc_asynchrony_behavior/derivatives/'
results_dir<-glue('{base_dir}results/behavioral/')
plots_dir <- glue('{base_dir}plots/final/')

```

## Functions

```{r}
# Function to convert specified columns to factors
convert_columns_to_factors <- function(df, columns_to_convert) {
  # Check if all specified columns exist in the dataframe
  if (!all(columns_to_convert %in% names(df))) {
    missing_cols <- columns_to_convert[!columns_to_convert %in% names(df)]
    stop(paste("The following columns do not exist in the dataframe:", 
               paste(missing_cols, collapse = ", ")))
  }
  
  # Convert each specified column to factor
  for (col in columns_to_convert) {
    df[[col]] <- factor(df[[col]])
  }
  
  return(df)
}

```

# Run human participant analysis

## Data loading

Load data and set factor columns 

```{r}

# Load the results file
results_fn<-glue('{results_dir}all-task_group-analyzed-behavior_window-size-00025_human-model-lemmatized.csv')
df_results <- read.csv(results_fn)

# ADD A COLUMN THAT GROUPS HUMANS/MODELS
df_results <- df_results %>%
  mutate(model_type = case_when(
    modality %in% c("audio") ~ "audio",
    modality %in% c("text") ~ "text",
    modality %in% c('roberta', 'electra', 'xlm-prophetnet') ~ "mlm",
    TRUE ~ "clm"  # Default case
  ))


```

### Set up order of factors

```{r}

# Set the variable types
factor_columns <- c('modality', 'model_type', 'word_index', 'top_pred', 'task', "entropy_group", "accuracy_group", 'task')

df_results <- convert_columns_to_factors(df_results, factor_columns)


# set order of variables
df_results$model_type <- factor(df_results$model_type, levels = 
                                  c("audio", "text", "clm", "mlm"))
df_results$entropy_group <- factor(df_results$entropy_group, levels = c("high", "low"))
df_results$accuracy_group <- factor(df_results$accuracy_group, levels = c("high", "low"))

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

```

## Binary accuracy

### Logistic regression 

Classify accuracy based on modality
Test ordered contrast of audio > text > clm > mlm

```{r}

human_v_model_formula <- 'accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- glmer(human_v_model_formula, data=df_results, family=binomial(link="logit"))

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
summary(model)

```

### Prosody interaction

Rerun the logistic regression with the mean prosody included as an interaction effect. 

```{r}

human_v_model_formula <- 'accuracy ~ model_type * prominence_mean + (1|modality) + (1|word_index:task)'

model <- glmer(human_v_model_formula, data=df_results, 
               family=binomial(link="logit"), 
               control =glmerControl(optimizer ="Nelder_Mead"))

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE)
summary(model)

```


## Continuous accuracy

### Linear mixed-effects model

Predict accuracy based on modality 

```{r}

human_v_model_formula <- 'fasttext_top_word_accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_results)

report(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)

# df_results$fasttext_top_word_distance <- 1 - df_results$fasttext_top_word_accuracy
# df_results[df_results$fasttext_top_word_distance < 0]$fasttext_top_word_distance <- 0

# model <- glmmTMB(
#   formula = fasttext_top_word_distance ~ model_type * prominence_mean + (1|modality) + (1|word_index:task),
#   ziformula = ~ model_type * prominence_mean + (1|modality) + (1|word_index:task),
#   data=df_results,
#   family=gaussian(),
# )

# ggplot(df_results, aes(x=fasttext_top_word_distance, fill=model_type)) + 
#   geom_histogram(alpha=0.5)

```

### Check model

```{r}
# 1. Get predictions for both components
# Conditional (Gaussian) model
conditional_pred <- ggpredict(model, terms = c("model_type", 'prominence_mean'), type = "fixed")

# Create prediction data for both components
conditional_pred <- ggpredict(model, 
                            terms = c("prominence_mean [all]", "model_type"),
                            type = "fixed")

zi_pred <- ggpredict(model, 
                     terms = c("prominence_mean [all]", "model_type"),
                     type = "zi_prob")

# Plot for conditional component
p1 <- ggplot(conditional_pred, aes(x = x, y = predicted, color = group)) +
  geom_line() +
  # geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2) +
  labs(title = "Conditional Component",
       x = "Prominence Mean",
       y = "Predicted Distance",
       color = "Model Type",
       fill = "Model Type") +
  theme_minimal()


# Plot for zero-inflation component
p2 <- ggplot(zi_pred, aes(x = x, y = predicted, color = group)) +
  geom_line() +
  # geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2) +
  labs(title = "Zero-Inflation Component",
       x = "Prominence Mean",
       y = "Probability of Zero",
       color = "Model Type",
       fill = "Model Type") +
  theme_minimal()

# Combine plots
combined_plot <- p1 / p2

# Display
print(combined_plot)
```

### Include prosody within model

```{r}

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

continuous_accuracy_formula <- 'fasttext_top_word_accuracy ~ model_type * prominence_mean + (1|modality) + (1|word_index:task)'

# Fit the logistic mixed-effects model
model <- lmer(continuous_accuracy_formula, data=df_results)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE)
summary (model)

```

## Accuracy difference

### Accuracy difference info kept in comparisons file

Load data and set factor columns 

```{r}

# Load the results file
results_fn<-glue('{results_dir}all-task_group-analyzed-behavior_window-size-00025_human-model-distributions-lemmatized.csv')

df_accuracy_contrast <- read.csv(results_fn)

# ADD A COLUMN THAT GROUPS HUMANS/MODELS
df_accuracy_contrast <- df_accuracy_contrast %>%
  mutate(model_type = case_when(
    model_name %in% c('roberta', 'electra', 'xlm-prophetnet') ~ "mlm",
    TRUE ~ "clm"  # Default case
  ))

# Set the variable types
factor_columns <- c('modality', 'model_name', 'model_type', 'word_index', 'task', "entropy_group", "accuracy_group", 'task')

df_accuracy_contrast <- convert_columns_to_factors(df_accuracy_contrast, factor_columns)

# set order of variables
df_accuracy_contrast$modality <- factor(df_accuracy_contrast$modality, levels = c("audio", "text"))
df_accuracy_contrast$model_type <- factor(df_accuracy_contrast$model_type, levels = c("clm", "mlm"))

audio_greater_text <- c(1,-1)
contrasts(df_accuracy_contrast$modality) <- cbind(audio_greater_text)
```

### Calculate difference in accuracy

```{r}

human_v_model_formula <- 'human_model_accuracy_diff ~  modality * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast, REML=TRUE)

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df = TRUE)

```


### Plot model results

```{r}
# task_average <- df_accuracy_contrast %>%
#   group_by(task, word_index) %>%
#   summarize(mean_accuracy_difference = mean(accuracy_difference, na.rm = TRUE))

preds <- data.frame(get_model_data(model, type='pred', terms = c("model_entropy", "modality")))

head(preds)

colors <- c('#82C564', '#F7CD84')

ggplot(preds, aes(x=x, y=predicted, color=group)) + 
  geom_point(
    data = df_accuracy_contrast, 
    aes(x=model_entropy, y=human_model_accuracy_diff, color=modality), 
    stroke=1,
    alpha=0.075) +
  geom_line(size=1) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3, color=NA) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1) +
  theme(
    aspect.ratio = 6/7,
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
  ) +
  scale_color_manual(values=colors) +
  scale_fill_manual(values=colors) +
  labs(
    x = "Model Entropy",
    y = "Accuracy Difference",
    title = "Difference of human and model accuracy") 

ggsave('human-llm_accuracy-difference-entropy.pdf', device = "pdf")

```
### Now include prosody

```{r}

human_v_model_formula <- 'human_model_accuracy_diff ~ modality * prominence_mean * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast, REML=TRUE)

# summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
```


```{r}

preds <- data.frame(get_model_data(model, type='pred', terms = c("prominence_mean", "baseline_modality")))

head(preds)

colors <- c('#82C564', '#F7CD84')

ggplot(preds, aes(x=x, y=predicted, color=group)) + 
  geom_point(
    data = df_accuracy_contrast, 
    aes(x=prominence_mean, y=accuracy_difference, color=baseline_modality), 
    stroke=1,
    alpha=0.05) +
  geom_line(size=1) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3, color=NA) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1) +
  theme(
    aspect.ratio = 6/7,
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
  ) +
  scale_color_manual(values=colors) +
  scale_fill_manual(values=colors) +
  labs(
    x = "Prosodic Prominence",
    y = "Accuracy Difference",
    title = "Prosody drives difference of human and LLM accuracy ") 

# ggsave('human-llm_accuracy-difference-prosody-interaction.pdf', device = "pdf")
```

# Supplementary analyses

## Leakage filtering stat check

```{r}

# First filter by pvalue less than 0.05 uncorrected --> test absence of effect
df_results_filtered <- subset(df_results, df_results$barnard_pvalue >= 0.05)
df_accuracy_contrast_filtered <- subset(df_accuracy_contrast, df_accuracy_contrast$barnard_pvalue >= 0.05)

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

```

## Binary accuracy

### Logistic regression 

Classify accuracy based on modality
Test ordered contrast of audio > text > clm > mlm

```{r}

human_v_model_formula <- 'accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- glmer(
  human_v_model_formula, 
  data=df_results_filtered, 
  family=binomial(link="logit"))

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
report(model)

```

## Continuous accuracy

### Linear mixed-effects model

Predict accuracy based on modality 

```{r}

human_v_model_formula <- 'fasttext_top_word_accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_results_filtered)

report(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)

```

## Accuracy difference

### Calculate difference in accuracy

```{r}

human_v_model_formula <- 'human_model_accuracy_diff ~  modality * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast_filtered, REML=TRUE)

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df = TRUE)

```

### Plot results

```{r}
preds <- data.frame(get_model_data(model, type='pred', terms = c("model_entropy", "modality")))

head(preds)

colors <- c('#82C564', '#F7CD84')

ggplot(preds, aes(x=x, y=predicted, color=group)) + 
  geom_point(
    data = df_accuracy_contrast_filtered, 
    aes(x=model_entropy, y=human_model_accuracy_diff, color=modality), 
    stroke=1,
    alpha=0.05) +
  geom_line(size=1) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3, color=NA) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1) +
  theme(
    aspect.ratio = 16/9,
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
  ) +
  scale_color_manual(values=colors) +
  scale_fill_manual(values=colors) +
  labs(
    x = "Model Entropy",
    y = "Accuracy Difference",
    title = "Difference of human and model accuracy") 
```

### Now include prosody

```{r}

human_v_model_formula <- 'human_model_accuracy_diff ~ modality * prominence_mean * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast_filtered, REML=TRUE)

# summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
```