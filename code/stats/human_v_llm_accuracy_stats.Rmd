---
title: "human_v_llm_accuracy_stats"
author: "Tommy Botch"
date: "2024-11-15"
output: html_document
---

# Setup environment

## Load packages

```{r}
# remove all variables
rm(list=ls()) 

# install.packages(c("lmerTest", "emmeans", "glue", "ggeffects", "ggplot2", 
#                    "ggsignif", "ggpattern", "viridis", "forcats", "dplyr",
#                    "stringr", "tools", "lmer4", "combinat", "ggpubr", "report",
#                    "rcompanion", "sjPlot", "glmmTMB", "DHARMa", "tidyverse"))

library(lmerTest)
library(emmeans)
library(glue)
library(ggeffects)
library(ggplot2)
library(sjPlot)
library(report)
library(rcompanion)
library(sjPlot)
library(tidyverse)

library(DHARMa)
library(glmmTMB)
library(tidyverse)
library(performance)
library(ordinal)
```

## Prepare directories

Set up directories - since we're doing this locally (and mounting the server), 
we're going to use a different base_dir

```{r}

base_dir<-'/Volumes/FinnLab/tommy/isc_asynchrony_behavior/derivatives/'
results_dir<-glue('{base_dir}results/behavioral/')
plots_dir <- glue('{base_dir}plots/final/')

```

## Functions

```{r}
# Function to convert specified columns to factors
convert_columns_to_factors <- function(df, columns_to_convert) {
  # Check if all specified columns exist in the dataframe
  if (!all(columns_to_convert %in% names(df))) {
    missing_cols <- columns_to_convert[!columns_to_convert %in% names(df)]
    stop(paste("The following columns do not exist in the dataframe:", 
               paste(missing_cols, collapse = ", ")))
  }
  
  # Convert each specified column to factor
  for (col in columns_to_convert) {
    df[[col]] <- factor(df[[col]])
  }
  
  return(df)
}

```

# Run human participant analysis

## Data loading

Load data and set factor columns 

```{r}

# Load the results file
results_fn<-glue('{results_dir}all-task_group-analyzed-behavior_window-size-25_human-model-lemmatized.csv')
df_results <- read.csv(results_fn)

# ADD A COLUMN THAT GROUPS HUMANS/MODELS
df_results <- df_results %>%
  mutate(model_type = case_when(
    modality %in% c("audio") ~ "audio",
    modality %in% c("text") ~ "text",
    modality %in% c('roberta', 'electra', 'xlm-prophetnet') ~ "mlm",
    TRUE ~ "clm"  # Default case
  ))


```

### Set up order of factors

```{r}

# Set the variable types
factor_columns <- c('modality', 'model_type', 'word_index', 'top_pred', 'task', "entropy_group", "accuracy_group", 'task')

df_results <- convert_columns_to_factors(df_results, factor_columns)


# set order of variables
df_results$model_type <- factor(df_results$model_type, levels = 
                                  c("audio", "text", "clm", "mlm"))
df_results$entropy_group <- factor(df_results$entropy_group, levels = c("high", "low"))
df_results$accuracy_group <- factor(df_results$accuracy_group, levels = c("high", "low"))
```

## Binary accuracy

### Logistic regression 

Classify accuracy based on modality
Test ordered contrast of audio > text > clm > mlm

```{r}

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

human_v_model_formula <- 'accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- glmer(human_v_model_formula, data=df_results, family=binomial(link="logit"))

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)
report(model)

```

```{r}

simulationOutput <- simulateResiduals(fittedModel = model, n = 1000, seed = 42)
plot(simulationOutput)

```

### Prosody interaction

Rerun the logistic regression with the mean prosody included as an interaction effect. 

```{r}

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

human_v_model_formula <- 'accuracy ~ model_type * prominence_mean + (1|modality) + (1|word_index:task)'

model <- glmer(human_v_model_formula, data=df_results, 
               family=binomial(link="logit"), 
               control =glmerControl(optimizer ="Nelder_Mead"))

tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE)
summary(model)

```


## Continuous accuracy

### Linear mixed-effects model

Predict accuracy based on modality 

```{r}

# Test ordered contrast --> audio >
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

human_v_model_formula <- 'fasttext_top_word_accuracy ~ model_type + (1|modality) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_results)

report(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.est=TRUE, show.df=TRUE)

# df_results$fasttext_top_word_distance <- 1 - df_results$fasttext_top_word_accuracy
# df_results[df_results$fasttext_top_word_distance < 0]$fasttext_top_word_distance <- 0

# model <- glmmTMB(
#   formula = fasttext_top_word_distance ~ model_type * prominence_mean + (1|modality) + (1|word_index:task),
#   ziformula = ~ model_type * prominence_mean + (1|modality) + (1|word_index:task),
#   data=df_results,
#   family=gaussian(),
# )

# ggplot(df_results, aes(x=fasttext_top_word_distance, fill=model_type)) + 
#   geom_histogram(alpha=0.5)

```

### Check model

```{r}
# 1. Get predictions for both components
# Conditional (Gaussian) model
conditional_pred <- ggpredict(model, terms = c("model_type", 'prominence_mean'), type = "fixed")

# Create prediction data for both components
conditional_pred <- ggpredict(model, 
                            terms = c("prominence_mean [all]", "model_type"),
                            type = "fixed")

zi_pred <- ggpredict(model, 
                     terms = c("prominence_mean [all]", "model_type"),
                     type = "zi_prob")

# Plot for conditional component
p1 <- ggplot(conditional_pred, aes(x = x, y = predicted, color = group)) +
  geom_line() +
  # geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2) +
  labs(title = "Conditional Component",
       x = "Prominence Mean",
       y = "Predicted Distance",
       color = "Model Type",
       fill = "Model Type") +
  theme_minimal()


# Plot for zero-inflation component
p2 <- ggplot(zi_pred, aes(x = x, y = predicted, color = group)) +
  geom_line() +
  # geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2) +
  labs(title = "Zero-Inflation Component",
       x = "Prominence Mean",
       y = "Probability of Zero",
       color = "Model Type",
       fill = "Model Type") +
  theme_minimal()

# Combine plots
combined_plot <- p1 / p2

# Display
print(combined_plot)
```
### Include prosody within model

```{r}

# Test ordered contrast --> audio > 
contrasts(df_results$model_type, how.many=1) <- contr.poly(length(unique(df_results$model_type)))

continuous_accuracy_formula <- 'fasttext_top_word_accuracy ~ model_type * prominence_mean + (1|modality) + (1|word_index:task)'

# Fit the logistic mixed-effects model
model <- lmer(continuous_accuracy_formula, data=df_results)

tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE)
summary (model)

```

### Function to create accuracy difference

We need to contrast each model's accuracy with audio/text

```{r}

# Function to create contrasts between baseline modalities and models, including entropy
create_accuracy_contrasts <- function(df) {
  # Get unique models (excluding audio and text)
  models <- setdiff(unique(df$modality), c("audio", "text"))
  
  # Initialize lists to store results
  contrasts <- list()
  
  # Create contrasts for both audio and text
  for (baseline in c("audio", "text")) {
    baseline_acc <- df$fasttext_top_word_accuracy[df$modality == baseline]
    baseline_word_index <- df$word_index[df$modality == baseline]
    baseline_prominence <- df$prominence_mean[df$modality == baseline]
    
    for (model in models) {
      
      model_acc <- df$fasttext_top_word_accuracy[df$modality == model]
      model_entropy <- df$entropy[df$modality == model]
      word_index <- df$word_index[df$modality == model]
      task <- df$task[df$modality == model]
      model_type <- df$model_type[df$modality==model]
      
      word_index_filter <- baseline_word_index == word_index
      
      contrasts[[length(contrasts) + 1]] <- data.frame(
        baseline_modality = baseline,
        model_name = model,
        model_type = model_type,
        accuracy_difference = baseline_acc[word_index_filter] - model_acc,
        model_entropy = model_entropy,
        word_index = word_index,
        task = task,
        prominence_mean = baseline_prominence[word_index_filter]
      )
    }
  }
  
  # Combine all contrasts into a single dataframe
  result <- do.call(rbind, contrasts)
  
  # Reset row names
  rownames(result) <- NULL
  
  # Order by baseline_modality and absolute accuracy difference
  result <- result[order(result$baseline_modality,
                        result$task,
                        result$word_index,
                        -abs(result$accuracy_difference)), ]
  return(result)
  
}

normalize <- function(x){(x-min(x))/(max(x)-min(x))}

```

### Contrast model accuracy with human accuracy in both conditions

```{r}

df_accuracy_contrast <- create_accuracy_contrasts(df_results)
df_accuracy_contrast <- convert_columns_to_factors(df_accuracy_contrast, c('baseline_modality', "model_name", "word_index", "task", "model_type"))

df_results$model_type <- factor(df_results$model_type, levels = c('clm', 'mlm'))

audio_greater_text <- c(1, -1)
contrasts(df_accuracy_contrast$baseline_modality) <- cbind(audio_greater_text)

clm_greater_mlm <- c(1, -1)
contrasts(df_accuracy_contrast$model_type) <- cbind(clm_greater_mlm)

# df_accuracy_contrast$accuracy_difference <- normalize(df_accuracy_contrast$accuracy_difference)

# df_accuracy_contrast[df_accuracy_contrast$accuracy_difference == 0, ]$accuracy_difference <- 0.001
# df_accuracy_contrast[df_accuracy_contrast$accuracy_difference == 1, ]$accuracy_difference <- 0.999
```

### Compare accuracy difference as a function of model entropy

```{r}

ggplot(df_accuracy_contrast, aes(x=accuracy_difference)) + geom_histogram(alpha=0.5)


human_v_model_formula <- 'accuracy_difference ~  baseline_modality * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast, REML=TRUE)

summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df = TRUE)

```


### Plot model results

```{r}
# task_average <- df_accuracy_contrast %>%
#   group_by(task, word_index) %>%
#   summarize(mean_accuracy_difference = mean(accuracy_difference, na.rm = TRUE))

preds <- data.frame(get_model_data(model, type='pred', terms = c("model_entropy", "baseline_modality")))

head(preds)

colors <- c('#82C564', '#F7CD84')

ggplot(preds, aes(x=x, y=predicted, color=group)) + 
  geom_point(
    data = df_accuracy_contrast, 
    aes(x=model_entropy, y=accuracy_difference, color=baseline_modality), 
    stroke=1,
    alpha=0.05) +
  geom_line(size=1) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3, color=NA) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1) +
  theme(
    aspect.ratio = 16/9,
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
  ) +
  scale_color_manual(values=colors) +
  scale_fill_manual(values=colors) +
  labs(
    x = "Model Entropy",
    y = "Accuracy Difference",
    title = "Difference of human and model accuracy") 

ggsave('human-llm_accuracy-difference-entropy.pdf', device = "pdf")

```

### Check model

```{r, fig.width=10, fig.height=8}

check_model(model)

```
### Now include prosody

```{r}

audio_greater_text <- c(1, -1)
clm_greater_mlm <- c(1, -1)

contrasts(df_accuracy_contrast$baseline_modality) <- cbind(audio_greater_text)
contrasts(df_accuracy_contrast$model_type) <- cbind(clm_greater_mlm)

human_v_model_formula <- 'accuracy_difference ~ baseline_modality * prominence_mean * model_entropy + (1|model_name) + (1|word_index:task)'

model <- lmer(human_v_model_formula, data=df_accuracy_contrast, REML=TRUE)

# summary(model)
tab_model(model, show.se=TRUE, show.stat=TRUE, show.r2=TRUE, show.df=TRUE)
```


```{r}

preds <- data.frame(get_model_data(model, type='pred', terms = c("prominence_mean", "baseline_modality")))

head(preds)

colors <- c('#82C564', '#F7CD84')

ggplot(preds, aes(x=x, y=predicted, color=group)) + 
  geom_point(
    data = df_accuracy_contrast, 
    aes(x=prominence_mean, y=accuracy_difference, color=baseline_modality), 
    stroke=1,
    alpha=0.05) +
  geom_line(size=1) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3, color=NA) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1) +
  theme(
    aspect.ratio = 6/7,
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
  ) +
  scale_color_manual(values=colors) +
  scale_fill_manual(values=colors) +
  labs(
    x = "Prosodic Prominence",
    y = "Accuracy Difference",
    title = "Prosody drives difference of human and LLM accuracy ") 

ggsave('human-llm_accuracy-difference-prosody-interaction.pdf', device = "pdf")
```
