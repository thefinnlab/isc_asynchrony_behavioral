program: train.py
method: bayes
metric:
  goal: maximize
  name: val/accuracy
parameters:
  # model/params/trainable:
  #   max: 248884224
  #   min: 62221056
  #   distribution: int_uniform
  # model/params/total:
  #   max: 248884224
  #   min: 62221056
  #   distribution: int_uniform
  task_name:
    values:
      - train
    distribution: categorical
  callbacks:
    values:
      - "{'model_checkpoint': {'_target_': 'lightning.pytorch.callbacks.ModelCheckpoint'"
      - "'dirpath': '${paths.output_dir}/checkpoints'"
      - "'filename': 'epoch_{epoch:03d}'"
      - "'monitor': 'val/loss'"
      - "'verbose': False"
      - "'save_last': True"
      - "'save_top_k': 1"
      - "'mode': 'min'"
      - "'auto_insert_metric_name': False"
      - "'save_weights_only': False"
      - "'every_n_train_steps': None"
      - "'train_time_interval': None"
      - "'every_n_epochs': None"
      - "'save_on_train_epoch_end': None}"
      - "'early_stopping': {'_target_': 'lightning.pytorch.callbacks.EarlyStopping'"
      - "'monitor': 'val/loss'"
      - "'min_delta': 0.0"
      - "'patience': 3"
      - "'verbose': False"
      - "'mode': 'min'"
      - "'strict': True"
      - "'check_finite': True"
      - "'stopping_threshold': None"
      - "'divergence_threshold': None"
      - "'check_on_train_epoch_end': None}"
      - "'model_summary': {'_target_': 'lightning.pytorch.callbacks.RichModelSummary'"
      - "'max_depth': -1}"
      - "'rich_progress_bar': {'_target_': 'lightning.pytorch.callbacks.RichProgressBar'}}"
    distribution: categorical
  trainer:
    values:
      - "{'_target_': 'lightning.pytorch.trainer.Trainer'"
      - "'default_root_dir': '${paths.output_dir}'"
      - "'min_epochs': 1"
      - "'max_epochs': 15"
      - "'accelerator': 'gpu'"
      - "'devices': 1"
      - "'precision': '16-mixed'"
      - "'check_val_every_n_epoch': 1"
      - "'deterministic': False"
      - "'gradient_clip_val': 1"
      - "'accumulate_grad_batches': 4}"
    distribution: categorical
  extras:
    values:
      - "{'ignore_warnings': False"
      - "'enforce_tags': True"
      - "'print_config': True}"
    distribution: categorical
  model:
    values:
      - "{'_target_': 'src.models.joint_clm_prosody.ProsodyCausalLM'"
      - "'optimizer': {'_target_': 'torch.optim.AdamW'"
      - "'_partial_': True"
      - "'lr': 2.5e-05"
      - "'weight_decay': 0.1}"
      - "'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau'"
      - "'_partial_': True"
      - "'mode': 'min'"
      - "'factor': 0.1"
      - "'patience': 2}"
      - "'model_name': 'gpt2'"
      - "'num_labels': 1"
      - "'loss_mode': 'clm'"
      - "'shuffle_prosody': False"
      - "'use_prosody_embeddings': False"
      - "'tie_prosody_embeddings': True"
      - "'pretrained': False"
      - "'output_activation': {'_target_': 'torch.nn.Identity'}"
      - "'freeze_kwargs': {'freeze_lm': False"
      - "'unfreeze_after': -1}"
      - "'loss_kwargs': {'w_prosody': 1"
      - "'w_clm': 1}}"
      - "{'_target_': 'src.models.joint_clm_prosody.ProsodyCausalLM'"
      - "'optimizer': {'_target_': 'torch.optim.AdamW'"
      - "'_partial_': True"
      - "'lr': 2.5e-05"
      - "'weight_decay': 0.1}"
      - "'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau'"
      - "'_partial_': True"
      - "'mode': 'min'"
      - "'factor': 0.1"
      - "'patience': 2}"
      - "'model_name': 'gpt2'"
      - "'num_labels': 1"
      - "'loss_mode': 'clm'"
      - "'shuffle_prosody': False"
      - "'use_prosody_embeddings': True"
      - "'tie_prosody_embeddings': True"
      - "'pretrained': False"
      - "'output_activation': {'_target_': 'torch.nn.Identity'}"
      - "'freeze_kwargs': {'freeze_lm': False"
      - "'unfreeze_after': -1}"
      - "'loss_kwargs': {'w_prosody': 1"
      - "'w_clm': 1}}"
      - "{'_target_': 'src.models.joint_clm_prosody.ProsodyCausalLM'"
      - "'optimizer': {'_target_': 'torch.optim.AdamW'"
      - "'_partial_': True"
      - "'lr': 2.5e-05"
      - "'weight_decay': 0.1}"
      - "'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau'"
      - "'_partial_': True"
      - "'mode': 'min'"
      - "'factor': 0.1"
      - "'patience': 2}"
      - "'model_name': 'gpt2'"
      - "'num_labels': 1"
      - "'loss_mode': 'joint'"
      - "'shuffle_prosody': False"
      - "'use_prosody_embeddings': True"
      - "'tie_prosody_embeddings': True"
      - "'pretrained': False"
      - "'output_activation': {'_target_': 'torch.nn.Identity'}"
      - "'freeze_kwargs': {'freeze_lm': False"
      - "'unfreeze_after': -1}"
      - "'loss_kwargs': {'w_prosody': 0.3"
      - "'w_clm': 1}}"
      - "{'_target_': 'src.models.joint_clm_prosody.ProsodyCausalLM'"
      - "'optimizer': {'_target_': 'torch.optim.AdamW'"
      - "'_partial_': True"
      - "'lr': 2.5e-05"
      - "'weight_decay': 0.1}"
      - "'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau'"
      - "'_partial_': True"
      - "'mode': 'min'"
      - "'factor': 0.1"
      - "'patience': 2}"
      - "'model_name': 'gpt2'"
      - "'num_labels': 1"
      - "'loss_mode': 'joint'"
      - "'shuffle_prosody': True"
      - "'use_prosody_embeddings': True"
      - "'tie_prosody_embeddings': True"
      - "'pretrained': False"
      - "'output_activation': {'_target_': 'torch.nn.Identity'}"
      - "'freeze_kwargs': {'freeze_lm': False"
      - "'unfreeze_after': -1}"
      - "'loss_kwargs': {'w_prosody': 0.3"
      - "'w_clm': 1}}"
      - "{'_target_': 'src.models.joint_clm_prosody.ProsodyCausalLM'"
      - "'optimizer': {'_target_': 'torch.optim.AdamW'"
      - "'_partial_': True"
      - "'lr': 2.5e-05"
      - "'weight_decay': 0.1}"
      - "'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau'"
      - "'_partial_': True"
      - "'mode': 'min'"
      - "'factor': 0.1"
      - "'patience': 2}"
      - "'model_name': 'gpt2'"
      - "'num_labels': 1"
      - "'loss_mode': 'clm'"
      - "'shuffle_prosody': True"
      - "'use_prosody_embeddings': True"
      - "'tie_prosody_embeddings': True"
      - "'pretrained': False"
      - "'output_activation': {'_target_': 'torch.nn.Identity'}"
      - "'freeze_kwargs': {'freeze_lm': False"
      - "'unfreeze_after': -1}"
      - "'loss_kwargs': {'w_prosody': 1"
      - "'w_clm': 1}}"
    distribution: categorical
  tags:
    values:
      - "['gpt2'"
      - "'prominence'"
      - "'regression'"
      - "'absolute'"
      - "'mle']"
    distribution: categorical
  seed:
    max: 84
    min: 21
    distribution: int_uniform
  data:
    values:
      - "{'_target_': 'src.data.wavelet_prominence_datamodule.WaveletDataModule'"
      - "'data_dir': '${paths.data_dir}/gigaspeech/prosody'"
      - "'batch_size': 64"
      - "'train_val_test_split': None"
      - "'model_name': 'gpt2'"
      - "'use_fast_tokenizer': False"
      - "'score_first_token': False"
      - "'score_last_token': True"
      - "'relative_to_prev': False"
      - "'n_prev': 1"
      - "'relative_to_mean': False"
      - "'word_stats_path': None"
      - "'shuffle_labels_yoked': False"
      - "'num_workers': 8"
      - "'pin_memory': False"
      - "'dataset_name': 'gigaspeech'"
      - "'debug': False}"
      - "{'_target_': 'src.data.wavelet_prominence_datamodule.WaveletDataModule'"
      - "'data_dir': '${paths.data_dir}/gigaspeech/prosody'"
      - "'batch_size': 64"
      - "'train_val_test_split': None"
      - "'model_name': 'gpt2'"
      - "'use_fast_tokenizer': False"
      - "'score_first_token': False"
      - "'score_last_token': True"
      - "'relative_to_prev': False"
      - "'n_prev': 1"
      - "'relative_to_mean': False"
      - "'word_stats_path': None"
      - "'shuffle_labels_yoked': True"
      - "'num_workers': 8"
      - "'pin_memory': False"
      - "'dataset_name': 'gigaspeech'"
      - "'debug': False}"
    distribution: categorical
  
command:
  - ${env}
  - python
  - ${program}
  - ${args_no_hyphens}